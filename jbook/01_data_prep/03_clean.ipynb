{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "This stage involves systematically addressing anomalies identified during the data quality assessment.\n",
    "\n",
    "## Approach to Addressing Anomalies\n",
    "\n",
    "During the data quality assessment, we identified various anomalies within the dataset. Each anomaly was then evaluated to estimate its potential impact on the subsequent analysis. This evaluation process categorized anomalies into four distinct levels of criticality:\n",
    "\n",
    "1. **Critical**: These anomalies have a significant impact on the integrity and reliability of the data. If left unaddressed, they could severely distort the results of any analysis. Examples include duplicate records, non-English text (if the analysis is language-specific), and invalid ratings.\n",
    "\n",
    "2. **High**: High impact anomalies also pose a substantial threat to the validity of the analysis but are slightly less severe than critical issues. These include records with excessive special characters, profanity, and privacy-related issues such as email addresses or phone numbers embedded in the text.\n",
    "\n",
    "3. **Medium**: Medium impact anomalies have a moderate effect on the analysis. While they do not necessarily distort results as severely as critical or high issues, they can still introduce noise and reduce the overall quality of insights. Examples include outliers in vote sums and vote counts, and unusually long reviews.\n",
    "\n",
    "4. **Low**: Low impact anomalies are considered minor issues that have minimal impact on the overall analysis. These include the presence of emojis and URLs in the text, which typically do not affect the analytical outcome significantly.\n",
    "\n",
    "## Removal Criteria\n",
    "\n",
    "Based on the criticality assessment, a systematic approach was adopted to handle these anomalies:\n",
    "\n",
    "- **Critical and High Impact Issues**: Observations containing anomalies classified as critical or high impact were earmarked for removal. The rationale behind this strict approach is to eliminate any potential distortions in the analysis that could arise from these severe issues. By removing these observations, we ensure that the dataset maintains a high level of integrity and reliability.\n",
    "\n",
    "- **Medium and Low Impact Issues**: Anomalies classified as medium or low impact were not grounds for removal of the observations. Instead, these issues were retained in the dataset to preserve as much data as possible while accepting a tolerable level of noise. This approach balances the need for data quality with the necessity of maintaining a sufficient volume of data for robust analysis.\n",
    "\n",
    "## Sorting\n",
    "Reviews are sorted by date to support temporal analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from appvocai-discover.data_prep.clean import DataCleaner, CleanConfig\n",
    "from appvocai-discover.analysis.dqa import DataQualityAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "#                             DataCleaner Pipeline                             #\n",
      "# ============================================================================ #\n",
      "\n",
      "Task ReadTask completed successfully.\n",
      "\n",
      "\n",
      "                            AppInsight Data Cleaning                            \n",
      "                      Original DataFrame | 18306 rows\n",
      "                       Cleaned DataFrame | 15138 rows\n",
      "                    Removed Observations | 3168 rows\n",
      "\n",
      "\n",
      "Task DataCleaningTask completed successfully.\n",
      "Task WriteTask completed successfully.\n",
      "\n",
      "\n",
      "                                  DataCleaner                                   \n",
      "                          Pipeline Start | 2024-06-07 02:51:26.286717\n",
      "                           Pipeline Stop | 2024-06-07 02:51:26.548644\n",
      "                        Pipeline Runtime | 00 Minutes 00.261927 Seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = CleanConfig(force=True)\n",
    "cleaner = DataCleaner(config=config)\n",
    "data_clean = cleaner.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data cleaning stage successfully completed, we have ensured that our dataset is free from critical and high-impact anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "Let's verify that the critical and high impact issues have been addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Duplication\n",
      "Analyzing Duplication by id\n",
      "Analyzing Null Values\n",
      "Analyzing Non-English Reviews\n",
      "Analyzing Non-English Reviews\n",
      "Analyzing Emojis\n",
      "Analyzing Excessive Special Characters\n",
      "Analyzing Invalid Dates\n",
      "Analyzing Invalid Ratings\n",
      "Analyzing Profanity\n",
      "Analyzing Emails in Reviews\n",
      "Analyzing URLs in Reviews\n",
      "Analyzing Phone Numbers in Reviews\n",
      "Analyzing Outliers in vote_count\n",
      "Analyzing Outliers in vote_sum\n",
      "Analyzing Outliers in review_length\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Characteristic</th>\n",
       "      <th>Impact</th>\n",
       "      <th>Count</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Duplicate Values</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duplicate IDs</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Non-English Review</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-English App Name</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Invalid Ratings</td>\n",
       "      <td>Critical</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Null Values</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Excessive Special Characters</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Invalid Dates</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Profanity</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Contains Email Address(es)</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Contains Phone Number(s)</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emojis</td>\n",
       "      <td>Low</td>\n",
       "      <td>610</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Contains URL(s)</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Contains Vote Count Outliers</td>\n",
       "      <td>Medium</td>\n",
       "      <td>821</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Contains Vote Sum Outliers</td>\n",
       "      <td>Medium</td>\n",
       "      <td>622</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Contains Review Length Outliers</td>\n",
       "      <td>Medium</td>\n",
       "      <td>982</td>\n",
       "      <td>6.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Characteristic    Impact  Count  Percent\n",
       "0                  Duplicate Values  Critical      0     0.00\n",
       "1                     Duplicate IDs  Critical      0     0.00\n",
       "3                Non-English Review  Critical      0     0.00\n",
       "4              Non-English App Name  Critical      0     0.00\n",
       "8                   Invalid Ratings  Critical      0     0.00\n",
       "2                       Null Values      High      0     0.00\n",
       "6      Excessive Special Characters      High      0     0.00\n",
       "7                     Invalid Dates      High      0     0.00\n",
       "9                         Profanity      High      0     0.00\n",
       "10       Contains Email Address(es)      High      0     0.00\n",
       "12         Contains Phone Number(s)      High      0     0.00\n",
       "5                            Emojis       Low    610     4.03\n",
       "11                  Contains URL(s)       Low      0     0.00\n",
       "13     Contains Vote Count Outliers    Medium    821     5.42\n",
       "14       Contains Vote Sum Outliers    Medium    622     4.11\n",
       "15  Contains Review Length Outliers    Medium    982     6.49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "analyzer = DataQualityAnalysis()\n",
    "results = analyzer.run_analysis(data=data_clean)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the observations with critical and high impact issues have been removed from the dataset. Next, a spot of feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai-discover",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
