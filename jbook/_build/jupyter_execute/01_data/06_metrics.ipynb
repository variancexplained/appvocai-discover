{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if 'jbook' in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "In this stage, we delve deeper, aggregating and computing vital statistics across multiple dimensions of our dataset. The Metrics Aggregation Stage provides a multi-dimensional overview by aggregating data at various levels: category, author, app, and the combination of category and author. \n",
    "\n",
    "For each level of aggregation, we extract key metrics including counts of reviews, unique authors, and unique apps. Additionally, we compute descriptive statistics on important features such as rating, review length, vote count, vote sum, and date.\n",
    "\n",
    "This approach allows us to gain insights into the distribution and characteristics of reviews across different categories, authors, and apps, providing valuable information for our subsequent analysis and decision-making processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'appvocai-discover.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mappvocai-discover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Metrics, AppMetricsConfig, CategoryAuthorMetricsConfig, AuthorMetricsConfig, CategoryMetricsConfig, CategoryMetricsTask, AuthorMetricsTask, AppMetricsTask, CategoryAuthorMetricsTask\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mappvocai-discover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfrastructure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSessionPool\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mappvocai-discover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Printer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'appvocai-discover.data'"
     ]
    }
   ],
   "source": [
    "from appvocai-discover.data.prep.metrics import Metrics, AppMetricsConfig, CategoryAuthorMetricsConfig, AuthorMetricsConfig, CategoryMetricsConfig, CategoryMetricsTask, AuthorMetricsTask, AppMetricsTask, CategoryAuthorMetricsTask\n",
    "from appvocai-discover.infrastructure.spark.factory import SparkSessionPool\n",
    "from appvocai-discover.utils.print import Printer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You know the drill. We're setting up our Spark session just like before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "factory = SparkSessionPool()\n",
    "spark = factory.build(nlp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Metrics\n",
    "In this section, we review category-level metrics, providing insights into various aspects such as review counts, unique authors, unique apps, and descriptive statistics concerning ratings, review length, vote count, vote sum, and date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CategoryMetricsConfig()\n",
    "metrics = Metrics(config=config, spark=spark, metrics_task_cls=CategoryMetricsTask)\n",
    "category_metrics = metrics.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                Category Metrics                                \n",
      "                                category | Education\n",
      "                               app_count | 300\n",
      "                            author_count | 1040\n",
      "                            review_count | 1040\n",
      "                         reviews_per_app | 3.466666666666667\n",
      "                      reviews_per_author | 1.0\n",
      "                              rating_min | 1\n",
      "                              rating_max | 5\n",
      "                              rating_avg | 3.5913461538461537\n",
      "                             rating_mode | 5\n",
      "                              rating_std | 1.7432178810280476\n",
      "                       review_length_min | 1\n",
      "                       review_length_max | 363\n",
      "                       review_length_avg | 28.556730769230768\n",
      "                      review_length_mode | 2\n",
      "                       review_length_std | 33.72065298611556\n",
      "                          vote_count_min | 0\n",
      "                          vote_count_max | 9\n",
      "                          vote_count_avg | 0.15\n",
      "                         vote_count_mode | 0\n",
      "                          vote_count_std | 0.6482374118019358\n",
      "                            vote_sum_min | 0\n",
      "                            vote_sum_max | 5\n",
      "                            vote_sum_avg | 0.09230769230769231\n",
      "                           vote_sum_mode | 0\n",
      "                            vote_sum_std | 0.4082150416738216\n",
      "                                date_min | 2009-05-25 05:24:45\n",
      "                                date_max | 2023-08-06 14:55:02\n",
      "                               date_mode | 2013-06-25 03:53:40\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category = category_metrics.sample(n=1)\n",
    "Printer().print_dataframe_as_dict(df=category, title=\"Category Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample provides various statistics related to app reviews within a particular category. Key insights include the number of apps and authors, the range and distribution of ratings, review lengths, and vote counts. \n",
    "\n",
    "The metrics outline the total number of apps and authors involved in the reviews for the category. It also highlights the minimum, maximum, average, and most common values for ratings, showing how users generally perceive the apps in this category. Additionally, the standard deviation offers insight into the variability of these ratings.\n",
    "\n",
    "Review length statistics are included, describing the shortest and longest reviews, the average review length, the most frequent review length, and the variability in review length. \n",
    "\n",
    "Vote counts and sums are detailed, presenting the spread and commonality of votes received by reviews. The dataset also captures the range of dates during which the reviews were submitted, providing a timeframe for the data collection.\n",
    "\n",
    "Overall, these statistics help in understanding user engagement and satisfaction within the selected app category, as well as the distribution and variability of reviews over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Metrics\n",
    "Building on the category-level metrics, author-level metrics provide a more granular view of individual reviewers' behaviors and contributions. These metrics include the total number of reviews each author has submitted, the distribution of their ratings, and the lengths of their reviews. Additionally, author-level metrics capture the number of votes their reviews receive, both individually and in aggregate. This helps in understanding patterns in reviewer activity, the consistency of their feedback, and the reception of their reviews by the community, complementing the broader insights gained from the category-level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "#                            AuthorMetrics Pipeline                            #\n",
      "# ============================================================================ #\n",
      "\n",
      "Task Reader completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ConvertTask completed successfully.\n",
      "Task AuthorMetricsTask completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ConvertTask completed successfully.\n",
      "Task Writer completed successfully.\n",
      "\n",
      "\n",
      "                                 AuthorMetrics                                  \n",
      "                          Pipeline Start | 2024-06-03 13:40:11.227942\n",
      "                           Pipeline Stop | 2024-06-03 13:40:27.873968\n",
      "                        Pipeline Runtime | 00 Minutes 16.646026 Seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AuthorMetricsConfig()\n",
    "metrics = Metrics(config=config, spark=spark, metrics_task_cls=AuthorMetricsTask)\n",
    "author_metrics = metrics.execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull a sample from authors that have 2 or more reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                 Author Metrics                                 \n",
      "                                  author | 010551c7268306b0e116\n",
      "                                category | 2\n",
      "                               app_count | 2\n",
      "                            review_count | 2\n",
      "                         reviews_per_app | 1.0\n",
      "                    reviews_per_category | 1.0\n",
      "                              rating_min | 5\n",
      "                              rating_max | 5\n",
      "                              rating_avg | 5.0\n",
      "                             rating_mode | 5\n",
      "                              rating_std | 0.0\n",
      "                       review_length_min | 4\n",
      "                       review_length_max | 34\n",
      "                       review_length_avg | 19.0\n",
      "                      review_length_mode | 34\n",
      "                       review_length_std | 21.213203435596427\n",
      "                          vote_count_min | 0\n",
      "                          vote_count_max | 0\n",
      "                          vote_count_avg | 0.0\n",
      "                         vote_count_mode | 0\n",
      "                          vote_count_std | 0.0\n",
      "                            vote_sum_min | 0\n",
      "                            vote_sum_max | 0\n",
      "                            vote_sum_avg | 0.0\n",
      "                           vote_sum_mode | 0\n",
      "                            vote_sum_std | 0.0\n",
      "                                date_min | 2015-08-11 04:19:48\n",
      "                                date_max | 2015-11-18 00:13:57\n",
      "                               date_mode | 2015-08-11 04:19:48\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "author = author_metrics.loc[author_metrics[\"review_count\"]>1]\n",
    "author = author.sample(n=1)\n",
    "Printer().print_dataframe_as_dict(df=author, title=\"Author Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample reveals that author-level metrics provide a more granular view of individual reviewer behaviors. It details the number of reviews the author has submitted, the distribution and variability of their ratings, and the lengths of their reviews. Additionally, these metrics capture the number of votes their reviews receive, both individually and in total. This deeper analysis helps reveal patterns in reviewer activity, consistency in their feedback, and how their reviews are received by the community, complementing the broader trends observed at the category level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Metrics\n",
    "Following the insights from the author metrics, let's now transition to exploring the characteristics of individual apps. Through app-level metrics, we can gain deeper insights into the performance, user engagement, and features of specific applications within the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "#                             AppMetrics Pipeline                              #\n",
      "# ============================================================================ #\n",
      "\n",
      "Task Reader completed successfully.\n",
      "Task ConvertTask completed successfully.\n",
      "Task AppMetricsTask completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ConvertTask completed successfully.\n",
      "Task Writer completed successfully.\n",
      "\n",
      "\n",
      "                                   AppMetrics                                   \n",
      "                          Pipeline Start | 2024-06-03 13:40:27.935439\n",
      "                           Pipeline Stop | 2024-06-03 13:40:32.010320\n",
      "                        Pipeline Runtime | 00 Minutes 04.074881 Seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AppMetricsConfig()\n",
    "metrics = Metrics(config=config, spark=spark, metrics_task_cls=AppMetricsTask)\n",
    "app_metrics = metrics.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a sample of an app with two or more reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                  App Metrics                                   \n",
      "                                app_name | ShopShop - Shopping List\n",
      "                            author_count | 4\n",
      "                            review_count | 4\n",
      "                      reviews_per_author | 1.0\n",
      "                              rating_min | 3\n",
      "                              rating_max | 5\n",
      "                              rating_avg | 4.0\n",
      "                             rating_mode | 4\n",
      "                              rating_std | 0.816496580927726\n",
      "                       review_length_min | 11\n",
      "                       review_length_max | 67\n",
      "                       review_length_avg | 32.0\n",
      "                      review_length_mode | 11\n",
      "                       review_length_std | 25.85858980429263\n",
      "                          vote_count_min | 0\n",
      "                          vote_count_max | 0\n",
      "                          vote_count_avg | 0.0\n",
      "                         vote_count_mode | 0\n",
      "                          vote_count_std | 0.0\n",
      "                            vote_sum_min | 0\n",
      "                            vote_sum_max | 0\n",
      "                            vote_sum_avg | 0.0\n",
      "                           vote_sum_mode | 0\n",
      "                            vote_sum_std | 0.0\n",
      "                                date_min | 2008-12-24 03:50:07\n",
      "                                date_max | 2022-12-30 00:41:58\n",
      "                               date_mode | 2008-12-24 03:50:07\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "app = app_metrics.loc[app_metrics[\"review_count\"]>1]\n",
    "app = app.sample(n=1)\n",
    "Printer().print_dataframe_as_dict(df=app, title=\"App Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample illustrates the app-level metrics, providing detailed insights into individual applications. These metrics encompass various aspects such as the number of authors associated with each app, the total number of reviews received, the distribution of reviews per author, and detailed rating information including minimum, maximum, average, and mode ratings. Additionally, it includes statistics on the lengths of reviews, the number of votes received, and the timeframe during which the reviews were submitted for each app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category and Author Metrics\n",
    "Now, let's wrap up our analysis by combining the insights from both category-level and author-level metrics. By synthesizing these comprehensive sets of statistics, we can gain a holistic understanding of the category's landscape, and individual author behaviors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CategoryAuthorMetricsConfig()\n",
    "metrics = Metrics(config=config, spark=spark, metrics_task_cls=CategoryAuthorMetricsTask)\n",
    "category_author_metrics = metrics.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, let's inspect a sample of an author that has two or more reviews within a category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                            Category/Author Metrics                             \n",
      "                                category | Social Networking\n",
      "                                  author | 7402e6f4591082ddf333\n",
      "                               app_count | 2\n",
      "                            review_count | 2\n",
      "                         reviews_per_app | 1.0\n",
      "                              rating_min | 1\n",
      "                              rating_max | 5\n",
      "                              rating_avg | 3.0\n",
      "                             rating_mode | 1\n",
      "                              rating_std | 2.8284271247461903\n",
      "                       review_length_min | 4\n",
      "                       review_length_max | 23\n",
      "                       review_length_avg | 13.5\n",
      "                      review_length_mode | 4\n",
      "                       review_length_std | 13.435028842544403\n",
      "                          vote_count_min | 0\n",
      "                          vote_count_max | 0\n",
      "                          vote_count_avg | 0.0\n",
      "                         vote_count_mode | 0\n",
      "                          vote_count_std | 0.0\n",
      "                            vote_sum_min | 0\n",
      "                            vote_sum_max | 0\n",
      "                            vote_sum_avg | 0.0\n",
      "                           vote_sum_mode | 0\n",
      "                            vote_sum_std | 0.0\n",
      "                                date_min | 2022-01-31 22:48:27\n",
      "                                date_max | 2022-05-02 19:27:22\n",
      "                               date_mode | 2022-01-31 22:48:27\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_author = category_author_metrics.loc[category_author_metrics[\"review_count\"]>1]\n",
    "category_author = category_author.sample(n=1)\n",
    "Printer().print_dataframe_as_dict(df=category_author, title=\"Category/Author Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample provides a detailed overview of specific authors within the Social Networking category. Each row represents a distinct author and their interactions within this category. The metrics encompass various aspects such as the number of apps and reviews associated with each author within a category, the range and distribution of ratings, the lengths of their reviews, and voting activity. Analyzing these metrics at the category and author level offers insights into individual user behavior and contributions within the each category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai-discover",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}