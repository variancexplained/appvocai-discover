#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# ================================================================================================ #
# Project    : AppVoCAI-Discover                                                                   #
# Version    : 0.1.0                                                                               #
# Python     : 3.10.14                                                                             #
# Filename   : /discover/flow/feature/tqa/syntactic/task.py                                        #
# ------------------------------------------------------------------------------------------------ #
# Author     : John James                                                                          #
# Email      : john@variancexplained.com                                                           #
# URL        : https://github.com/variancexplained/appvocai-discover                               #
# ------------------------------------------------------------------------------------------------ #
# Created    : Sunday January 19th 2025 11:53:03 am                                                #
# Modified   : Sunday January 19th 2025 05:54:11 pm                                                #
# ------------------------------------------------------------------------------------------------ #
# License    : MIT License                                                                         #
# Copyright  : (c) 2025 John James                                                                 #
# ================================================================================================ #
"""Syntactic Text Quality Analysis Task Module"""
import logging

import pyspark.sql.functions as F
from pyspark.sql import DataFrame
from pyspark.sql.types import ArrayType, IntegerType

from discover.flow.base.task import Task
from discover.infra.service.logging.task import task_logger

# ------------------------------------------------------------------------------------------------ #
#                                    PHRASE COUNTS                                                 #
# ------------------------------------------------------------------------------------------------ #


class PhraseCount(Task):
    """Counts phrases extracted by a Spark NLP Chunker.

    This class takes a DataFrame with a column containing arrays of phrases (e.g.,
    noun phrases, verb phrases) generated by a Spark NLP Chunker and adds a new
    column with the count of those phrases for each row. Optionally, the counts
    can be log-normalized.

    Attributes:
        _column (str): The name of the column containing the phrase arrays.
        _new_column (str): The name of the new column to store the phrase counts.
        _normalized (bool): Whether to log-normalize the counts (default: True).
        _logger (logging.Logger): Logger instance for the class.

    Args:
        column (str): The name of the column containing the phrase arrays.
        new_column (str): The name of the new column to store the phrase counts.
        normalized (bool, optional): Whether to log-normalize the counts. Defaults to True.

    Raises:
        ValueError: If the specified `column` is not found in the DataFrame.
        TypeError: If the specified `column` is not an array type.

    """

    def __init__(
        self,
        column: str,
        new_column: str,
        normalized: bool = True,
        **kwargs,
    ) -> None:
        super().__init__(**kwargs)
        self._column = column
        self._new_column = new_column
        self._normalized = normalized
        self._kwargs = kwargs

        self._logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

    @task_logger
    def run(self, data: DataFrame) -> DataFrame:
        """Counts phrases and adds the counts to a new column.

        This method counts the number of phrases in the specified column of the
        input DataFrame and adds a new column containing these counts. The counts
        can be optionally log-normalized by adding 1 to the count before taking
        the logarithm.

        Args:
            data (DataFrame): A Spark DataFrame containing the phrase arrays.

        Returns:
            DataFrame: The input DataFrame with an additional column containing
                the phrase counts.

        """

        if self._column not in data.columns:
            raise ValueError(f"Column '{self._column}' not found in DataFrame.")

        if not isinstance(
            data.schema[self._column].dataType, ArrayType
        ):  # Check if column is array. Not strictly necessary but good practice
            raise TypeError(f"Column '{self._column}' is not an array type.")

        data = data.withColumn(
            self._new_column, F.size(F.col(self._column))
        ).withColumn(self._new_column, F.col(self._new_column).cast(IntegerType()))

        if self._normalized:
            data = data.withColumn(self._new_column, F.log(F.col(self._new_column) + 1))

        return data


# ------------------------------------------------------------------------------------------------ #
class NounPhraseCount(PhraseCount):
    def __init__(self, column, new_column, normalized=True, **kwargs):
        super().__init__(column, new_column, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
class AdjectiveNounPairCount(PhraseCount):
    def __init__(self, column, new_column, normalized=True, **kwargs):
        super().__init__(column, new_column, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
class AspectVerbPairCount(PhraseCount):
    def __init__(self, column, new_column, normalized=True, **kwargs):
        super().__init__(column, new_column, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
class AdverbPhraseCount(PhraseCount):
    def __init__(self, column, new_column, normalized=True, **kwargs):
        super().__init__(column, new_column, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
#                                      POS COUNTS                                                  #
# ------------------------------------------------------------------------------------------------ #
class POSCount(Task):
    """Counts occurrences of a specific POS tag in a DataFrame column.

    This class takes a DataFrame with a column containing arrays of POS tags
    and adds a new column with the count of a specified POS tag. The counts
    can be optionally log-normalized.

    Attributes:
        _column (str): The name of the column containing the POS tag arrays.
        _new_column (str): The name of the new column to store the POS tag counts.
        _pos (str): The POS tag to count (e.g., "NN", "VB", "JJ").
        _normalized (bool): Whether to log-normalize the counts (default: True).
        _logger (logging.Logger): Logger instance for the class.

    Args:
        column (str): The name of the column containing the POS tag arrays.
        new_column (str): The name of the new column to store the POS tag counts.
        pos (str): The POS tag to count (e.g., "NN", "VB", "JJ").
        normalized (bool, optional): Whether to log-normalize the counts. Defaults to True.

    Raises:
        ValueError: If the specified `column` is not found in the DataFrame.
        TypeError: If the specified `column` is not an array type.
    """

    def __init__(
        self, column: str, new_column: str, pos: str, normalized: bool = True, **kwargs
    ):
        super().__init__(**kwargs)
        self._column = column
        self._new_column = new_column
        self._pos = pos
        self._normalized = normalized
        self._logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")

    @task_logger
    def run(self, data: DataFrame) -> DataFrame:
        """Counts POS tags and adds the counts to a new column.

        This method counts the occurrences of the specified POS tag in the
        given column of the input DataFrame and adds a new column containing
        these counts. The counts can be optionally log-normalized.

        Args:
            data (DataFrame): A Spark DataFrame containing the POS tag arrays.

        Returns:
            DataFrame: The input DataFrame with an additional column containing
                the POS tag counts.
        """
        if self._column not in data.columns:
            raise ValueError(f"Column '{self._column}' not found in DataFrame.")

        if not isinstance(data.schema[self._column].dataType, ArrayType):
            raise TypeError(f"Column '{self._column}' is not an array type.")

        # Count occurrences of the specific POS tag
        data = data.withColumn(
            self._new_column,
            F.aggregate(
                F.col(self._column),
                F.lit(0),
                lambda acc, x: acc
                + F.when(x.result.startswith(self._pos), 1).otherwise(0),
            ).cast(IntegerType()),
        )

        if self._normalized:
            data = data.withColumn(self._new_column, F.log(F.col(self._new_column) + 1))

        return data


# ------------------------------------------------------------------------------------------------ #
class NounCount(POSCount):
    def __init__(self, column, new_column, pos, normalized=True, **kwargs):
        super().__init__(column, new_column, pos, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
class VerbCount(POSCount):
    def __init__(self, column, new_column, pos, normalized=True, **kwargs):
        super().__init__(column, new_column, pos, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
class AdverbCount(POSCount):
    def __init__(self, column, new_column, pos, normalized=True, **kwargs):
        super().__init__(column, new_column, pos, normalized, **kwargs)


# ------------------------------------------------------------------------------------------------ #
class AdjectiveCount(POSCount):
    def __init__(self, column, new_column, pos, normalized=True, **kwargs):
        super().__init__(column, new_column, pos, normalized, **kwargs)
