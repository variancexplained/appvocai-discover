{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification\n",
    "This stage leverages a **DistilBERT-based Sentiment Classification Model**, specifically the `tabularisai/robust-sentiment-analysis` model, to perform sentiment analysis. The goal is to efficiently analyze and classify sentiment within a dataset for the purposes of **Data Quality Assessment (DQA)** and **Exploratory Data Analysis (EDA)**. \n",
    "\n",
    "## Model Overview\n",
    "- **Model Name**: `tabularisai/robust-sentiment-analysis`\n",
    "- **Base Model**: `distilbert/distilbert-base-uncased`\n",
    "- **Task**: Text Classification (Sentiment Analysis)\n",
    "- **Language**: English\n",
    "- **Number of Classes**: 5 sentiment categories:\n",
    "  - **Very Negative**\n",
    "  - **Negative**\n",
    "  - **Neutral**\n",
    "  - **Positive**\n",
    "  - **Very Positive**\n",
    "\n",
    "## Model Description\n",
    "This model is a fine-tuned version of `distilbert-base-uncased`, optimized for sentiment analysis using synthetic data generated by cutting-edge language models like **Llama3.1** and **Gemma2**. By training exclusively on synthetic data, the model has been exposed to a diverse range of sentiment expressions, which enhances its ability to generalize across different use cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'deserialize_dataset_config' from 'discover.flow.stage.base' (/home/john/projects/appvocai-discover/discover/flow/stage/base.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msetup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m auto_wire_container\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentClassificationStage\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PhaseEnum, DataEnrichmentStageEnum\n",
      "File \u001b[0;32m~/projects/appvocai-discover/discover/setup.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetFactory\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiscoverContainer\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_dataset_config\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AppConfigReader\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfra\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkspace\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WorkspaceService\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deserialize_dataset_config' from 'discover.flow.stage.base' (/home/john/projects/appvocai-discover/discover/flow/stage/base.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from discover.setup import auto_wire_container\n",
    "from discover.flow.stage.model.sentiment import SentimentClassificationStage\n",
    "from discover.core.flow import PhaseEnum, DataEnrichmentStageEnum\n",
    "from discover.infra.config.flow import FlowConfigReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Register `tqdm` with pandas\n",
    "tqdm.pandas()\n",
    "# Wire container\n",
    "container = auto_wire_container()\n",
    "# Pandas\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Task\n",
    "The `SentimentClassificationTask` class performs sentiment analysis on text data using the `tabularisai/robust-sentiment-analysis` pre-trained transformer model. It is built to handle large-scale text data efficiently and is optimized for execution on GPU when available.\n",
    "\n",
    "**Key Technical Aspects**:\n",
    "\n",
    "1. **Model Loading**: The transformer is loaded using the Hugging Face `transformers` library, leveraging both the `AutoTokenizer` for text tokenization and `AutoModelForSequenceClassification` for sentiment classification.\n",
    "2. **Hardware Optimization**: The class supports GPU acceleration through PyTorch. It checks for the availability of a CUDA-compatible GPU and moves the model and data to the GPU if available. This significantly speeds up inference, making it suitable for large datasets.\n",
    "3. **Text Preprocessing and Tokenization**: Text data is preprocessed and tokenized using the `AutoTokenizer`, which converts text into input tensors that the model can process. The inputs are truncated or padded to a maximum sequence length of 512 tokens, ensuring consistency in input size.\n",
    "4. **Memory Management**: The class uses `torch.cuda.empty_cache()` to clear CUDA memory before loading the model, optimizing memory usage and preventing potential out-of-memory errors on the GPU.\n",
    "5. **Sentiment Prediction**: The `predict_sentiment` method performs inference using `torch.no_grad()` to disable gradient calculation, reducing memory consumption and speeding up computations. It calculates class probabilities using the `softmax` function and maps the predicted class index to a sentiment label.\n",
    "6. **Caching Mechanism**: The class constructs a cache file path using environment-specific settings, making it possible to store and reuse sentiment analysis results efficiently. This can help avoid redundant computations and improve the overall performance of the data pipeline.\n",
    "7. **Integration with DataFrames**: The class operates on pandas DataFrames, applying sentiment analysis to each entry in the specified text column using the `progress_apply` method, which provides a progress bar for monitoring the processing status.\n",
    "\n",
    "The code is included in the following expandable cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 19-210 discover/flow/task/model/sentiment.py\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from discover.flow.task.base import Task\n",
    "from discover.infra.service.logging.task import task_logger\n",
    "from discover.infra.utils.file.io import IOService\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class SentimentClassificationTask(Task):\n",
    "    \"\"\"\n",
    "    Task for performing sentiment analysis on text data in a specified column of a Pandas DataFrame.\n",
    "\n",
    "    This task uses a pre-trained model to predict sentiment for text in the specified column and\n",
    "    stores the sentiment predictions in a new column. Results are cached to a file to avoid reprocessing.\n",
    "    It supports execution on GPUs or local devices depending on the configuration.\n",
    "\n",
    "    Args:\n",
    "        cache_filepath (str): Path to the cache file for storing or loading sentiment predictions.\n",
    "        column (str): The name of the column in the DataFrame containing text data for sentiment analysis.\n",
    "            Defaults to \"content\".\n",
    "        new_column (str): The name of the column to store sentiment predictions. Defaults to \"sentiment\".\n",
    "        model_name (str): The name of the pre-trained model to use for sentiment analysis. Defaults to\n",
    "            \"tabularisai/robust-sentiment-analysis\".\n",
    "        device_local (bool): Indicates whether to execute the task on local devices. Defaults to False.\n",
    "\n",
    "    Methods:\n",
    "        run(data: pd.DataFrame) -> pd.DataFrame:\n",
    "            Executes the sentiment analysis task, using a cache if available. If not, it predicts sentiment\n",
    "            for the text column and caches the results.\n",
    "        predict_sentiment(text: str) -> str:\n",
    "            Predicts sentiment for a given text string.\n",
    "        _load_model_tokenizer_to_device() -> None:\n",
    "            Loads the model, tokenizer, and device for performing sentiment analysis.\n",
    "        _run(data: pd.DataFrame) -> pd.DataFrame:\n",
    "            Executes the model inference for sentiment prediction and writes the results to the cache.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cache_filepath: str,\n",
    "        column=\"content\",\n",
    "        new_column=\"sentiment\",\n",
    "        model_name: str = \"tabularisai/robust-sentiment-analysis\",\n",
    "        device_local: bool = False,\n",
    "        io_cls: type[IOService] = IOService,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self._column = column\n",
    "        self._new_column = f\"{self.stage.id}_{new_column}\"\n",
    "        self._model_name = model_name\n",
    "        self._cache_filepath = cache_filepath\n",
    "        self._device_local = device_local\n",
    "        self._io = io_cls()\n",
    "\n",
    "        # Model, tokenizer, and device are initialized as None and will be loaded later\n",
    "        self._model = None\n",
    "        self._tokenizer = None\n",
    "        self._device = None\n",
    "\n",
    "    @task_logger\n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Executes the sentiment analysis task on the input DataFrame.\n",
    "\n",
    "        This method first attempts to read sentiment predictions from a cache file. If the cache\n",
    "        is not available or not valid, it performs sentiment analysis using the pre-trained model\n",
    "        and writes the results to the cache. Sentiment predictions are stored in the specified\n",
    "        `new_column` of the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input DataFrame containing the text data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with sentiment predictions added to the specified column.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the cache is not found or the task is run locally without a GPU.\n",
    "            Exception: For any other unexpected errors.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cache = self._io.read(filepath=self._cache_filepath, lineterminator=\"\\n\")\n",
    "            cache[\"id\"] = cache[\"id\"].astype(\"string\")\n",
    "            data = data.merge(cache[[\"id\", self._new_column]], how=\"left\", on=\"id\")\n",
    "            return data\n",
    "        except (FileNotFoundError, TypeError):\n",
    "            if self._device_local:\n",
    "                return self._run(data=data)\n",
    "            else:\n",
    "                msg = (\n",
    "                    f\"Cache not found or not available. {self.__class__.__name__} is not \"\n",
    "                    \"supported on local devices. Try running on Kaggle, Colab, or AWS.\"\n",
    "                )\n",
    "                self._logger.error(msg)\n",
    "                raise FileNotFoundError(msg)\n",
    "        except Exception as e:\n",
    "            msg = f\"Unknown exception encountered.\\n{e}\"\n",
    "            self._logger.exception(msg)\n",
    "            raise\n",
    "\n",
    "    def _run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Executes model inference for sentiment analysis and writes results to the cache.\n",
    "\n",
    "        This method processes the input DataFrame by applying sentiment predictions for each entry\n",
    "        in the specified text column. It uses parallel processing for efficient computation and\n",
    "        writes the results to the cache file.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input DataFrame containing the text data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with sentiment predictions added to the specified column.\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()  # Clear CUDA memory to ensure sufficient space\n",
    "\n",
    "        # Load the device, model, and tokenizer\n",
    "        self._load_model_tokenizer_to_device()\n",
    "\n",
    "        # Apply sentiment prediction to each text entry\n",
    "        data[self._new_column] = data[self._column].progress_apply(\n",
    "            self.predict_sentiment\n",
    "        )\n",
    "\n",
    "        # Write results to the cache file\n",
    "        self._write_file(\n",
    "            filepath=self._cache_filepath, data=data[[\"id\", self._new_column]]\n",
    "        )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def predict_sentiment(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Predicts the sentiment of a given text string.\n",
    "\n",
    "        This method uses the loaded model and tokenizer to predict the sentiment of the input\n",
    "        text. It maps the model's output to a sentiment label.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text string.\n",
    "\n",
    "        Returns:\n",
    "            str: The predicted sentiment label, e.g., \"Positive\", \"Negative\", or \"Neutral\".\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            inputs = self._tokenizer(\n",
    "                text.lower(),\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "            )\n",
    "            inputs = {key: value.to(self._device) for key, value in inputs.items()}\n",
    "            outputs = self._model(**inputs)\n",
    "            probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "        sentiment_map = {\n",
    "            0: \"Very Negative\",\n",
    "            1: \"Negative\",\n",
    "            2: \"Neutral\",\n",
    "            3: \"Positive\",\n",
    "            4: \"Very Positive\",\n",
    "        }\n",
    "        return sentiment_map[predicted_class]\n",
    "\n",
    "    def _load_model_tokenizer_to_device(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the pre-trained model, tokenizer, and device for sentiment analysis.\n",
    "\n",
    "        This method selects the appropriate device (GPU or CPU), loads the tokenizer and model\n",
    "        based on the specified model name, and moves the model to the selected device.\n",
    "        \"\"\"\n",
    "        self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(self._model_name)\n",
    "        self._model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self._model_name\n",
    "        )\n",
    "        self._model.to(self._device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Pipeline\n",
    "Similar to the previous Ingestion pipeline, we obtain the configuration using `FlowConfigReader` and set up the `SentimentClassificationStage` with the specified phase and stage definitions. The stage is then built and executed, with the `asset_id` capturing the resulting data asset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseEnum.ENRICHMENT, stage=DataEnrichmentStageEnum.SENTIMENT\n",
    ")\n",
    "\n",
    "# Build and run Data Sentiment Analysis Stage\n",
    "stage = SentimentClassificationStage.build(stage_config=stage_config, force=FORCE)\n",
    "dataset = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Results\n",
    "This sample illustrates sentiment vis-a-vis ratings, revealing the complexity and nuance in user opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_pandas()[[\"id\", \"content\", \"rating\", \"en_sentiment\"]].sample(\n",
    "    n=5, random_state=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Sentiment vs. Ratings\n",
    "1. **Entry 1: Mooncycle**\n",
    "   - **Rating**: 4\n",
    "   - **Sentiment Analysis**: Very Positive\n",
    "   - **Comment**: The user provided a high rating (4 stars), and the sentiment analysis correctly identified a very positive sentiment. This indicates a good match between the expressed sentiment and the user's rating.\n",
    "\n",
    "2. **Entry 2: Privacy Concern**\n",
    "   - **Rating**: 3\n",
    "   - **Sentiment Analysis**: Neutral\n",
    "   - **Comment**: The review mentions significant concerns about privacy features but still gives a moderate rating of 3 stars. The sentiment analysis classified this as Neutral, which seems reasonable given the mix of positive and negative feedback. However, one might argue that a \"Slightly Negative\" label could better capture the overall tone.\n",
    "\n",
    "3. **Entry 3: Survey Payouts**\n",
    "   - **Rating**: 3\n",
    "   - **Sentiment Analysis**: Negative\n",
    "   - **Comment**: The user was disappointed with survey payouts, rating the experience as 3 stars. The sentiment analysis classified this as Negative, which reflects the user's dissatisfaction. The rating, however, seems higher than expected for a purely negative sentiment, suggesting potential leniency or mixed feelings not fully captured by the text.\n",
    "\n",
    "4. **Entry 4: Instagram Censorship**\n",
    "   - **Rating**: 1\n",
    "   - **Sentiment Analysis**: Very Negative\n",
    "   - **Comment**: This review strongly criticizes Instagram's content policies, and the user gave the lowest possible rating (1 star). The sentiment analysis accurately labeled this as Very Negative, showing a clear alignment between sentiment and rating.\n",
    "\n",
    "5. **Entry 5: Informative App**\n",
    "   - **Rating**: 5\n",
    "   - **Sentiment Analysis**: Very Positive\n",
    "   - **Comment**: The review is overwhelmingly positive, emphasizing the app's usefulness and unique features, and the user gave a 5-star rating. The sentiment analysis correctly labeled it as Very Positive, demonstrating alignment between the rating and sentiment.\n",
    "\n",
    "### Observations\n",
    "- **Alignment**: In most cases, the sentiment analysis aligns well with the user ratings. Positive sentiments correlate with higher ratings, while negative sentiments correspond to lower ratings.\n",
    "- **Mixed Reviews**: The Neutral sentiment for the privacy concern review highlights the complexity of mixed feedback, where both positives and negatives are present. This might require more nuanced classification.\n",
    "- **Alignment Between Sentiment and Rating**: In most cases, there is alignment between the sentiment analysis and user ratings. For instance, Very Positive sentiments are generally accompanied by high ratings (4 or 5), and Very Negative sentiments align with the lowest rating of 1.\n",
    "- **Neutral Sentiment vs. Moderate Rating**: For reviews with Neutral or Negative sentiment (Ratings: 3), the ratings reflect appreciation for the app's core value but reveal dissatisfaction with specific features or limitations.\n",
    "- **Sentiment Outliers**: No significant mismatches are observed here, suggesting that the sentiment analysis accurately reflects the reviewer’s stance in this sample. However, cases like Review 2 highlight how neutral sentiments can still accompany moderate ratings due to unfulfilled expectations.\n",
    "\n",
    "This analysis indicates that sentiment analysis can generally align well with user ratings, offering insights into specific areas of dissatisfaction or satisfaction that might otherwise be missed in numerical ratings alone.\n",
    "\n",
    "In the next section, we evaluate data quality and requirements for data cleaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
