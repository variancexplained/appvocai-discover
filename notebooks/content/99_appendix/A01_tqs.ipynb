{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(appendix:tqs)\n",
    "# Text Quality Scoring Method \n",
    "The **Text Quality Scoring Method** is designed to assess the quality of textual content by combining two weighted components that capture distinct aspects of linguistic quality: **Syntactic Complexity** and **Perplexity**.\n",
    "\n",
    "1. **Syntactic Complexity Score**:\n",
    "   - This component evaluates the structural richness of the text, focusing on aspects like **Part-of-Speech (POS) density, POS diversity, and sentence structure complexity**. By examining syntactic elements, this score captures how linguistically complex and detailed a text is.\n",
    "   - A high Syntactic Complexity Score typically indicates a text rich in linguistic features, with varied sentence structures and a well-balanced mix of nouns, verbs, and modifiers (like adjectives and adverbs). This variety is particularly valuable for tasks like Aspect-Based Sentiment Analysis (ABSA), where structural complexity can signal content with nuanced aspects and sentiments.\n",
    "\n",
    "2. **Perplexity-Based Score**:\n",
    "   - The Perplexity-Based Score measures the **predictability and coherence** of the text from the perspective of a language model. It reflects how well the text aligns with natural language patterns, as determined by a pre-trained model (e.g., GPT).\n",
    "   - Lower perplexity implies higher fluency, coherence, and grammatical correctness, which are key indicators of text quality. This component is useful for flagging low-quality or noisy text that may be unpredictable or deviate significantly from standard linguistic norms.\n",
    "\n",
    "### Weighted Scoring Approach\n",
    "\n",
    "To create a balanced quality score, the Syntactic Complexity Score and Perplexity-Based Score are combined with tailored weights that emphasize their respective strengths. \n",
    "\n",
    "- **Syntactic Complexity Weight**: Typically given more weight when the task demands detailed and linguistically rich text, such as ABSA, where richer syntactic content improves aspect and sentiment extraction.\n",
    "- **Perplexity-Based Weight**: Often assigned a moderate weight to capture coherence and fluency, ensuring that only grammatically sound and predictable text is prioritized without sacrificing syntactic diversity.\n",
    "\n",
    "The final **Text Quality Score** is a weighted average of these two components, providing a single score that balances both syntactic richness and linguistic fluency. This composite score helps to prioritize high-quality text for downstream tasks, improving model performance by ensuring that selected text is both structurally complex and coherent. \n",
    "\n",
    "---\n",
    "\n",
    "This approach ensures that the scoring method is robust, versatile, and aligned with the requirements of complex text analysis tasks like aspect-based sentiment analysis.\n",
    "\n",
    "In Aspect-Based Sentiment Analysis (ABSA), high-quality text enables models to accurately parse and infer nuanced sentiment across diverse aspects, particularly within user-generated content such as app reviews. To maximize ABSA efficacy, reviews should exhibit richness in lexical diversity, structural depth, sentiment clarity, and readability. \n",
    "\n",
    "Here, we present a text quality scoring framework that leverages multiple linguistic and structural dimensions to filter app reviews, ensuring that only those meeting high-quality standards are selected for analysis. \n",
    "\n",
    "### Quality Scoring Framework\n",
    "The framework assigns a weighted quality score to each review based on six key components:\n",
    "1. **POS Count (Content Volume)**\n",
    "2. **POS Diversity (Lexical Variety)**\n",
    "3. **Structural Complexity**\n",
    "4. **POS Intensity (Sentiment Focus)**\n",
    "5. **Readability**\n",
    "6. **TQA Check (Formal Quality Indicators)**\n",
    "\n",
    "Each component contributes to a comprehensive understanding of review quality, reflecting various linguistic and stylistic aspects that support ABSA objectives.\n",
    "\n",
    "### Overall Quality Score Formula\n",
    "\n",
    "The quality score \\( Q \\) is defined as follows:\n",
    "\n",
    "$$\n",
    "Q = w_1 \\times \\text{POS Count} + w_2 \\times \\text{POS Diversity} + w_3 \\times \\text{Structural Complexity} + w_4 \\times \\text{POS Intensity} + w_5 \\times \\text{Readability} + w_6 \\times \\text{TQA Check}\n",
    "$$\n",
    "\n",
    "where $( w_1, w_2, w_3, w_4, w_5)$, and $(w_6)$ are weights representing the relative importance of each component. The weights are calibrated to prioritize content-rich reviews conducive to multi-aspect sentiment inference.\n",
    "\n",
    "#### Weight Allocation and Justification\n",
    "\n",
    "The framework prioritizes **POS Count** due to its direct correlation with ABSA goals. POS Count holds the highest weight, as it ensures sufficient lexical volume, enabling richer and more varied sentiment and aspect extraction. POS Diversity and Structural Complexity are also assigned significant weights, as they enhance the scope and depth of analysis by ensuring reviews cover multiple aspects with well-structured expression. POS Intensity, Readability, and TQA Check receive supporting weights, contributing to focus, interpretability, and quality consistency without disproportionately influencing the quality assessment.\n",
    "\n",
    "### Components and Calculation\n",
    "\n",
    "Each component is designed to capture a specific dimension of review quality, relevant to ABSA’s emphasis on aspect coverage, sentiment clarity, and text readability.\n",
    "\n",
    "#### 1. POS Count (Content Volume) — $(w_1 = 0.4)$\n",
    "\n",
    "**Definition**: POS Count is a measure of the absolute quantity of content-bearing parts of speech, specifically nouns, verbs, adjectives, and adverbs. This component prioritizes reviews with a substantial volume of lexical material, directly supporting ABSA tasks by providing sufficient substance for identifying aspects and inferring nuanced sentiment.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{POS Count} = \\text{nouns} + \\text{verbs} + \\text{adjectives} + \\text{adverbs}\n",
    "$$\n",
    "\n",
    "**Rationale**: In the context of ABSA, reviews with high POS Count are more likely to provide in-depth feedback, encompassing multiple app features and varied sentiment. This component, weighted at 0.3, serves as the primary driver of the quality score, reflecting its fundamental role in content adequacy.\n",
    "\n",
    "#### 2. POS Diversity (Lexical Variety) — $( w_2 = 0.2 )$\n",
    "\n",
    "**Definition**: POS Diversity assesses the variety and balance of POS tags within the text. It calculates how evenly nouns, verbs, adjectives, and adverbs are distributed, using a normalized entropy score to reflect balance across content-bearing parts of speech.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{POS Diversity} = - \\sum_{i} \\left( p_{i} \\times \\log(p_{i}) \\right)\n",
    "$$\n",
    "where \\( p_i \\) represents the proportion of each POS type (nouns, verbs, adjectives, adverbs) within the text.\n",
    "\n",
    "**Rationale**: Lexical variety enhances ABSA performance by increasing the probability that multiple aspects and sentiments are represented. Reviews with balanced POS usage are more likely to contain a mixture of descriptive, evaluative, and action-oriented language, which provides a richer substrate for aspect and sentiment extraction.\n",
    "\n",
    "#### 3. Structural Complexity — $( w_3 = 0.18 )$\n",
    "\n",
    "**Definition**: Structural Complexity evaluates the variability and engagement level within each review, capturing sentence length variability, unique word usage, and punctuation proportion. This component encourages reviews with intricate sentence structures and unique tokens, both of which signal a higher depth of content and engagement.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{Structural Complexity} = 0.25 \\times \\text{sentence\\_length\\_std} + 0.25 \\times \\text{p\\_unique\\_tokens} + 0.25 \\times \\text{p\\_punctuation} + 0.25 \\times \\text{n\\_sentences}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **sentence\\_length\\_std**: Standard deviation of sentence lengths, capturing complexity.\n",
    "- **p\\_unique\\_tokens**: Proportion of unique tokens, indicating lexical variety.\n",
    "- **p\\_punctuation**: Proportion of punctuation, reflecting sentence structuring.\n",
    "- **n\\_sentences**: Number of sentences, indicating text depth.\n",
    "\n",
    "**Rationale**: This component complements POS Count and POS Diversity by capturing sentence-level structure and engagement, both of which improve ABSA’s ability to parse and infer multi-dimensional sentiment. Weighted at 0.2, Structural Complexity balances the need for structured yet diverse content.\n",
    "\n",
    "#### 4. POS Intensity (Sentiment Focus) — $( w_4 = 0.07 )$\n",
    "\n",
    "**Definition**: POS Intensity measures the density of content-bearing words relative to total word count, emphasizing reviews where sentiment-laden and aspect-rich language predominates.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{POS Intensity} = \\frac{\\text{nouns} + \\text{verbs} + \\text{adjectives} + \\text{adverbs}}{\\text{total words}}\n",
    "$$\n",
    "\n",
    "**Rationale**: High POS Intensity suggests a focused, sentiment-rich review, where descriptive and evaluative language outweighs filler or redundant text. This complements POS Count by ensuring that content volume is matched with density, focusing on the substance of each review.\n",
    "\n",
    "#### 5. Readability — $( w_5 = 0.05 )$\n",
    "\n",
    "**Definition**: Readability assesses the ease with which a review can be read and interpreted, using the Flesch Reading Ease score to gauge accessibility. High readability ensures that reviews are well-structured and easily parsed, which benefits both ABSA models and human readability.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{Readability} = \\text{Flesch Reading Ease}\n",
    "$$\n",
    "\n",
    "**Rationale**: Readability supports ABSA by ensuring that sentiment and aspect-related language is presented in a straightforward manner. However, readability alone does not guarantee substantive content, so it is weighted lower, serving as a secondary quality indicator.\n",
    "\n",
    "#### 6. TQA Check (Formal Quality Indicators) — $( w_6 = 0.1 )$\n",
    "\n",
    "**Definition**: The TQA Check evaluates the formal quality of the text, including punctuation and digit ratio, which signal professionalism and readability. TQA Check serves as a filter for overly simplistic or noisy text.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{TQA Check} = 0.3 \\times (1 - \\text{high\\_digit\\_ratio}) + 0.3 \\times (1 - \\text{high\\_punctuation\\_ratio}) + 0.4 \\times \\text{has\\_terminal\\_punctuation}\n",
    "$$\n",
    "\n",
    "**Rationale**: By enforcing basic formal standards, the TQA Check helps maintain a minimum quality threshold, reducing noise without strongly influencing content richness. It’s particularly useful for filtering out low-quality reviews that might otherwise distort ABSA performance.\n",
    "\n",
    "### Final Quality Score Formula\n",
    "\n",
    "Based on the above rationale, the complete quality score formula is as follows:\n",
    "\n",
    "$$\n",
    "Q = 0.4 \\times \\text{POS Count} + 0.2 \\times \\text{POS Diversity} + 0.18 \\times \\text{Structural Complexity} + 0.07 \\times \\text{POS Intensity} + 0.05 \\times \\text{Readability} + 0.1 \\times \\text{TQA Check}\n",
    "$$\n",
    "\n",
    "This quality scoring framework provides a multi-dimensional approach to filtering app reviews for ABSA. By weighting content volume, diversity, structural complexity, intensity, readability, and formal quality checks, the score favors reviews rich in content, balanced in lexical usage, and clear in sentiment expression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "from discover.flow.data_prep.tqa.stage import TQAStage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Dependency Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.data_prep.stage\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Quality Scoring Pipeline\n",
    "The text quality scoring pipeline begins by obtaining a configuration tailored to the text quality assessment (TQA) stage. Using the `FlowConfigReader`, we retrieve and apply a configuration specific to TQA from the overall data preparation phase. This configuration includes the parameters and settings required to assess the quality of the text data.\n",
    "\n",
    "### Pipeline Steps:\n",
    "\n",
    "1. **Configuration Retrieval**: The pipeline starts by reading the configuration via `FlowConfigReader`. By specifying \"phases\" as the target configuration, we isolate the required settings, focusing on the TQA stage.\n",
    "\n",
    "2. **Stage Initialization**: The `TQAStage` is built using the retrieved `stage_config`, which defines parameters such as thresholds, quality components, and weightings for text quality scoring. Setting the `force` parameter allows us to re-run this stage if necessary.\n",
    "\n",
    "3. **Execution and Asset Creation**: Finally, running the `TQAStage` initiates the text quality assessment, where each review's quality score is computed based on the defined formula. Once completed, this produces an asset identifier, `asset_id`, which corresponds to the processed dataset with text quality scores applied.\n",
    "\n",
    "This pipeline ensures that the text quality assessment is structured and reproducible, setting the stage for further analysis and filtering based on quality thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/04/2024 09:47:12 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-03_tqa-review-dataset.parquet from repository.\n",
      "[11/04/2024 09:47:12 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-dataprep-tqa-review from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                          Text Quality Analysis Stage                           #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/john/.ivy2/cache\n",
      "The jars for the packages stored in: /home/john/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-86c4582c-4823-48da-95fc-e95bc445f9fa;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.17.0 in central\n",
      ":: resolution report :: resolve 1883ms :: artifacts dl 90ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.17.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   83  |   0   |   0   |   5   ||   78  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-86c4582c-4823-48da-95fc-e95bc445f9fa\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 78 already retrieved (0kB/41ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                    TQATask                                     \n",
      "                                    -------                                     \n",
      "                          Start Datetime | Mon, 04 Nov 2024 09:47:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Mon, 04 Nov 2024 09:47:49\n",
      "                                 Runtime | 12.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "config = reader.get_config(\"phases\", namespace=False)\n",
    "stage_config = config[\"dataprep\"][\"stages\"][\"tqa\"]\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = TQAStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completing the text quality scoring pipeline, the dataset is now enriched with quality scores that reflect the structural and linguistic richness of each review. This dataset provides a foundation for further selection, where high-quality samples can be identified for pseudolabeling and other downstream tasks. Next, we will examine how the scores and data are distributed at different quality thresholds. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
