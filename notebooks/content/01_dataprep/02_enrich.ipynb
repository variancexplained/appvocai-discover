{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppVoCAI Dataset Enrichment\n",
    "This data enrichment effort will imbue subsequent data quality and exploratory analyses with essential quality signals, user engagement data, target class distributions, and aggregations that position us for a systematic, and intensive data quality analysis, and an insight-rich exploratory effort. This data enrichment stage will unfold through five progressive steps:\n",
    "\n",
    "1. **Text Quality Detection**: We identify and address extraneous characters, non-standard symbols, and other noise elements that may distort analytical insights. This ensures our textual data maintains a high level of clarity and precision, which is crucial for accurate natural language processing.\n",
    "\n",
    "2. **Text Quality Analysis**: We evaluate grammatical complexity, syntactic structure diversity, coherence, clarity, intensity, and the overall linguistic elaborateness {ref}`appendix:tqs`. These factors significantly impact the performance of language models, enhancing our understanding of nuanced user sentiment and intent.\n",
    "\n",
    "3. **Sentiment Classification**: Utilizing SpaCy’s rule-based sentiment classifier allows for a computationally efficient, high-level analysis of sentiment distribution and balance within the dataset. This provides an initial framework to identify emotional trends and ensure the dataset is representative of a wide range of user experiences.\n",
    "\n",
    "4. **Quantitative Enrichment**: Decomposing timestamps yields valuable temporal features, such as the relative age of reviews and submission details like month, day, and hour. This enables us to conduct temporal and longitudinal analyses, uncover cyclical trends in app usage, and observe variations in user behavior. Analyzing deviations from category-level and app-level themes may reveal unmet needs, feature gaps, and inconsistencies in user experiences.\n",
    "\n",
    "5. **Aggregate Data Analysis**: By summarizing data at the app, author, and category levels, we expose overarching themes related to user engagement, satisfaction, and app performance. This macro-level analysis provides  insight into broader dynamics of user interactions, highlighting areas of strength and opportunities for improvement.\n",
    "\n",
    "### Early Feature Engineering?\n",
    "Excellent question. Whereas feature engineering derives new variables that are expected to have an influential effect on model development and predictive performance, this data enrichment effort aims to facilitate rigorous data quality analysis, and exploration while minimizing bias, and avoiding transformations that might distort or invalidate analytical interpretations.\n",
    "\n",
    "Let's move forward!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "from discover.core.flow import DataPrepStageDef\n",
    "from discover.flow.data_prep.quant.stage import QuantStage\n",
    "from discover.flow.data_prep.sentiment.stage import SentimentClassificationStage\n",
    "from discover.flow.data_prep.dqm.stage import TextQualityDetectionStage\n",
    "from discover.flow.data_prep.tqa.stage import TQAStage\n",
    "from discover.flow.data_prep.aggregation.stage import AggregationStage\n",
    "from discover.core.flow import PhaseDef, DataPrepStageDef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.data_prep.stage\",\n",
    "        \"discover.flow.data_prep.aggregation.stage\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Quality Detection (TQD) Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                          Text Quality Detection Stage                          #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                          Text Quality Detection Stage                          \n",
      "                          ============================                          \n",
      "                           Stage Started | Tue, 12 Nov 2024 02:09:15\n",
      "                         Stage Completed | Tue, 12 Nov 2024 02:09:15\n",
      "                           Stage Runtime | 0.0 seconds\n",
      "                           Cached Result | True\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.DATAPREP, stage=DataPrepStageDef.TQD\n",
    ")\n",
    "# Build and run the stage\n",
    "stage = TextQualityDetectionStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Quality Analysis (TQA) Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                          Text Quality Analysis Stage                           #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                          Text Quality Analysis Stage                           \n",
      "                          ===========================                           \n",
      "                           Stage Started | Tue, 12 Nov 2024 02:09:17\n",
      "                         Stage Completed | Tue, 12 Nov 2024 02:09:17\n",
      "                           Stage Runtime | 0.0 seconds\n",
      "                           Cached Result | True\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.DATAPREP, stage=DataPrepStageDef.TQA\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = TQAStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Pipeline  \n",
    "The Review-Level Sentiment Classification Pipeline uses spaCy to analyze sentiment on a scale from -1 to 1. Reviews are then classified as negative, neutral, or positive by dividing this scale into three equal spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/12/2024 02:09:24 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-04_sentiment-review-dataset.parquet from repository.\n",
      "[11/12/2024 02:09:24 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-dataprep-sentiment-review from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                         Sentiment Classification Stage                         #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                           VaderSentimentAnalysisTask                           \n",
      "                           --------------------------                           \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2147abd9727041a89f87615d0ca99ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=4817), Label(value='0 / 4817'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:31\n",
      "                                 Runtime | 7.4 seconds\n",
      "\n",
      "\n",
      "                         Sentiment Classification Stage                         \n",
      "                         ==============================                         \n",
      "                           Stage Started | Tue, 12 Nov 2024 02:09:24\n",
      "                         Stage Completed | Tue, 12 Nov 2024 02:09:32\n",
      "                           Stage Runtime | 8.38 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FORCE = True\n",
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.DATAPREP, stage=DataPrepStageDef.SENTIMENT\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = SentimentClassificationStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Enrichment Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/12/2024 02:09:34 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-05_quant-review-dataset.parquet from repository.\n",
      "[11/12/2024 02:09:34 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-dataprep-quant-review from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                         Quantitative Enrichment Stage                          #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                              ComputeReviewAgeTask                              \n",
      "                              --------------------                              \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                                 Runtime | 3.79 seconds\n",
      "\n",
      "\n",
      "                             ComputeReviewMonthTask                             \n",
      "                             ----------------------                             \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                                 Runtime | 0.09 seconds\n",
      "\n",
      "\n",
      "                           ComputeReviewDayofWeekTask                           \n",
      "                           --------------------------                           \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                                 Runtime | 0.07 seconds\n",
      "\n",
      "\n",
      "                             ComputeReviewHourTask                              \n",
      "                             ---------------------                              \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                                 Runtime | 0.05 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                                 Runtime | 0.32 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                                 Runtime | 0.28 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:51\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:52\n",
      "                                 Runtime | 0.43 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:09:52\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:09:53\n",
      "                                 Runtime | 0.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                         Quantitative Enrichment Stage                          \n",
      "                         =============================                          \n",
      "                           Stage Started | Tue, 12 Nov 2024 02:09:34\n",
      "                         Stage Completed | Tue, 12 Nov 2024 02:10:02\n",
      "                           Stage Runtime | 28.58 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.DATAPREP, stage=DataPrepStageDef.QUANT\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = QuantStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Pipelines\n",
    "Aggregating data at the app and category levels provides a high-level view of review trends and user behavior, offering insights into user engagement and feedback patterns. At the app level, we consolidate key metrics, such as average ratings, review length, review count, and total vote sum, while identifying standout reviews based on highest vote counts, top TQA scores, and longest review lengths. \n",
    "\n",
    "A similar approach is used at the category level, aggregating metrics across all apps within a category to reveal trends that may indicate common strengths or pain points across similar apps. This two-tiered aggregation—app-level and category-level—allows for both detailed and broad insights into app performance, aiding in strategic decisions and market comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Aggregation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                               Aggregation Stage                                #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/12/2024 02:10:03 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-06_agg-app-dataset.parquet from repository.\n",
      "[11/12/2024 02:10:03 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-dataprep-agg-app from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                               AppAggregationTask                               \n",
      "                               ------------------                               \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:10:03\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:10:03\n",
      "                                 Runtime | 0.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/12/2024 02:10:13 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-06_agg-category-dataset.parquet from repository.\n",
      "[11/12/2024 02:10:13 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-dataprep-agg-category from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                            CategoryAggregationTask                             \n",
      "                            -----------------------                             \n",
      "                          Start Datetime | Tue, 12 Nov 2024 02:10:13\n",
      "                       Complete Datetime | Tue, 12 Nov 2024 02:10:13\n",
      "                                 Runtime | 0.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                               Aggregation Stage                                \n",
      "                               =================                                \n",
      "                           Stage Started | Tue, 12 Nov 2024 02:10:03\n",
      "                         Stage Completed | Tue, 12 Nov 2024 02:10:16\n",
      "                           Stage Runtime | 13.05 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.DATAPREP, stage=DataPrepStageDef.AGG\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = AggregationStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_ids = stage.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'app': 'dataset-dev-dataprep-agg-app',\n",
       " 'category': 'dataset-dev-dataprep-agg-category'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asset_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Stage Wrap-Up\n",
    "The enrichment stage enhanced the dataset with features, including review metadata (such as length, age and temporal data), sentiment analysis, text quality scores, and comprehensive app- and category-level aggregations. In the upcoming EDA phase, we will leverage these enriched attributes to uncover patterns, relationships, and trends that illuminate user behavior and app performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
