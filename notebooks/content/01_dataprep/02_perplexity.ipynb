{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity Analysis\n",
    "Perplexity is a measurement used in natural language processing (NLP) to evaluate how well a language model predicts a sequence of words. It quantifies the model's uncertainty when generating or understanding text. In other words, perplexity indicates how \"perplexed\" or confident a language model is when attempting to predict the next word in a sequence.\n",
    "\n",
    "Mathematically, perplexity is the exponential of the average negative log-likelihood of a sequence of words. A **higher perplexity** suggests the text is rich, complex, and harder for the model to predict, often indicating meaningful and varied content. Conversely, a **lower perplexity** indicates the model can predict the text more easily, which might signal irrelevant data, repetitive patterns, or noise.\n",
    "\n",
    "### Why Use Perplexity as a Proxy for Noise Detection?\n",
    "\n",
    "In the context of noise and data quality assessment, perplexity serves as a valuable proxy for identifying repetitive or irrelevant content:\n",
    "- **Low Perplexity**: Text with repeated patterns, simplistic language, or irrelevant content is easier for the model to predict and, therefore, has a lower perplexity. This can be an indicator of low-quality or noisy data.\n",
    "- **High Perplexity**: Rich, well-formed, and grammatically complex text has a higher perplexity, suggesting linguistic diversity and relevance.\n",
    "\n",
    "By using perplexity as a metric, we can detect and filter out low-quality or repetitive text, enhancing the overall quality of text data for applications like data quality assessment, content moderation, or noise reduction in large datasets.\n",
    "\n",
    "### How is Perplexity Calculated?\n",
    "Perplexity is calculated using a language model that has been trained on a large corpus of text. Here’s a step-by-step explanation of how it works:\n",
    "\n",
    "1. **Tokenization**: The text is first tokenized into words or subwords that the language model can process.\n",
    "2. **Model Prediction**: The language model assigns a probability to each word in the sequence based on the words that precede it. The likelihood of the entire sequence is then computed as the product of the probabilities of each word.\n",
    "3. **Log-Likelihood**: To make the calculations more manageable, the negative log-likelihood of the sequence is computed.\n",
    "4. **Average Log-Likelihood**: The average negative log-likelihood per word is calculated over the entire sequence.\n",
    "5. **Perplexity**: Finally, perplexity is calculated as the exponential of the average negative log-likelihood:\n",
    "   $$\n",
    "   \\text{Perplexity} = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^{N} \\log P(w_i)\\right)\n",
    "   $$\n",
    "   where $N$ is the number of words in the text, and $P(w_i)$ is the probability assigned to the $i^{th}$ word by the model.\n",
    "\n",
    "### Interpreting Perplexity\n",
    "- **Low Perplexity**: Indicates that the text is easier for the model to predict, suggesting it is coherent and follows typical language patterns.\n",
    "- **High Perplexity**: Suggests that the text is difficult to predict, often indicating that the text is gibberish, random, or otherwise unconventional.\n",
    "\n",
    "### Why Perplexity Matters\n",
    "Perplexity is a widely used metric in NLP for evaluating language models, and it provides a quantitative way to assess the quality of text. In our analysis, we use perplexity as an indicator to flag potential gibberish or poorly constructed text, which is crucial for filtering and cleaning data in natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Overview\n",
    "- **Model Name**: ` \"distilbert/distilgpt2\"`\n",
    "- **Base Model**: Generative Pre-trained Transformer 2 (GPT-2)\n",
    "- **Task**: Text Generation\n",
    "- **Language**: English\n",
    "\n",
    "## Model Description\n",
    "DistilGPT2 (short for Distilled-GPT2) is an English-language model pre-trained with the supervision of the smallest version of Generative Pre-trained Transformer 2 (GPT-2). Like GPT-2, DistilGPT2 can be used to generate text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from discover.app.ppl import PerplexityAnalyzer\n",
    "from discover.container import DiscoverContainer\n",
    "from discover.flow.stage.model.perplexity import PerplexityAnalysisStage\n",
    "from discover.core.flow import PhaseDef, StageDef\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.stage.base\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity Analysis Task\n",
    "The `PerplexityAnalysisTask` class performs perplexity analysis for each text entry, measuring the coherence and complexity of the text.\n",
    "\n",
    "**Key Technical Components**:\n",
    "\n",
    "1. **Model Setup and Hardware Optimization**:\n",
    "   - The class supports GPU acceleration using PyTorch. It detects if a CUDA-compatible GPU is available and assigns the device accordingly. This enables faster processing compared to using a CPU, which is critical for analyzing large datasets.\n",
    "   - The pre-trained language model and tokenizer are loaded using the Hugging Face `transformers` library. Specifically, `GPT2LMHeadModel` is used for language modeling, and `GPT2TokenizerFast` handles text tokenization.\n",
    "\n",
    "2. **Text Tokenization and Preparation**:\n",
    "   - The `predict_perplexity` method tokenizes the input text, converting it into a format that the model can process. Tokenization includes padding and truncating text to a fixed `max_length` (512 tokens by default), ensuring that all input sequences are the appropriate size for the model.\n",
    "\n",
    "3. **Chunked Text Processing**:\n",
    "   - For texts longer than the model's `max_length`, the class processes the text in overlapping chunks using a defined `stride` value. The stride determines how much of the text overlaps between chunks, ensuring that the model captures dependencies between words across chunks.\n",
    "   - Each chunk of text is passed through the model to compute the **negative log-likelihood (NLL)**, a key component in calculating perplexity. The method iterates over the text, collecting NLL values for each chunk.\n",
    "\n",
    "4. **Perplexity Calculation**:\n",
    "   - Perplexity is calculated as the exponential of the average negative log-likelihood across all chunks. Lower perplexity scores indicate simpler or more predictable text, while higher scores suggest greater linguistic richness and complexity.\n",
    "\n",
    "5. **Memory Management**:\n",
    "   - The class calls `torch.cuda.empty_cache()` before loading the model to free up GPU memory, preventing potential out-of-memory errors and ensuring efficient use of resources.\n",
    "\n",
    "6. **Efficient Data Processing**:\n",
    "   - The `run` method uses `progress_apply()` to apply the `predict_perplexity` method to each text entry in the specified column of a pandas DataFrame, with a progress bar for monitoring. This allows for a scalable and transparent analysis of text data.\n",
    "\n",
    "### Summary\n",
    "This class efficiently performs perplexity analysis, leveraging GPU acceleration to handle complex text data. It is designed for integration into data processing workflows, providing valuable insights into text coherence and quality. The source code is provided in the expandable cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -r 25-194 discover/flow/task/model/perplexity.py\n",
    "\n",
    "from discover.flow.task.base import Task\n",
    "from discover.infra.service.logging.task import task_logger\n",
    "from discover.infra.utils.file.io import IOService\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------ #\n",
    "class PerplexityAnalysisTask(Task):\n",
    "    \"\"\"Task for performing perplexity analysis on text data.\n",
    "\n",
    "    This class uses a pre-trained language model to calculate the perplexity\n",
    "    of text data in a specified column. The results are added to a new column\n",
    "    in the DataFrame, providing a quantitative measure of text coherence and\n",
    "    complexity.\n",
    "\n",
    "    Attributes:\n",
    "        cache_filepath (str): Path to file containing perplexities computed in the cloud.\n",
    "        device_local (bool): Whether to run locally, if cache isn't available. Default is False.\n",
    "            If cache is not available, an exceptoin will be raised.\n",
    "        column (str): The name of the column containing the text data. Defaults to \"content\".\n",
    "        new_column (str): The name of the column to store perplexity scores. Defaults to \"perplexity\".\n",
    "        model_name (str): The name of the pre-trained language model. Defaults to \"distilbert/distilgpt2\".\n",
    "        stride (int): The stride size used for processing long sequences in chunks. Defaults to 512.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cache_filepath: str,\n",
    "        column=\"content\",\n",
    "        new_column=\"perplexity\",\n",
    "        model_name: str = \"distilbert/distilgpt2\",\n",
    "        stride: int = 512,\n",
    "        device_local: bool = False,\n",
    "        io_cls: type[IOService] = IOService,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self._new_column = f\"{self.stage.id}_{new_column}\"\n",
    "        self._model_name = model_name\n",
    "        self._cache_filepath = cache_filepath\n",
    "        self._device_local = device_local\n",
    "\n",
    "        self._io = io_cls()\n",
    "\n",
    "        self._model_name = model_name\n",
    "        self._stride = stride\n",
    "\n",
    "        # Model, tokenizer, and device are initialized as None and will be loaded later\n",
    "        self._model = None\n",
    "        self._tokenizer = None\n",
    "        self._device = None\n",
    "        self._max_length = None\n",
    "\n",
    "    @task_logger\n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Executes perplexity on the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input DataFrame containing text data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with a new column containing perplexity.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cache = self._io.read(filepath=self._cache_filepath, lineterminator=\"\\n\")\n",
    "            cache[\"id\"] = cache[\"id\"].astype(\"string\")\n",
    "            data = data.merge(cache[[\"id\", self._new_column]], how=\"left\", on=\"id\")\n",
    "            return data\n",
    "        except (FileNotFoundError, TypeError):\n",
    "            if self._device_local:\n",
    "                return self._run(data=data)\n",
    "            else:\n",
    "                msg = f\"Cache not found or not available. {self.__class__.__name__} is not supported on local devices. Try running on Kaggle, Colab or AWS.\"\n",
    "                self._logger.error(msg)\n",
    "                raise FileNotFoundError(msg)\n",
    "        except Exception as e:\n",
    "            msg = f\"Unknown exception encountered.\\n{e}\"\n",
    "            self._logger.exception(msg)\n",
    "            raise\n",
    "\n",
    "    def _run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Executes perplexity analysis on the given DataFrame.\n",
    "\n",
    "        Args:\n",
    "            data (pd.DataFrame): The input DataFrame containing text data.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The DataFrame with a new column containing perplexity scores.\n",
    "        \"\"\"\n",
    "\n",
    "        from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "        # Clear CUDA memory to ensure enough space is available for the model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Load the device, model, and tokenizer\n",
    "        self._load_model_tokenizer_to_device()\n",
    "\n",
    "        # Compute perplexity for each text entry in the specified column\n",
    "        data[self._new_column] = data[self._column].progress_apply(\n",
    "            self.predict_perplexity\n",
    "        )\n",
    "        # Write results to cache\n",
    "        self._write_file(\n",
    "            filepath=self._cache_filepath, data=data[\"id\", self._new_column]\n",
    "        )\n",
    "\n",
    "        return data\n",
    "\n",
    "    def predict_perplexity(self, text):\n",
    "        \"\"\"Calculates the perplexity of a given text using the loaded language model.\n",
    "\n",
    "        Args:\n",
    "            text (str): The input text for perplexity computation.\n",
    "\n",
    "        Returns:\n",
    "            float: The calculated perplexity score for the text.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Tokenize the text and prepare it for the model\n",
    "            inputs = self._tokenizer(\n",
    "                text.lower(),\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=self._max_length,\n",
    "            )\n",
    "            # Move inputs to the appropriate device (CPU or GPU)\n",
    "            inputs = {key: value.to(self._device) for key, value in inputs.items()}\n",
    "            seq_len = inputs[\"input_ids\"].size(1)\n",
    "            nlls = []  # List to store negative log-likelihood values\n",
    "            prev_end_loc = 0\n",
    "\n",
    "            # Process the text in chunks using the specified stride\n",
    "            for begin_loc in range(0, seq_len, self._stride):\n",
    "                end_loc = min(begin_loc + self._max_length, seq_len)\n",
    "                trg_len = end_loc - prev_end_loc  # Target length for the current chunk\n",
    "                input_ids = inputs[\"input_ids\"][:, begin_loc:end_loc].to(self._device)\n",
    "                target_ids = input_ids.clone()\n",
    "                target_ids[:, :-trg_len] = -100  # Mask non-target tokens\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    # Compute the negative log-likelihood for the current chunk\n",
    "                    outputs = self._model(input_ids, labels=target_ids)\n",
    "                    neg_log_likelihood = outputs.loss\n",
    "\n",
    "                nlls.append(neg_log_likelihood)\n",
    "                prev_end_loc = end_loc\n",
    "                if end_loc == seq_len:\n",
    "                    break\n",
    "\n",
    "        # Return the exponential of the average negative log-likelihood as perplexity\n",
    "        return torch.exp(torch.stack(nlls).mean()).item()\n",
    "\n",
    "    def _load_model_tokenizer_to_device(self) -> None:\n",
    "        \"\"\"Loads the device, tokenizer, and model for perplexity analysis.\"\"\"\n",
    "        # Select GPU if available, otherwise use CPU\n",
    "        self._device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Load the tokenizer and model from the pre-trained model name\n",
    "        self._tokenizer = GPT2TokenizerFast.from_pretrained(self._model_name)\n",
    "        self._model = GPT2LMHeadModel.from_pretrained(self._model_name).to(self._device)\n",
    "\n",
    "        # Set the maximum length supported by the model\n",
    "        self._max_length = self._model.config.n_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity Analysis Pipeline\n",
    "Extract the configuration, construct the `PerplexityAnalysisStage` pipeline and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                           Perplexity Analysis Stage                            #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                           Perplexity Analysis Stage                            \n",
      "                           =========================                            \n",
      "                           Stage Started | Mon, 02 Dec 2024 18:59:31\n",
      "                         Stage Completed | Mon, 02 Dec 2024 18:59:32\n",
      "                           Stage Runtime | 0.27 seconds\n",
      "                           Cached Result | True\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.DATAPREP, stage=StageDef.PERPLEXITY\n",
    ")\n",
    "\n",
    "# Build and run Data Sentiment Analysis Stage\n",
    "stage = PerplexityAnalysisStage.build(\n",
    "    stage_config=stage_config, return_dataset=True, force=FORCE\n",
    ")\n",
    "dataset = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity Results Analysis\n",
    "Let's examine a few random samples to get a sense of how perplexity scores are reflected in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>vote_sum</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>date</th>\n",
       "      <th>review_length</th>\n",
       "      <th>pa_perplexity</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56610</th>\n",
       "      <td>9912730443</td>\n",
       "      <td>1108185179</td>\n",
       "      <td>Calendar</td>\n",
       "      <td>6007</td>\n",
       "      <td>1d4d567c0e44acaf77e6</td>\n",
       "      <td>4</td>\n",
       "      <td>Mooncycle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-05-10 15:50:00</td>\n",
       "      <td>1</td>\n",
       "      <td>184325.468750</td>\n",
       "      <td>Productivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72533</th>\n",
       "      <td>9522246562</td>\n",
       "      <td>454638411</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>6005</td>\n",
       "      <td>0f07e09228191139bcb8</td>\n",
       "      <td>3</td>\n",
       "      <td>Would be 5 stars, but missing this feature. Please bring back the option to remove contact from non-friends, so we can have some privacy. I think there’s use to be this option years ago. Now once you chat with non friends you will see each other active. For example if you contact thru Facebook marketplace you it will automatically add to your contact which you can’t remove and can only block. Which I don’t want to see anyone  on my block list. So overall 3 stars unless fixed with future updates.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-18 23:40:59</td>\n",
       "      <td>91</td>\n",
       "      <td>77.504509</td>\n",
       "      <td>Social Networking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41259</th>\n",
       "      <td>8455560762</td>\n",
       "      <td>1184577212</td>\n",
       "      <td>Zap Surveys - Earn Easy Money</td>\n",
       "      <td>6012</td>\n",
       "      <td>b4be52faf2d35af522cb</td>\n",
       "      <td>3</td>\n",
       "      <td>I thought that the payout would have been higher for surveys.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-03-14 18:20:27</td>\n",
       "      <td>11</td>\n",
       "      <td>155.309021</td>\n",
       "      <td>Lifestyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51489</th>\n",
       "      <td>7358923363</td>\n",
       "      <td>389801252</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>6008</td>\n",
       "      <td>7042f5e76c74cf3f4433</td>\n",
       "      <td>1</td>\n",
       "      <td>I havent been able to stay in connection with what is happening in Palestine because instagram keeps blocking most of the videos and posts and banning their spread. As a user that has the total freedom to follow whatever page i want and that expects to recieve the news i select, this have been useless lately because i no longer have the right nor the ability to chose the platforms i would like to be connected to. Only ridiculously useless pages on the top of the feeds with very unimportant content while disasterous unhumatarian events are happening all over the world with zero coverage and transparency. Hypocrite</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-19 03:36:48</td>\n",
       "      <td>107</td>\n",
       "      <td>114.216942</td>\n",
       "      <td>Photo &amp; Video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29621</th>\n",
       "      <td>7043042797</td>\n",
       "      <td>386022579</td>\n",
       "      <td>Pregnancy Tracker - BabyCenter</td>\n",
       "      <td>6013</td>\n",
       "      <td>893d1c4e09825eba32f9</td>\n",
       "      <td>5</td>\n",
       "      <td>They give you so much unlimited information that other apps do not definitely worth downloading I have downloaded multiple maybe all and this was the best one !!! It’s awesome 🤰🏾🤰🏼🤰🏿🤰🏽🤰🏻🤰</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-02-27 02:35:55</td>\n",
       "      <td>31</td>\n",
       "      <td>35.672577</td>\n",
       "      <td>Health &amp; Fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      app_id                        app_name category_id  \\\n",
       "56610  9912730443  1108185179                        Calendar        6007   \n",
       "72533  9522246562   454638411                       Messenger        6005   \n",
       "41259  8455560762  1184577212   Zap Surveys - Earn Easy Money        6012   \n",
       "51489  7358923363   389801252                       Instagram        6008   \n",
       "29621  7043042797   386022579  Pregnancy Tracker - BabyCenter        6013   \n",
       "\n",
       "                     author  rating  \\\n",
       "56610  1d4d567c0e44acaf77e6       4   \n",
       "72533  0f07e09228191139bcb8       3   \n",
       "41259  b4be52faf2d35af522cb       3   \n",
       "51489  7042f5e76c74cf3f4433       1   \n",
       "29621  893d1c4e09825eba32f9       5   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            content  \\\n",
       "56610                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Mooncycle   \n",
       "72533                                                                                                                          Would be 5 stars, but missing this feature. Please bring back the option to remove contact from non-friends, so we can have some privacy. I think there’s use to be this option years ago. Now once you chat with non friends you will see each other active. For example if you contact thru Facebook marketplace you it will automatically add to your contact which you can’t remove and can only block. Which I don’t want to see anyone  on my block list. So overall 3 stars unless fixed with future updates.   \n",
       "41259                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 I thought that the payout would have been higher for surveys.   \n",
       "51489  I havent been able to stay in connection with what is happening in Palestine because instagram keeps blocking most of the videos and posts and banning their spread. As a user that has the total freedom to follow whatever page i want and that expects to recieve the news i select, this have been useless lately because i no longer have the right nor the ability to chose the platforms i would like to be connected to. Only ridiculously useless pages on the top of the feeds with very unimportant content while disasterous unhumatarian events are happening all over the world with zero coverage and transparency. Hypocrite   \n",
       "29621                                                                                                                                                                                                                                                                                                                                                                                                                                                   They give you so much unlimited information that other apps do not definitely worth downloading I have downloaded multiple maybe all and this was the best one !!! It’s awesome 🤰🏾🤰🏼🤰🏿🤰🏽🤰🏻🤰   \n",
       "\n",
       "       vote_sum  vote_count                date  review_length  pa_perplexity  \\\n",
       "56610         0           0 2023-05-10 15:50:00              1  184325.468750   \n",
       "72533         0           0 2023-01-18 23:40:59             91      77.504509   \n",
       "41259         0           0 2022-03-14 18:20:27             11     155.309021   \n",
       "51489         0           0 2021-05-19 03:36:48            107     114.216942   \n",
       "29621         0           0 2021-02-27 02:35:55             31      35.672577   \n",
       "\n",
       "                category  \n",
       "56610       Productivity  \n",
       "72533  Social Networking  \n",
       "41259          Lifestyle  \n",
       "51489      Photo & Video  \n",
       "29621   Health & Fitness  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = PerplexityAnalyzer(df=dataset.content)\n",
    "analyzer.sample(\n",
    "    n=5, random_state=8, column_subset=[\"id\", \"app_name\", \"content\", \"pa_perplexity\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "1. **Review 1** (\"Mooncycle\") has an extremely high perplexity score of **184,325.47**, which is consistent with the language model's difficulty in predicting the next word, particularly because \"Mooncycle\" and any domain-specific terms or infrequent phrases related to it may not have appeared in the training corpus. This unfamiliarity leads to greater uncertainty and a higher perplexity score, reflecting the model's struggle to make accurate predictions for such text content.process.\n",
    "2. **Review 2** (Long review about privacy concerns on Facebook) has a perplexity score of **77.50**. This indicates a relatively structured and predictable text, suggesting the language is coherent but not overly simplistic.\n",
    "3. **Review 3** (Complaint about survey payouts) has a perplexity score of **155.31**, which is higher than average but not extreme. The text might have a moderate level of complexity or variability in its language.\n",
    "4. **Review 4** (Criticism of Instagram’s censorship) has a perplexity score of **114.22**. This score suggests a coherent yet linguistically rich text, with the complexity stemming from the review's length and nuanced content.\n",
    "5. **Review 5** (Highly positive review with emojis) has the lowest perplexity score of **35.67**. This reflects simple and repetitive language, making the text highly predictable for the language model.\n",
    "\n",
    "Overall, the data highlights variations in text complexity, with most reviews being reasonably coherent but differing in their richness and structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Low Perplexity Signal Noise, Gibberish and Irrelevancy \n",
    "Examing the lowest perplexity reviews may illuminate the degree to which low perplexity may signal irrelevant content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.select(\n",
    "    n=10,\n",
    "    sort_by=\"pa_perplexity\",\n",
    "    ascending=True,\n",
    "    cols=[\"id\", \"app_name\", \"pa_perplexity\", \"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This preliminary examination of the 10 observations with the lowest perplexity values (ranging from approximately 1.05 to 1.23) reveals a pattern of highly repetitive or symbol-dominated content, such as:\n",
    "\n",
    "1. **Excessive Symbols and Emojis**: Examples like \"👏👏👏...\" and \"👌👌👌...\" illustrate content that primarily consists of repeated emojis or symbols, contributing to their predictability and low complexity scores.\n",
    "2. **Uniform Text Fragments**: Entries such as \"Trash Trash Trash...\" highlight a simple repetitive structure, again leading to lower perplexity values due to the model's ability to easily anticipate the sequence.\n",
    "3. **Emoji Blocks and Repeated Symbols**: Reviews full of emojis (\"🔥🔥🔥...\") or non-standard characters (\"𓂺𓂺𓂺...\") also exhibit low perplexity, reflecting predictable patterns.\n",
    "\n",
    "These data suggest, **but do not conclusively prove**, that low perplexity may indeed serve as an indicator of noise or less meaningful content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity Threshold Analysis\n",
    "These observations raise an important question: **At what point does perplexity's ability to indicate noise diminish?** To examine this, we analyze reviews and their associated perplexity values at various percentile thresholds, ranging from 0.1 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.arange(0.1, 3, 0.1)\n",
    "analyzer.max_perplexity_by_percentile(\n",
    "    percentiles=percentiles, cols=[\"percentile\", \"content\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The analysis of various levels of perplexity reveals distinct patterns in the types of content that each threshold captures, shedding light on the potential utility of perplexity as a signal for noise and irrelevancy in text data. Here's what the findings suggest:\n",
    "\n",
    "1. **Extremely Low Perplexity (0.1 to 0.3)**:\n",
    "   - Content in this range is dominated by sequences of repetitive emojis or simple, highly redundant patterns, such as repeated applause or thumbs-up emojis.\n",
    "   - These observations suggest that extremely low perplexity values are indicative of non-linguistic content or sequences that offer little informational complexity.\n",
    "\n",
    "2. **Low Perplexity (0.4 to 0.7)**:\n",
    "   - Content becomes more mixed but still includes a significant presence of repetitive or predictable text. For instance, some posts contain emotional expressions with heart emojis, while others feature straightforward, positive reviews in foreign languages.\n",
    "   - The presence of foreign language content, though coherent, demonstrates that perplexity may be sensitive to linguistic variety that was not well-represented in the training data.\n",
    "\n",
    "3. **Moderate Perplexity (0.8 to 1.0)**:\n",
    "   - Reviews in this range exhibit more complexity and structure, with longer, narrative-style content and some use of slang or colloquial language. There are song lyrics and stylized, informal writing that adds some linguistic variability.\n",
    "   - While these texts are coherent, they may still contain irrelevant or non-substantive content (e.g., song lyrics) that adds complexity but not necessarily valuable information.\n",
    "\n",
    "4. **Perplexity Above 1.0**:\n",
    "   - Content in this range starts to include reviews with clear and substantive feedback, coherent expressions of opinions, or narratives that offer more informative insights into user experiences.\n",
    "   - However, as perplexity increases beyond 2.0, the content tends to include longer and more detailed complaints, requests for help, or descriptions of specific app issues.\n",
    "\n",
    "#### Potential Threshold for Data Cleaning\n",
    "Based on the observations, a **threshold around 0.3 to 0.5** might be suitable for filtering out the most egregiously redundant or non-informative content. However, the utility of perplexity as a cleaning mechanism is not foolproof. While it appears effective at capturing non-linguistic noise and repetitive text, there are edge cases (e.g., foreign language content or stylized writing) where its predictive value diminishes.\n",
    "\n",
    "Ultimately, our observations suggest a useful, though preliminary, heuristic: **low perplexity may be a helpful indicator of repetitive or irrelevant text**, but its effectiveness is likely to improve when used alongside complementary metrics in a holistic data quality assessment framework.\n",
    "\n",
    "In the next section, we model sentiments within the dataset, providing an overall sense of class balance and representativeness of the dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
