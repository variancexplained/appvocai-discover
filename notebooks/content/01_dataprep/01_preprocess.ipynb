{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppVoCAI Dataset Preprocessing\n",
    "---\n",
    "In this section, we unbox and preprocess the AppVoCAI dataset, survey its key characteristics, and profile its structure, format, and data types, before downstream data quality assessment, cleaning, analysis activities and feature engineering. The raw dataset was loaded into the workspace during project initialization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from genailab.infra.config.flow import FlowConfigReader\n",
    "from genailab.setup import auto_wire_container\n",
    "from genailab.infra.utils.file.fileset import FileFormat\n",
    "from genailab.core.flow import PhaseDef, StageDef\n",
    "from genailab.asset.dataset.config import DatasetConfigfig\n",
    "from genailab.flow.dataprep.preprocess.builder import PreprocessStageBuilder\n",
    "\n",
    "# Wire container\n",
    "container = auto_wire_container()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Pipeline\n",
    "--\n",
    "\n",
    "The `PreprocessingStage` ensures that the data are in a structure and format suitable for downstream processing and analysis. This involves verifying UTF-8 encoding, casting data to appropriate types, converting datetimes to millisecond precision (for Spark) and removing any extraneous newlines from the review text.\n",
    "\n",
    "The next code cell creates and runs the PreprocessingStage pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01/19/2025 02:49:23 PM] [ERROR] [genailab.infra.persist.object.dao.ShelveDAO] [read] : Asset dataset_dataprep_preprocess_review_v0.1.1 was not found.\n",
      "[01/19/2025 02:49:23 PM] [WARNING] [genailab.flow.base.stage.PreprocessStage] [_remove_target] : Dataset and/or files not found for asset dataset_dataprep_preprocess_review_v0.1.1.\n",
      "Asset dataset_dataprep_preprocess_review_v0.1.1 was not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                 Data Preprocessing Stage Sun, 19 Jan 2025 14:49:23                 #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "Task                                    Start       End         Runtime     \n",
      "----------------------------------------------------------------------------\n",
      "VerifyEncodingTask                      14:49:23    14:49:23    0.01 seconds\n",
      "CastDataTypeTask                        14:49:23    14:49:23    0.01 seconds\n",
      "RemoveNewlinesTask                      14:49:23    14:49:23    0.0 seconds \n",
      "____________________________________________________________________________\n",
      "Data Preprocessing Stage                    14:49:23    14:49:23    0.2 seconds \n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the preprocess stage builder\n",
    "builder = PreprocessStageBuilder()\n",
    "# Add preprocess tasks to the builder and return the stage object.\n",
    "stage = (\n",
    "    .encoding()  # Verifies UTF-8 Encoding\n",
    "    .datatypes()  # Casts appropriate datatypes, i.e. category, int, float, and datetime variables.\n",
    "    .newlines()  # Removes newlines from text\n",
    "    .datetime()  # Converts datatime to millisecond precision (for pyspark)\n",
    "    .build()  # Constructs the pipeline and returns the stage\n",
    ")\n",
    "# Run the stage pipeline\n",
    "dataset = stage.run(force=FORCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Structure\n",
    "Let's examine the dataset structure, data types, completeness, uniqueness, and size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>DataType</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Null</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Uniqueness</th>\n",
       "      <th>Size (Bytes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>581479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>app_id</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2636</td>\n",
       "      <td>6034</td>\n",
       "      <td>0.304037</td>\n",
       "      <td>576305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>app_name</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2634</td>\n",
       "      <td>6036</td>\n",
       "      <td>0.303806</td>\n",
       "      <td>703398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category_id</td>\n",
       "      <td>category</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8656</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>10080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8668</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999769</td>\n",
       "      <td>667590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rating</td>\n",
       "      <td>int16</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8665</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>17340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>string[python]</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8368</td>\n",
       "      <td>302</td>\n",
       "      <td>0.965167</td>\n",
       "      <td>4192835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vote_sum</td>\n",
       "      <td>int64</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>8653</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>69360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vote_count</td>\n",
       "      <td>int64</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>8651</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>69360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>date</td>\n",
       "      <td>datetime64[ms]</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>8670</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>8656</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>10169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column        DataType  Complete  Null  Completeness  Unique  \\\n",
       "0            id  string[python]      8670     0           1.0    8670   \n",
       "1        app_id  string[python]      8670     0           1.0    2636   \n",
       "2      app_name  string[python]      8670     0           1.0    2634   \n",
       "3   category_id        category      8670     0           1.0      14   \n",
       "4        author  string[python]      8670     0           1.0    8668   \n",
       "5        rating           int16      8670     0           1.0       5   \n",
       "6       content  string[python]      8670     0           1.0    8368   \n",
       "7      vote_sum           int64      8670     0           1.0      17   \n",
       "8    vote_count           int64      8670     0           1.0      19   \n",
       "9          date  datetime64[ms]      8670     0           1.0    8670   \n",
       "10     category        category      8670     0           1.0      14   \n",
       "\n",
       "    Duplicate  Uniqueness  Size (Bytes)  \n",
       "0           0    1.000000        581479  \n",
       "1        6034    0.304037        576305  \n",
       "2        6036    0.303806        703398  \n",
       "3        8656    0.001615         10080  \n",
       "4           2    0.999769        667590  \n",
       "5        8665    0.000577         17340  \n",
       "6         302    0.965167       4192835  \n",
       "7        8653    0.001961         69360  \n",
       "8        8651    0.002191         69360  \n",
       "9           0    1.000000         69360  \n",
       "10       8656    0.001615         10169  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comprises 22,166,591 fully complete records, with no missing values, and a well-structured variety of data types. Key interpretations include:\n",
    "\n",
    "- **Data Types**: The dataset employs a thoughtful mix of data types, such as strings for identifiers and text fields, `int16` and `int64` for numerical columns like `Rating`, `Vote Sum`, and `Vote Count`, and `datetime64[ms]` for precise date tracking. This combination ensures both efficiency and accuracy in data handling.\n",
    "\n",
    "- **Duplicate Review IDs**: There are 117 duplicate `ID` values, indicating potential duplicate reviews. This suggests the need for a deduplication process to ensure data integrity and prevent biases in analysis due to repeated entries.\n",
    "\n",
    "- **Categorical Insights**: The dataset features 14 unique `Category` values, reflecting the breadth of application categories, and 5 unique `Rating` values, consistent with a standard 5-point rating scale. These are critical for categorical analyses and aggregating review sentiment.\n",
    "\n",
    "- **Duplicate Content**: The `Content` column shows high uniqueness overall but also includes significant duplicate entries. This could indicate commonly used phrases or templated responses in short reviews, which may require special handling during text analysis to differentiate between genuine user feedback and repetitive content.\n",
    "\n",
    "- **High Uniqueness in Key Columns**: Columns like `ID`, `Content`, and `Date` demonstrate high uniqueness, essential for detailed individual review analysis and time-series studies.\n",
    "\n",
    "- **Memory Efficiency**: Despite the large volume, efficient use of data types—particularly categorical and numerical fields—helps manage the dataset's memory footprint. The `Content` field, being text-heavy, dominates memory usage but is critical for in-depth textual analysis.\n",
    "\n",
    "Overall, the dataset is ready for a more robust quality analysis, with attention to duplication, relevance, validity, and privacy concerns. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AppVoCAI Dataset Summary\n",
    "Here, we summarize the dataset contents in terms of reviews, apps, reviewer engagement, influence, app, and categorical breadth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                            AppVoCAI Dataset Summary                            \n",
      "                       Number of Reviews | 8,670\n",
      "                     Number of Reviewers | 8,668\n",
      "              Number of Repeat Reviewers | 2 (0.0%)\n",
      "         Number of Influential Reviewers | 575 (6.6%)\n",
      "                          Number of Apps | 2,636\n",
      "                    Number of Categories | 14\n",
      "                 Average Reviews per App | 3.3\n",
      "                                Features | 11\n",
      "                        Memory Size (Mb) | 6.71\n",
      "                    Date of First Review | 2020-01-01 11:06:50\n",
      "                     Date of Last Review | 2023-08-29 13:25:46\n"
     ]
    }
   ],
   "source": [
    "dataset.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "- **Volume and Scale**: The dataset contains a substantial number of reviews (22.17 million) and reviewers (15.71 million), indicating a broad and diverse user engagement across a wide range of applications.\n",
    "\n",
    "- **Repeat Reviewers**: Approximately 22.9% of reviewers have submitted more than one review, suggesting a significant proportion of engaged users who consistently contribute feedback. This can provide valuable longitudinal insights into user experiences and loyalty.\n",
    "\n",
    "- **Influential Reviewers**: With 6.6% of reviewers deemed influential (based on vote sum and counts), their contributions could play a pivotal role in shaping app perceptions and rankings.\n",
    "\n",
    "- **App Diversity**: The dataset covers 36,377 unique apps across 14 categories, indicating a wide-ranging scope of applications. This diversity is beneficial for conducting category-specific analyses and identifying trends within various app domains.\n",
    "\n",
    "- **Review Distribution**: On average, each app has approximately 609 reviews. This high level of engagement per app supports detailed app-level performance and sentiment analysis.\n",
    "\n",
    "- **Temporal Range**: The dataset spans over 15 years, from July 2008 to September 2023. This extensive timeframe allows for robust historical analysis, capturing the evolution of user feedback and app development trends over time.\n",
    "\n",
    "- **Memory Usage**: The dataset's size is significant, with a memory footprint of approximately 14.51 GB. This underscores the need for efficient data handling and processing strategies, particularly for large-scale analyses.\n",
    "\n",
    "- **Feature Richness**: With 11 distinct app, reviewer, and review features, the dataset enables both qualitative (review) and quantitative (rating, review_count, vote metrics) analysis of app performance and user sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "### Limitations of the Dataset\n",
    "\n",
    "While the AppVoCAI dataset provides a wealth of user review and satisfaction information, there are notable limitations regarding missing data on app performance and financial metrics. Specifically, data on **downloads**, **price**, and **sales figures** are not included. These omissions limit the ability to perform comprehensive analyses that would require correlating user reviews with app popularity and financial performance. Future datasets that incorporate these factors would enable a more holistic view of the app ecosystem, enhancing the ability to draw connections between user sentiment, app success, and market performance.\n",
    "\n",
    "In summary, the AppVoCAI dataset offers a rich and expansive resource for analyzing user reviews across a wide variety of applications and categories, with strong potential for deriving actionable insights from its longitudinal and categorical data.\n",
    "\n",
    "---\n",
    "\n",
    "In the next section, we will analyze the validity, relevance, uniqueness, privacy and completeness of the dataset, providing a robust, multi-dimensional data quality analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
