{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification \n",
    "This notebook leverages a **DistilBERT-based Sentiment Classification Model**, specifically the `tabularisai/robust-sentiment-analysis` model, to perform sentiment analysis. The goal is to efficiently analyze and classify sentiment within a dataset for the purposes of **Data Quality Assessment (DQA)** and **Exploratory Data Analysis (EDA)**. By using an 'off-the-shelf', pre-trained model, we gain a sense of sentiment class balance, and insights with a computational efficient technique.  \n",
    "\n",
    "## Model Overview\n",
    "- **Model Name**: `tabularisai/robust-sentiment-analysis`\n",
    "- **Base Model**: `distilbert/distilbert-base-uncased`\n",
    "- **Task**: Text Classification (Sentiment Analysis)\n",
    "- **Language**: English\n",
    "- **Number of Classes**: 5 sentiment categories:\n",
    "  - **Very Negative**\n",
    "  - **Negative**\n",
    "  - **Neutral**\n",
    "  - **Positive**\n",
    "  - **Very Positive**\n",
    "\n",
    "## Model Description\n",
    "This model is a fine-tuned version of `distilbert-base-uncased`, optimized for sentiment analysis using synthetic data generated by cutting-edge language models like **Llama3.1** and **Gemma2**. By training exclusively on synthetic data, the model has been exposed to a diverse range of sentiment expressions, which enhances its ability to generalize across different use cases\n",
    "\n",
    "## Purpose of the Notebook\n",
    "1. **Data Quality Assessment (DQA)**: By running sentiment analysis on the dataset, we can assess sentiment distribution and identify any potential biases or issues in the data that may impact subsequent analysis.\n",
    "2. **Exploratory Data Analysis (EDA)**: Understanding the overall sentiment landscape of the dataset provides critical context for deeper analysis, revealing trends, patterns, or anomalies in the data.\n",
    "3. **Pre-Tuned Efficiency**: Using an off-the-shelf model ensures quick and efficient analysis, allowing us to focus on insights rather than model optimization. This is particularly valuable as we will later fine-tune a more specialized model for ABSA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "\n",
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.service.datamanager.sentiment import SentimentAnalysisDataManager\n",
    "\n",
    "# Register `tqdm` with pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.options.display.max_colwidth = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.infra.service.datamanager.base\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manager\n",
    "The `SentimentAnalysisDataManager` owns persistence of data and datasets used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamanager = SentimentAnalysisDataManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Path Options\n",
    "This notebook supports three execution paths:\n",
    "\n",
    "1. **Load Endpoint**: If the notebook has already been executed and results are stored in the repository, they will be loaded. This path is used unless the `FORCE` parameter is set to `True`.\n",
    "2. **Load Sentiments**: If sentiment analysis results have been precomputed on cloud-based GPUs and saved in a CSV file, the file will be loaded and merged with the dataset, unless `FORCE` is `True`.\n",
    "3. **Execute Inference**: If `FORCE` is set to `True` or if neither the endpoint nor the sentiment file is available, the notebook will perform inference using the sentiment analysis model.\n",
    "\n",
    "The following code supports the determination of the execution path based on these conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecutionPath(Enum):\n",
    "    LOAD_ENDPOINT = \"load_endpoint\"\n",
    "    LOAD_SENTIMENTS = \"load_sentiments\"\n",
    "    EXECUTE_INFERENCE = \"execute_inference\"\n",
    "\n",
    "\n",
    "def determine_execution_path(\n",
    "    force: bool, datamanager: SentimentAnalysisDataManager\n",
    ") -> ExecutionPath:\n",
    "    \"\"\"Determines the execution path based on the existence of data and the force parameter.\n",
    "\n",
    "    Args:\n",
    "        force (bool): Whether to force execution, overriding existing data checks.\n",
    "        data_manager (SentimentAnalysisDataManager): The data manager to check for existing datasets and sentiments.\n",
    "\n",
    "    Returns:\n",
    "        ExecutionPath: The determined execution path.\n",
    "    \"\"\"\n",
    "    if force:\n",
    "        return ExecutionPath.EXECUTE_INFERENCE\n",
    "\n",
    "    elif datamanager.dataset_exists(stage=\"sentiment\"):\n",
    "        return ExecutionPath.LOAD_ENDPOINT\n",
    "\n",
    "    elif datamanager.sentiments_exist():\n",
    "        return ExecutionPath.LOAD_SENTIMENTS\n",
    "\n",
    "    else:\n",
    "        return ExecutionPath.EXECUTE_INFERENCE\n",
    "\n",
    "\n",
    "execution_path = determine_execution_path(force=FORCE, datamanager=datamanager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Endpoint\n",
    "Loads the endpoint if appropriate given the execution path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_path == ExecutionPath.LOAD_ENDPOINT:\n",
    "    df = datamanager.get_dataset(stage=\"sentiment\", name=\"review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-Computed Sentiments\n",
    "Obtain the dataset from the prior stage, 'ingest', and merge in the sentiments from file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_path == ExecutionPath.LOAD_SENTIMENTS:\n",
    "    df = datamanager.get_dataset(stage=\"ingest\", name=\"review\")\n",
    "    sentiments = datamanager.get_sentiments()\n",
    "    df = datamanager.merge_sentiments(df=df, sentiments=sentiments)\n",
    "    datamanager.add_dataset(df=df, stage=\"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Inference\n",
    "The following cells perform inference using the sentiment analysis model according to the execution path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Model and Transformer Libraries\n",
    "PyTorch model and tokenizer are imported, as well as tqdm for progress monitoring.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_path == ExecutionPath.EXECUTE_INFERENCE:\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "    import torch\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Availability and Prepare for Inference \n",
    "Verify GPU availability, ensuring GPU resources are being detected and utilized. To mitigate memory issues, release all unused cached memory held by the caching allocator, making it available for other GPU applications and visible in `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_path == ExecutionPath.EXECUTE_INFERENCE:\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    !nvidia-smi\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Loads the data from the ingest stage from the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_path == ExecutionPath.EXECUTE_INFERENCE:\n",
    "    df = datamanager.get_dataset(stage=\"ingest\", name=\"review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer\n",
    "Import and load the sentiment analyzer and the tokenizer designed for sequence classification, then move the model to the device detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "if execution_path == ExecutionPath.EXECUTE_INFERENCE:\n",
    "    model_name = \"tabularisai/robust-sentiment-analysis\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Classifier\n",
    "Tokenize the string of text, truncating it to 512 characters and pad the text if it is shorter than 512 characters. Move the tokenized input to the device detected. Probabilities are computed for each class, and the function returns the highest probability class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict sentiment\n",
    "def predict_sentiment(text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            text.lower(),\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        )\n",
    "        inputs = {\n",
    "            key: value.to(device) for key, value in inputs.items()\n",
    "        }  # Move inputs to the GPU\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "    sentiment_map = {\n",
    "        0: \"Very Negative\",\n",
    "        1: \"Negative\",\n",
    "        2: \"Neutral\",\n",
    "        3: \"Positive\",\n",
    "        4: \"Very Positive\",\n",
    "    }\n",
    "    return sentiment_map[predicted_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference\n",
    "Run inference using the classification function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if execution_path == ExecutionPath.EXECUTE_INFERENCE:\n",
    "    df[\"an_sentiment\"] = df[\"content\"].progress_apply(predict_sentiment)\n",
    "    datamanager.add_dataset(df=df, stage=\"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>an_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76544</th>\n",
       "      <td>10201072201</td>\n",
       "      <td>Ad Block One: Tube Ad Blocker</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82700</th>\n",
       "      <td>8833410900</td>\n",
       "      <td>Cleanup: Phone Storage Cleaner</td>\n",
       "      <td>Save time and space</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26968</th>\n",
       "      <td>8183002438</td>\n",
       "      <td>sweetgreen</td>\n",
       "      <td>I’ve used Chipotle’s and other restaurants’ apps and this is by far the easiest to use and best interface. Not to mention it is similar in price to get a salad delivered and the food is absolutely amazing!! I do have two suggestions: (I) allow the user to add more than two bases and (ii) allow for the use of Apple Pay at checkout. Thanks :)!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>Very Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>9187505053</td>\n",
       "      <td>OwO Novel - Read Romance Story</td>\n",
       "      <td>The app is not worth 5 stars and the cost for chapters keeps going up</td>\n",
       "      <td>5</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60842</th>\n",
       "      <td>9288815829</td>\n",
       "      <td>Bible</td>\n",
       "      <td>I use this app every day. Easy and intuitive. I like all the different versions. I would love to see a chronological version and a Reference to Jesus version. I want plans that are for one day a week.</td>\n",
       "      <td>5</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                        app_name  \\\n",
       "76544  10201072201   Ad Block One: Tube Ad Blocker   \n",
       "82700   8833410900  Cleanup: Phone Storage Cleaner   \n",
       "26968   8183002438                      sweetgreen   \n",
       "2161    9187505053  OwO Novel - Read Romance Story   \n",
       "60842   9288815829                           Bible   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                         content  \\\n",
       "76544                                                                                                                                                                                                                                                                                                                                                    Awesome   \n",
       "82700                                                                                                                                                                                                                                                                                                                                        Save time and space   \n",
       "26968  I’ve used Chipotle’s and other restaurants’ apps and this is by far the easiest to use and best interface. Not to mention it is similar in price to get a salad delivered and the food is absolutely amazing!! I do have two suggestions: (I) allow the user to add more than two bases and (ii) allow for the use of Apple Pay at checkout. Thanks :)!!!   \n",
       "2161                                                                                                                                                                                                                                                                                       The app is not worth 5 stars and the cost for chapters keeps going up   \n",
       "60842                                                                                                                                                   I use this app every day. Easy and intuitive. I like all the different versions. I would love to see a chronological version and a Reference to Jesus version. I want plans that are for one day a week.   \n",
       "\n",
       "       rating   an_sentiment  \n",
       "76544       5  Very Positive  \n",
       "82700       5  Very Positive  \n",
       "26968       5  Very Positive  \n",
       "2161        5       Negative  \n",
       "60842       5        Neutral  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"id\", \"app_name\", \"content\", \"rating\", \"an_sentiment\"]].sample(n=5, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this sample, several observations are notable:\n",
    "\n",
    "1. **Ad Block One: Tube Ad Blocker (\"Awesome\")**: The 5-star rating and \"Very Positive\" sentiment remain well-aligned, as the single-word feedback conveys a clear and enthusiastic endorsement. No further action needed here.\n",
    "\n",
    "2. **Cleanup: Phone Storage Cleaner (\"Save time and space\")**: The sentiment analysis again correctly identifies the positive tone of the review, which matches the 5-star rating. The short, impactful statement reflects high user satisfaction with the app's functionality.\n",
    "\n",
    "3. **sweetgreen**: The expanded review content continues to justify the \"Very Positive\" sentiment and the 5-star rating. The user expresses enthusiasm about the app's interface, ease of use, and the quality of the food. Despite suggesting improvements (like adding more bases and supporting Apple Pay), the overall sentiment remains overwhelmingly positive. This is a good example of how constructive feedback can coexist with high satisfaction, and the sentiment analysis accurately captures the overall positive tone.\n",
    "\n",
    "4. **OwO Novel - Read Romance Story**: The mismatch between the negative content and the 5-star rating becomes even more evident with the added details. The user explicitly states that the app \"is not worth 5 stars\" and criticizes the rising cost for chapters. This discrepancy is likely a case where the sentiment model is correct in detecting negativity, but the user gave a high rating that contradicts their review. This case suggests that users may sometimes give ratings that do not reflect their written feedback, highlighting the complexity of relying solely on ratings for sentiment analysis.\n",
    "\n",
    "5. **Bible**: The review content provides constructive feedback alongside a description of regular app use. The suggestions for additional features, like a chronological version and specific plans, are not emotionally charged, which supports the \"Neutral\" sentiment label. However, the 5-star rating indicates a high level of satisfaction despite the neutral tone of the review. This suggests that the user is content overall but expressed feedback in a more factual manner. The model’s labeling is understandable, but incorporating more contextual understanding might help align sentiment labels more closely with ratings in cases like this.\n",
    "\n",
    "### Key Takeaways and Recommendations:\n",
    "- **sweetgreen**: The sentiment analysis does well to capture overall positivity despite the presence of suggestions for improvement, demonstrating robustness in handling mixed feedback.\n",
    "- **OwO Novel - Read Romance Story**: This highlights a potential gap in understanding user intent behind ratings. Further investigation into user behavior (such as high ratings paired with negative comments) may provide insights into refining sentiment analysis models.\n",
    "- **Bible**: This review underscores the challenge of interpreting reviews that are positive overall but expressed in a neutral tone. Sentiment analysis might benefit from additional heuristics or metadata to better align with user ratings.\n",
    "\n",
    "Overall, these examples illustrate the complexities of sentiment analysis when ratings and content don’t always align perfectly, but your model appears to be performing well in capturing the general sentiment conveyed by the text. Let me know if you’d like to explore further improvements or adjustments!\n",
    "\n",
    "In the next section, we will add perplexity, a proxy measure for gibberish in review text, to the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
