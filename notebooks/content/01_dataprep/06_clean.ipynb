{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "In the previous section, we analyzed the AppVoCAI dataset, evaluating its validity, completeness, uniqueness, relevance, and adherence to data privacy concerns. This section is about duplicate deleting, language filtering, artifact removing, PII masking, character normalizing data cleaning. Our data cleaning methodology focuses on addressing critical data quality issues that could undermine the integrity of downstream analyses, while preserving the text as close to its original form as possible. By adopting this conservative approach, we tackle key issues without sacrificing the nuance and representativeness of the data, ensuring the models are presented with rich, authentic input.\n",
    "\n",
    "## Data Cleaning Key Evaluation Questions (KEQs)\n",
    "Although, this data cleaning approach comprises many of the preprocessing techniques commonly found in the literature {cite}`symeonidisComparativeEvaluationPreprocessing2018`, the following data cleaning approach is motivated by three guiding questions.\n",
    "\n",
    "1. What’s essential to remove, and what can be left intact to preserve meaning?\n",
    "2. How do we best preserve text richness and nuance?\n",
    "3. How can the data cleaning process best exploit model strengths towards optimal model performance?\n",
    "\n",
    "These Key Evaluation Questions (KEQs) crystallized our approach which balanced data quality with model sophistication.\n",
    "\n",
    "## Data Cleaning Strategy\n",
    "The following describes our data cleaning process and steps, executed in the order listed. We begin with 'safe' techniques that carry minimal risk of compromising downstream cleaning tasks. For instance, UTF-8 encoding can impact the accuracy of language detection algorithms, especially if characters carry language-specific information. Removing special characters may compromise the detection of Personally Identifiable Information (PII) such as URLs and email addresses. As the process progresses, steps carry a greater impact on the data, its expressiveness, and representation.\n",
    "\n",
    "Our minimalist, *leave-as-is* approach can depart from data cleaning orthodoxy and standard practice. In such cases, we are transparent with our rationale. With that, our process is as follows:\n",
    "\n",
    "1. **Review ID Deduplication**: For duplicate review IDs, our policy for retention is based on several criteria: the most recent review date is prioritized, followed by the longest review text, and, if all else is equal, the review with the lowest row index is retained. This ensures that we keep the most informative and relevant reviews.\n",
    "2. **Control Characters**: We remove non-printable characters from the Unicode and ASCII character sets that are used to control text flow or hardware devices (e.g., newline, tab, or carriage return). These characters have no analytical value and can interfere with text processing.\n",
    "3. **Privacy**: URLs, email addresses and phone numbers are removed from the dataset to ensure adherence to data privacy and minimal information policies.\n",
    "4. **Remove Non-English Text**: We identify and remove non-English app names and reviews to maintain linguistic uniformity within the dataset, which is crucial for consistent language-based analysis.\n",
    "5. **HTML Characters**: Common in scraped data, HTML entities (e.g., `&amp;`, `&#39;`) are removed as they do not convey meaningful content. This ensures that the text is clean and ready for analysis.\n",
    "6. **Accents and Diacritics**: We normalize accented characters (e.g., converting `é` to `e`) to reduce unnecessary text variation, which simplifies analysis without compromising the meaning of the content.\n",
    "7. **Elongation Handling**: Elongated words (e.g., \"soooo\") convey emphasis in informal text, which is valuable for sentiment analysis. We use a threshold approach to limit characters that appear four or more times consecutively to a maximum of three (e.g., \"soooo\" becomes \"sooo\"), preserving emphasis while maintaining readability.\n",
    "8. **Repetition**: Excess character, sequence, word and phrase repetition is reduced, but not eliminated to perserve artifacts that may signal emphasis.\n",
    "9. **Non-Informative Reviews**: Reviews that don't match minimum length criteria are removed.\n",
    "10. **Special Characters**: Excessive special characters can indicate SPAM, emotional intensity, or nonsensical content. We apply a threshold: if special characters make up more than 30% of the review text, the review is removed. \n",
    "11. **Excessive Whitespace**: Excessive whitespace is removed.\n",
    "\n",
    "## Data Cleaning Techniques Not Implemented\n",
    "In natural language processing (NLP), text cleaning measures such as lower-casing, contraction and abbreviation expansion, spelling correction, and the removal of emoticons, emojis, and other artifacts are considered standard practice. Given that transformer models are fine-tuned on large user generated content datasets such as IMDB Movie Reviews and SemEval Laptop Reviews dataset, they are highly adept at handling a wide variety of tokens, including emojis, spelling variations, abbreviations and contractions. So, we take a **leave emojis as-is** approach. By leveraging the inherent strengths of transformer - particularly their ability to tokenize subword units and learn from context — we preserve the natural, authentic nature of user-generated content.\n",
    "\n",
    "Hey Siri, play my Data Cleaning playlist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "from discover.flow.stage.data_prep.clean import DataCleaningStage\n",
    "from discover.core.flow import PhaseDef, StageDef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Dependency Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.stage.base\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Pipeline\n",
    "This code snippet demonstrates how to set up and run a data cleaning stage based on a configuration obtained from a configuration reader. Here’s a breakdown of the steps:\n",
    "\n",
    "1. **Obtain the Configuration**: \n",
    "   - A `FlowConfigReader` instance (`reader`) is used to load the configuration. \n",
    "   - The `get_stage_config` method retrieves the stage configuration for data preparation and cleaning.\n",
    "\n",
    "2. **Build the Data Cleaning Stage**:\n",
    "   - The `DataCleaningStage.build` method initializes the data cleaning stage with the provided `stage_config`. Setting `force=False` ensures the stage is only built if the endpoint doesn't already exists.\n",
    "\n",
    "3. **Run the Data Cleaning Stage**:\n",
    "   - Finally, the `run` method executes the data cleaning stage and returns an `asset_id`, which likely identifies the cleaned dataset or asset generated by this stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:47:51 PM] [DEBUG] [discover.flow.stage.base.DataCleaningStage] [run] : Execution path: RUN\n",
      "[11/24/2024 07:47:51 PM] [DEBUG] [discover.infra.service.spark.session.SparkSessionPool] [_create_session] : Creating a spark session.\n",
      "[11/24/2024 07:47:51 PM] [DEBUG] [discover.infra.service.spark.session.SparkSessionPool] [_create_session] : Creating an Spark session. log4j Configuration: file:/home/john/projects/appvocai-discover/log4j.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                              Data Cleaning Stage                               #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                          DetectOrRepairUniquenessTask                          \n",
      "                          ----------------------------                          \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairUniquenessTask\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.44 seconds\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairControlCharsTask\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.07 seconds\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairURLTask\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.06 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                                 Runtime | 0.44 seconds\n",
      "\n",
      "\n",
      "                         DetectOrRepairControlCharsTask                         \n",
      "                         ------------------------------                         \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                                 Runtime | 0.07 seconds\n",
      "\n",
      "\n",
      "                             DetectOrRepairURLTask                              \n",
      "                             ---------------------                              \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                                 Runtime | 0.06 seconds\n",
      "\n",
      "\n",
      "                         DetectOrRepairEmailAddressTask                         \n",
      "                         ------------------------------                         \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairEmailAddressTask\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:03 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.06 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairPhoneNumberTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:03\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.05 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                                 Runtime | 0.06 seconds\n",
      "\n",
      "\n",
      "                         DetectOrRepairPhoneNumberTask                          \n",
      "                         -----------------------------                          \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:03\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.05 seconds\n",
      "\n",
      "\n",
      "                          DetectOrRepairNonEnglishTask                          \n",
      "                          ----------------------------                          \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairNonEnglishTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.16 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.16 seconds\n",
      "\n",
      "\n",
      "                          DetectOrRepairNonEnglishTask                          \n",
      "                          ----------------------------                          \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairNonEnglishTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.28 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairHTMLCharsTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.04 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairAccentedCharsTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.09 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairRepeatedCharactersTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.28 seconds\n",
      "\n",
      "\n",
      "                          DetectOrRepairHTMLCharsTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.04 seconds\n",
      "\n",
      "\n",
      "                        DetectOrRepairAccentedCharsTask                         \n",
      "                        -------------------------------                         \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.09 seconds\n",
      "\n",
      "\n",
      "                      DetectOrRepairRepeatedCharactersTask                      \n",
      "                      ------------------------------------                      \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.04 seconds\n",
      "\n",
      "\n",
      "                        DetectOrRepairRepeatedWordsTask                         \n",
      "                        -------------------------------                         \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairRepeatedWordsTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.04 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairRepeatedPhraseTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.04 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairShortReviewsTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.08 seconds\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairExcessiveSpecialCharsTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.04 seconds\n",
      "\n",
      "\n",
      "                        DetectOrRepairRepeatedPhraseTask                        \n",
      "                        --------------------------------                        \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.04 seconds\n",
      "\n",
      "\n",
      "                         DetectOrRepairShortReviewsTask                         \n",
      "                         ------------------------------                         \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.08 seconds\n",
      "\n",
      "\n",
      "                    DetectOrRepairExcessiveSpecialCharsTask                     \n",
      "                    ---------------------------------------                     \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.04 seconds\n",
      "\n",
      "\n",
      "                     DetectOrRepairExcessiveWhitespaceTask                      \n",
      "                     -------------------------------------                      \n",
      "                          Start Datetime | Sun, 24 Nov 2024 19:48:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Task: DetectOrRepairExcessiveWhitespaceTask\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Started: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Completed: Sun, 24 Nov 2024 19:48:04\n",
      "[11/24/2024 07:48:04 PM] [DEBUG] [Anomaly.run] [wrapper] : Runtime: 0.04 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Sun, 24 Nov 2024 19:48:04\n",
      "                                 Runtime | 0.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/24/2024 07:51:55 PM] [DEBUG] [Stage.run] [wrapper] : Stage: Data Cleaning Stage\n",
      "[11/24/2024 07:51:55 PM] [DEBUG] [Stage.run] [wrapper] : Stage Started: Sun, 24 Nov 2024 19:47:51\n",
      "[11/24/2024 07:51:55 PM] [DEBUG] [Stage.run] [wrapper] : Stage Completed: Sun, 24 Nov 2024 19:51:55\n",
      "[11/24/2024 07:51:55 PM] [DEBUG] [Stage.run] [wrapper] : Stage Runtime: 4.0 minutes and 4.62 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                              Data Cleaning Stage                               \n",
      "                              ===================                               \n",
      "                           Stage Started | Sun, 24 Nov 2024 19:47:51\n",
      "                         Stage Completed | Sun, 24 Nov 2024 19:51:55\n",
      "                           Stage Runtime | 4.0 minutes and 4.62 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(phase=PhaseDef.DATAPREP, stage=StageDef.CLEAN)\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = DataCleaningStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing\n",
    "With data cleaning complete, we have addressed the critical anomalies without over-processing.\n",
    "\n",
    "In the next section, we turn our attention to data enrichment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
