{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Anomaly Detection (DQAD)\n",
    "Data Quality Anomaly Detection and cleaning are standard parts of many NLP pipelines, and for good reason: machine learning models often struggle with inconsistencies and irrelevant artifacts in text data, which can degrade performance. Traditional models, in particular, were highly sensitive to noise, requiring rigorous preprocessing to function effectively.\n",
    "\n",
    "However, transformer models, such as BERT, which was trained on a corpus of approximately **3.3 billion words** from sources like BooksCorpus and English Wikipedia, have demonstrated remarkable robustness to linguistic noise. Their ability to handle variations in text, such as abbreviations, emojis, slang, internet jargon, grammatical errors, informal word forms, and misspellings, stems from a combination of subword tokenization techniques and the innovative self-attention mechanism.   \n",
    "\n",
    "1. **Misspellings**: Subword tokenization techniques, like Byte Pair Encoding (BPE) and SentencePiece, break misspelled words into recognizable subword components. This allows models to leverage existing subword embeddings and infer the intended meaning, even when spelling deviations occur. The model still maintains high semantic accuracy because it can assemble meaning from familiar patterns rather than needing a perfect match. \n",
    "2. **Slang and Informal Language**: Transformers are trained on diverse, real-world text that includes slang and informal expressions, making them adept at understanding and processing these variations. Subword tokenization decomposes these unconventional words into smaller units that the model has encountered in other contexts, enabling generalization. Additionally, transformersâ€™ vast training data captures the distribution and use of slang, embedding these linguistic nuances effectively. \n",
    "3. **Emojis and Special Characters**: Subword tokenization treats emojis and special symbols as unique tokens, preserving their semantic value. The self-attention mechanism allows the model to integrate these elements contextually, understanding their contribution to sentiment or meaning within the text. By attending to the relationships between emojis and surrounding words, the model can interpret and generate text that accurately reflects emotional tone or emphasis. \n",
    "4. **Abbreviations and Internet Jargon**: Abbreviations and internet-specific language are broken down into meaningful subword segments, allowing transformers to recognize patterns and relate them to standard language forms. The self-attention mechanism plays a crucial role here by dynamically assigning importance to different parts of the input sequence, enabling the model to understand the intended message despite the use of abbreviations. \n",
    "5. **Grammatical Errors and Informal Word Forms**: The self-attention mechanism is a fundamental innovation in transformer models. It enables the model to establish contextual relationships between words regardless of their order or grammatical correctness. By weighing the relevance of each word in relation to others, the model captures the overarching meaning even in the presence of syntax errors or informal language structures. This flexibility makes transformers robust to variations that would otherwise disrupt traditional models.\n",
    "\n",
    "Moreover, studies have shown that some types of \"useful\" noise, such as informal language and emojis, can enhance model performance and generalizability, as they better simulate real-world text scenarios {cite}`languageandmultimodalailamalabimperialcollegelondonukBetterUnderstandingNoise2021`. By preserving or even embracing this *useful* noise, models become more adaptable and effective in practical applications, demonstrating the nuanced trade-offs in handling linguistic noise.\n",
    "\n",
    "Therefore, we take a nuanced, task-specific approach to data quality assessment and anomaly detection, isolating and removing only *harmful* noise. We define harmful noise as artifacts that do not carry meaning or distort the intended meaning of the text. To ensure high data quality, we assess and flag observations to support analysis along several dimensions of data quality.\n",
    "\n",
    "## Accuracy Dimension\n",
    "The **Accuracy** dimension in text data quality focuses on the correctness and reliability of textual information, ensuring that the content represents what is intended without introducing errors or distortions. In the context of Natural Language Processing (NLP), accuracy checks are particularly crucial as they help maintain the integrity of the text data that models rely on to make predictions or derive insights.\n",
    "\n",
    "1. **Excessive Special Characters**: The presence of excessive or random special characters can corrupt the intended meaning of text and make it harder for models to interpret context. Accuracy checks ensure that these characters are only present when they add legitimate semantic value, such as in programming-related text or stylized writing. \n",
    "2. **Non-ASCII Characters**: While transformers can process non-ASCII characters, they may introduce unintended complexities or errors, especially when non-ASCII content is mixed into primarily English text without a clear purpose. Accuracy checks flag these occurrences to determine if they are contextually appropriate or represent an error in the data. \n",
    "3. **Control Characters**: Control characters, which are non-printable characters like tabs or line breaks embedded in text data, can disrupt text parsing and processing. Ensuring their absence or appropriate use maintains the structural accuracy needed for smooth NLP operations.\n",
    "4. **HTML Characters**: Text data sourced from the web may contain HTML tags or character entities that interfere with the text's readability and model understanding. Accuracy checks sanitize or transform these elements to their intended textual form. \n",
    "5. **Excessive Whitespace**: Extra spaces or line breaks, though seemingly minor, can affect text tokenization and representation in models. Normalizing whitespace ensures text is processed in a consistent, meaningful way. \n",
    "6. **Accented and Diacritic Characters**: While accented characters are valid in many languages, their unintended presence in primarily non-accented text can indicate data entry errors. Checks for these characters verify if they are linguistically appropriate or require correction. \n",
    "7. **Elongation**: Text elongation, like in \"sooo coool,\" is often used to emphasize words but may not be handled uniformly by models. Accuracy checks flag or normalize elongation to ensure consistent semantic interpretation. \n",
    "8. **Low Perplexity**: In the context of language models, low perplexity often signals repetitive or predictable patterns that may not carry substantive meaning. Ensuring text has appropriate complexity and variability is crucial for high-quality, informative data.\n",
    "\n",
    "Bottom line, the **Accuracy** dimension addresses the integrity of text content, ensuring that linguistic artifacts and patterns do not distort the meaning or introduce errors that could mislead models or downstream applications.\n",
    "\n",
    "## Relevance Dimension\n",
    "The **Relevance** dimension in text data quality ensures that the content is contextually appropriate and meaningful for the specific NLP task or analysis at hand. In other words, the text must be pertinent to the domain, language, or focus of the project. Relevance checks filter out content that could mislead models or degrade the performance of algorithms by introducing off-topic or linguistically inconsistent information.\n",
    "1. **Non-English App Names**: In datasets where the primary focus is on English-language content, non-English app names can be a source of confusion or skew analysis results. Relevance checks flag these instances, allowing us to either exclude or process them separately to maintain linguistic consistency. \n",
    "2. **Non-English Review Text**: Similar to non-English app names, reviews written in languages other than English may be irrelevant to models trained specifically on English text. Relevance checks identify non-English text, helping ensure the data aligns with the model's language capabilities and task requirements. \n",
    "3. **Review Length < 3**: Very short reviews, typically less than three words, often lack substantive information or context. These reviews are unlikely to provide meaningful insights and may act as noise, affecting sentiment analysis or topic modeling performance. Relevance checks filter these short reviews to maintain a focus on text that contributes valuable content to the analysis.\n",
    "\n",
    "By assessing relevancy, we ensure that the text data are appropriate, meaningful, and aligned with the goals of the analysis. This dimension helps avoid the inclusion of extraneous or off-topic content that could distort model training or analysis results.\n",
    "\n",
    "## Validity Dimension\n",
    "The **Validity** dimension in text data quality ensures that the content adheres to expected formats, structures, and rules, making it suitable for processing and analysis. Validity checks identify and flag content that deviates from these established norms, as such deviations can hinder the performance of NLP models and introduce inaccuracies. \n",
    "1. **URLs**: Reviews containing URLs may not provide meaningful textual content for analysis and can disrupt language models. Validity checks identify and flag URLs, allowing for their removal or replacement to maintain textual coherence. \n",
    "2. **Phone Numbers**: Similar to URLs, phone numbers are often irrelevant to the semantic content of a review and may interfere with text processing. Validity checks detect phone numbers, ensuring that they are either masked or removed to avoid skewing the analysis. \n",
    "3. **Email Addresses**: Email addresses can introduce noise and potentially violate privacy policies. Detecting and handling these elements helps maintain data integrity and privacy while ensuring the text remains analyzable. \n",
    "4. **Repeated Sequences**: Reviews with excessive repetition of sequences, such as repeated letters, words, or patterns, can indicate spam or low-quality content. Validity checks identify such sequences, enabling corrective measures to ensure high-quality input for NLP models. \n",
    "5. **Repeated Words**: Similar to repeated sequences, the presence of redundant words may indicate automated or spam-like content. Detecting and addressing these issues helps maintain the linguistic integrity of the dataset. \n",
    "6. **Repeated Phrases**: Repeated phrases can dilute the semantic richness of the text and may signify low-quality or irrelevant content. Validity checks ensure these phrases are flagged for removal or further examination. \n",
    "\n",
    "By incorporating these **Validity** checks, we verify that the textual data adheres to expected norms and formats, reducing the risk of disruptions during text analysis. \n",
    "\n",
    "## Uniqueness Dimension\n",
    "The **Uniqueness** dimension in text data quality emphasizes the importance of having distinct and non-duplicative content within a dataset. Ensuring uniqueness is crucial to prevent redundancy and to maintain the integrity and reliability of analytical results. In text processing, repeated or duplicated content can skew analysis, reduce the diversity of linguistic features, and lead to misleading insights.  \n",
    "1. **Duplicate Review Id**: Duplicate review identifiers indicate that the same piece of text has been repeated in the dataset. This can artificially inflate the perceived frequency of specific sentiments or topics, impacting statistical analysis and model performance. Uniqueness checks detect and flag duplicate review IDs, allowing for the removal of redundant entries and ensuring that each review contributes uniquely to the analysis.\n",
    "\n",
    "By enforcing the **Uniqueness** dimension, we ensure that analyses are based on a diverse and representative sample of the text.\n",
    "\n",
    "Next, we construct and execute the **Data Quality Anomaly Detection** pipeline, adding indicators of data accuracy, validity, uniqueness, and relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "from discover.core.flow import StageDef\n",
    "from discover.flow.data_prep.dqd.stage import DataQualityDetectionStage\n",
    "from discover.core.flow import PhaseDef, StageDef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.data_prep.base.stage\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Anomaly Detection (DQAD) Pipeline\n",
    "Following our standard orchestration process, we lodd the configuration using the `FiowConfiguReader`, then construct and execute the **DataQualityDetectionStage** pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20/2024 07:49:23 AM] [DEBUG] [discover.flow.data_prep.base.stage.DataQualityDetectionStage] [run] : Data prep execution path: RUN\n",
      "[11/20/2024 07:49:23 AM] [DEBUG] [discover.infra.service.spark.session.SparkSessionPool] [_create_session] : Creating a spark session.\n",
      "[11/20/2024 07:49:23 AM] [DEBUG] [discover.infra.service.spark.session.SparkSessionPool] [_create_session] : Creating an Spark session. log4j Configuration: file:/home/john/projects/appvocai-discover/log4j.properties\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                      Data Quality Anomaly Detection Stage                      #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                            DetectOrRepairPercentile                            \n",
      "                            ------------------------                            \n",
      "                          Start Datetime | Wed, 20 Nov 2024 07:49:37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20/2024 07:49:40 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Task: DetectOrRepairPercentile\n",
      "[11/20/2024 07:49:40 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Started: Wed, 20 Nov 2024 07:49:37\n",
      "[11/20/2024 07:49:40 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Completed: Wed, 20 Nov 2024 07:49:40\n",
      "[11/20/2024 07:49:40 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Runtime: 3.42 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Wed, 20 Nov 2024 07:49:40\n",
      "                                 Runtime | 3.42 seconds\n",
      "\n",
      "\n",
      "                         DetectOrRepairMinimumValueTask                         \n",
      "                         ------------------------------                         \n",
      "                          Start Datetime | Wed, 20 Nov 2024 07:49:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20/2024 07:49:41 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Task: DetectOrRepairMinimumValueTask\n",
      "[11/20/2024 07:49:41 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Started: Wed, 20 Nov 2024 07:49:40\n",
      "[11/20/2024 07:49:41 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Completed: Wed, 20 Nov 2024 07:49:41\n",
      "[11/20/2024 07:49:41 AM] [DEBUG] [DetectOrRepairTask.run] [wrapper] : Runtime: 0.83 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Wed, 20 Nov 2024 07:49:41\n",
      "                                 Runtime | 0.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20/2024 07:49:44 AM] [DEBUG] [DataPrepStage.run] [wrapper] : Stage: Data Quality Anomaly Detection Stage\n",
      "[11/20/2024 07:49:44 AM] [DEBUG] [DataPrepStage.run] [wrapper] : Stage Started: Wed, 20 Nov 2024 07:49:23\n",
      "[11/20/2024 07:49:44 AM] [DEBUG] [DataPrepStage.run] [wrapper] : Stage Completed: Wed, 20 Nov 2024 07:49:44\n",
      "[11/20/2024 07:49:44 AM] [DEBUG] [DataPrepStage.run] [wrapper] : Stage Runtime: 21.12 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                      Data Quality Anomaly Detection Stage                      \n",
      "                      ====================================                      \n",
      "                           Stage Started | Wed, 20 Nov 2024 07:49:23\n",
      "                         Stage Completed | Wed, 20 Nov 2024 07:49:44\n",
      "                           Stage Runtime | 21.12 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(phase=PhaseDef.DATAPREP, stage=StageDef.DQD)\n",
    "# Build and run the stage\n",
    "stage = DataQualityDetectionStage.build(\n",
    "    stage_config=stage_config, return_dataset=False, force=FORCE\n",
    ")\n",
    "dataset = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **Data Quality Anomaly Detection** we move on to **Data Quality Analysis (DQA)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-test-dataprep-dqd-review\n"
     ]
    }
   ],
   "source": [
    "from discover.assets.dataset import Dataset\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
