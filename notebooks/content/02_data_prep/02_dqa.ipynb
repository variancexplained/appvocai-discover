{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": [
                    "remove-cell"
                ]
            },
            "outputs": [],
            "source": [
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "import os\n",
                "\n",
                "if \"jbook\" in os.getcwd():\n",
                "    os.chdir(os.path.abspath(os.path.join(\"../..\")))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Quality Assessment\n",
                "The second stage of data processing is the Data Quality Assessment. This stage ensures that our dataset is ready for subsequent analysis and modeling tasks. By identifying and rectifying data quality issues early, we can avoid potential pitfalls that might compromise the integrity and accuracy of our results.\n",
                "\n",
                "## Data Quality Checks\n",
                "In this stage, we employ a series of tasks designed to identify and address any noise or irregularities within the dataset. Each task focuses on a specific aspect of data quality, ranging from detecting duplicate entries to identifying profanity, special patterns, and other potential sources of bias or distortion.\n",
                "1. **Duplicate Rows**: We identify and remove duplicate entries to ensure that each observation is unique, preventing skewed analyses and inflated metrics.\n",
                "2. **Null Values**: We detect and handle missing data appropriately, which could involve imputation, deletion, or flagging incomplete records for further investigation.\n",
                "3. **Non-English Text**: We check for and address non-English text in reviews and app names, as they may not be relevant to our analysis or could require special handling.\n",
                "4. **Emojis**: Emojis can carry significant meaning in certain contexts but might also introduce noise. We identify and decide on their treatmentâ€”whether to retain, remove, or translate them into textual representations.\n",
                "5. **Excessive Special Characters**: Special characters can disrupt text analysis and need to be managed, either by cleaning or encoding them appropriately.\n",
                "6. **Invalid Dates**: We verify that date values fall within expected ranges and formats, correcting or flagging anomalies for further review.\n",
                "7. **Invalid Ratings**: Ratings that fall outside the expected scale (e.g., 1 to 5) are identified and corrected or flagged.\n",
                "8. **Profanity**: We detect and handle profane content to ensure that our dataset adheres to appropriate usage standards, especially if it's intended for public or sensitive applications.\n",
                "9. **Special Patterns**: We identify and manage special patterns such as URLs, phone numbers, and emails. These patterns could be indicative of spam or need to be anonymized to protect privacy.\n",
                "\n",
                "By conducting these data quality checks, we ensure that our dataset is clean, reliable, and ready for detailed analysis. This foundational step sets the stage for accurate insights and robust conclusions in the subsequent phases of our data processing pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fasttext\n",
                "\n",
                "from discover.app.dqa import DataQualityAnalysis\n",
                "from discover.container import DiscoverContainer\n",
                "from discover.infra.config.orchestration import OrchestrationConfigReader\n",
                "from discover.orchestration.data_prep.stage import DataPrepStage\n",
                "\n",
                "fasttext.FastText.eprint = lambda x: None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dependency Container"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "container = DiscoverContainer()\n",
                "container.init_resources()\n",
                "container.wire(\n",
                "    modules=[\n",
                "        \"discover.orchestration.data_prep.stage\",\n",
                "        \"discover.orchestration.data_prep.dqa\",\n",
                "        \"discover.app.base\",\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Quality Assessment Pipeline\n",
                "The data quality assessment process conducts the 9 data quality checks, marking the observations that require attention."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Obtain the configuration\n",
                "from discover.orchestration.data_prep.stage import DataPrepStageCache\n",
                "\n",
                "reader = OrchestrationConfigReader()\n",
                "config = reader.get_config(\"phases\", namespace=False)\n",
                "stage_config = config[\"dataprep\"][\"stages\"][2]\n",
                "\n",
                "# Build and run Data Ingestion Stage\n",
                "stage = DataPrepStage.build(stage_config=stage_config, force=True)\n",
                "asset_id = stage.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Quality Impressions\n",
                "Let's get a summary of the data quality issues by type."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dqa = DataQualityAnalysis()\n",
                "dqa.summarize()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data quality assessment (DQA) conducted on the AppVoC dataset revealed several key issues that need to be addressed to ensure the integrity and reliability of the analysis. These issues include:\n",
                "\n",
                "- **Non-English**: Notable proportions of the app names (15%) and review content (4.9%) were flagged as being non-English.\n",
                "- **Emoji**: Approximately 6% of the reviews have emoji characters.\n",
                "- **Duplicates**: A small percentage (5.6%) have duplicate reviews.\n",
                "- **Special Characters**: A small percentage (< 2%) of reviews were noted for the presence of special characters in excessive proportions.\n",
                "- **Profanity**: About 1% of the reviews have language considered profane.\n",
                "- **Random Text**: Random text, indicated by high entropy scores, is present in less than 0.5% of the text.\n",
                "- **Sensitive Information**: The presence of sensitive information, such as email addresses, and phone numbers are relatively minimal.\n",
                "\n",
                "On the other hand:\n",
                "- **Null Values**: Fortunately, there were no null values detected in the dataset.\n",
                "- **Invalid Entries**: There were no invalid dates or invalid ratings found.\n",
                "\n",
                "Given these findings, the next step is to visually inspect a sample of the anomalies, then identify and treat the high-impact data quality issues. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Anomalies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dqa.get_non_english_apps()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This may involve, without limitation:\n",
                "\n",
                "- **Removing Duplicates**: Eliminating observations with duplicate review IDs.\n",
                "- **Handling Outliers**: Identifying and appropriately managing outliers in vote sums, and vote counts.\n",
                "- **Addressing Non-English Text**: Filtering or translating non-English reviews. \n",
                "- **filtering Noise**: Filtering or removing excessive special characters from reviews.\n",
                "- **Ensuring Clean Content**: Censor or remove reviews containing profanity.\n",
                "- **Remove Personal Data**: Personal identifying information such as phone numbers, and email addresses, would be removed.\n",
                "\n",
                "Cue the action!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from lingua import Language, LanguageDetectorBuilder\n",
                "\n",
                "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH]\n",
                "detector = LanguageDetectorBuilder.from_languages(*languages).build()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sklearn\n",
                "\n",
                "print(sklearn.__version__)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "appvocai",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
