{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "tags": [
                    "remove-cell"
                ]
            },
            "outputs": [],
            "source": [
                "import warnings\n",
                "\n",
                "warnings.filterwarnings(\"ignore\")\n",
                "import os\n",
                "\n",
                "if \"jbook\" in os.getcwd():\n",
                "    os.chdir(os.path.abspath(os.path.join(\"../..\")))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data Quality Assessment\n",
                "In the previous section, we provided an overview of the AppVoCAI dataset, including its structure, features, and distributions. The goal of this stage is to \n",
                "\n",
                "1. identify any unwanted artifacts in the dataset that could compromise the integrity and accuracy of our downstream modeling efforts, and\n",
                "2. design the data cleaning pipeline and text cleaning interventions to remove or otherwise treat these artifacts.\n",
                "\n",
                "It is important to clarify that this stage is focused on **data quality assessment** and **text cleaning**, rather than data preprocessing. While preprocessing tasks such as tokenization, lemmatization, stopword removal, and text normalization are crucial steps in preparing the dataset for model training, they are not the focus here. Instead, our goal is to address **anomalies**—such as duplicates, invalid characters, non-ASCII text, and other artifacts—that could compromise the integrity and reliability of downstream analysis. By ensuring the dataset is clean and free of unwanted noise, we lay the foundation for accurate, meaningful preprocessing and modeling in later stages.\n",
                "\n",
                "## Data Quality Context\n",
                "Downstream tasks such as sentiment analysis, classification, text summarization, and generation will leverage transformer-based models (like BERT, RoBERTa, and GPT), which have proven to be highly robust in handling various data anomalies and linguistic variations. Unlike traditional models such as Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM) networks, and Convolutional Neural Networks (CNNs)—which process data sequentially—transformers operate on entire sequences in parallel. This allows them to capture long-range dependencies and uncover subtle nuances and contextual relationships in language with near-human precision.\n",
                "\n",
                "However, research demonstrates that preprocessing can still significantly improve the performance of transformer models {cite}`siinoTextPreprocessingStill2024`. This synergy between preprocessing and model architecture suggests that a balanced approach is ideal. Our data preparation methodology focuses on addressing critical data quality issues that could undermine the integrity of downstream analyses, while preserving the text as close to its original form as possible. By adopting this conservative approach, we tackle key issues without sacrificing the nuance and representativeness of the data, ensuring the models are presented with rich, authentic input.\n",
                "\n",
                "## Data Quality Approach\n",
                "Although, our data quality and cleaning approach comprises many of the preprocessing techniques commonly found in the literature {cite}`symeonidisComparativeEvaluationPreprocessing2018`, three questions motivated the data quality design process.\n",
                "\n",
                "1. What’s essential to remove, and what can be left intact to preserve meaning?\n",
                "2. How do we best preserve text richness and nuance?\n",
                "3. How can the data cleaning process best exploit model strengths towards optimal model performance?\n",
                "\n",
                "These Key Evaluation Questions (KEQs) crystallized our approach which balanced data quality with model sophistication.\n",
                "\n",
                "---\n",
                "\n",
                "### Noise Removal\n",
                "Noise refers to characters or tokens that either distort the content or contribute little to understanding sentiment, intent, or behavior. Our approach to noise removal starts with the simpler and more common issues, followed by more nuanced decisions around special characters and punctuation.\n",
                "\n",
                "#### Encoding and Common Noise\n",
                "The first set of noise to address involves issues that are relatively easy to detect and remove, but can have a big impact on the clarity of the dataset:\n",
                "\n",
                "- **Encoding and Control Characters:** Often appearing as artifacts from different text encoding formats, these include characters that serve formatting or invisible functions in the text. They will be removed.\n",
                "- **Accents and Diacritics:** These will be normalized (e.g., converting `é` to `e`) to reduce unnecessary variation in the text.\n",
                "- **HTML Characters:** Common in scraped data, characters such as `&amp;` and `&#39;` will be removed as they do not add any meaningful content.\n",
                "- **Line Breaks and Excessive Whitespace:** Multiple line breaks and extra spaces will be condensed into a single space to ensure consistency and readability.\n",
                "- **Non-ASCII Characters:** While some non-ASCII characters (like certain symbols or non-English characters) may carry meaning, most introduce unnecessary complexity and will be removed. \n",
                "\n",
                "#### Special Characters\n",
                "Special characters can vary in importance, depending on their context in app reviews. To systematically handle special characters, we can categorize them into two groups: **those that should be removed** (because they add noise or don't carry useful information) and **those that should be retained** (because they might contribute to the meaning or sentiment in the text). Here's a breakdown:\n",
                "\n",
                "##### Special Characters to Remove \n",
                "These characters generally do not add meaningful content to app reviews and are mostly used for formatting or random emphasis. \n",
                "\n",
                "|     Special   Character     |          Examples          |                                                                  Rationale                                                                  |\n",
                "|:---------------------------:|:--------------------------:|:-------------------------------------------------------------------------------------------------------------------------------------------:|\n",
                "| Currency Symbols            | $, €, ¥, £                 | Unlikely to be relevant in app reviews unless specifically analyzing   price-related content, usually captured in text rather than symbols. |\n",
                "| Mathematical Symbols        | +, =, *, /, ^              | Rarely convey sentiment or meaning in reviews and can clutter   tokenization.                                                               |\n",
                "| Logical/Programming Symbols | {}, [], <>, \\|, \\, ~, ;, : | Generally irrelevant unless for technical feedback; uncommon in reviews.                                                                    |\n",
                "| Ampersand                   | &                          | Often shorthand for 'and,' normalization improves consistency without   altering meaning.                                                   |\n",
                "| At Symbol                   | @                          | Primarily used for tagging or mentions; usually irrelevant in app   reviews.                                                                |\n",
                "| Hashtag                     | #                          | Adds noise unless analyzing hashtags or trends; generally unnecessary in   reviews.                                                         |\n",
                "| Percentage                  | %                          | Typically written as words in reviews (e.g., “80% battery” as 'eighty   percent battery'), unnecessary unless focusing on numbers.          |\n",
                "| Underscore                  | _                          | Found in URLs or filenames, generally meaningless in app reviews.                                                                           |\n",
                "| Pipe                        | \\|                         | Used as a separator or in technical contexts, generally adds no value in   app reviews.                                                     |\n",
                "| Backslash                   | \\                          | Part of escape sequences or formatting, unnecessary for understanding   text content.                                                       |\n",
                "\n",
                "##### Special Characters to Retain\n",
                "These characters might carry semantic or emotional weight and could enhance analyses such as sentiment, emphasis, or intensity detection:\n",
                "\n",
                "| Special   Character | Examples |                                                                    Rationale                                                                   |\n",
                "|:-------------------:|:--------:|:----------------------------------------------------------------------------------------------------------------------------------------------:|\n",
                "| Apostrophe          | '        | Important for contractions (e.g., “don’t”, “can’t”), which can affect   meaning if removed.                                                    |\n",
                "| Quotation Marks     | \"        | Useful for retaining structure when users quote something directly in   their review.                                                          |\n",
                "| Parentheses         | ()       | Often used to add clarifying details or side comments in reviews. They   can add meaning that shouldn’t be stripped.                           |\n",
                "| Hyphen              | -        | Important for words that are hyphenated or when users break up long   thoughts. It can also appear in numerical ranges (e.g., '5-10 minutes'). |\n",
                "\n",
                "\n",
                "#### Punctuation\n",
                "Punctuation presents more nuanced challenges, as it often affects sentence structure, tone, and emphasis. Standard punctuation such as periods, commas, exclamation points, and question marks will be kept. They are important for understanding sentence boundaries and emotional emphasis. Multiple punctuation marks (e.g., \"!!!\", \"???\") are also retained, as they often signify strong emotion or sentiment.\n",
                "\n",
                "### Personallly Identifiable Information (PII)\n",
                "In this data cleaning phase, personally identifiable information (PII), such as emails, URLs, and phone numbers, will undergo masking to ensure privacy and compliance with ethical standards for data use. Emails, for instance, are highly sensitive and can reveal specific user identities or contact details, risking the exposure of personally sensitive information. To mitigate this, email addresses will be systematically replaced with the marker `[EMAIL]`. Similarly, URLs—often including specific domains or personal resources—may unintentionally disclose identifiable or private information. Masking URLs as `[URL]` prevents unintended data leakage while retaining content structure for analysis. Additionally, phone numbers, inherently identifiable and private, will be marked as `[PHONE]`. Given their nature as direct contact points, the masking of phone numbers is essential to uphold confidentiality and meet data privacy regulations.\n",
                "\n",
                "These masking protocols enable comprehensive content analysis while upholding data privacy obligations and reducing risks of re-identification in sensitive datasets. This approach allows the dataset to retain its structural and contextual integrity, facilitating meaningful analysis without compromising user privacy.\n",
                "### Language \n",
                "As part of the data quality assessment strategy, non-English app names and reviews will be systematically identified and removed to ensure linguistic consistency within the dataset. This process involves the application of advanced language detection models, which will analyze app names and review text to detect non-English content. Entries flagged as non-English will be excluded from the dataset, ensuring that only English-language data remains for analysis.\n",
                "\n",
                "The rationale for this step lies in the need to maintain coherence in language-based tasks such as sentiment analysis, aspect-based sentiment analysis (ABSA), and emotion detection, all of which rely on clear, uniform input. By removing non-English content, we aim to prevent noise, misinterpretation, or inconsistencies that could undermine the accuracy of insights. This approach is designed to focus the analysis on the English-speaking market, aligning the dataset with the target audience and improving the overall relevance and quality of the findings.\n",
                "\n",
                "### Data Normalization\n",
                "Standard NLP normalization includes key processes such as converting emoticons and emojis to text, correcting spelling, expanding abbreviations and acronyms, expanding contractions, and removing elongation. The following data quality analysis and cleaning strategies aim to preserve meaning, text richness, and nuance while leveraging the strengths of transformer models to achieve optimal performance. By focusing on essential elements, we ensure that unnecessary noise is removed without compromising the depth and context of the original content, allowing for more accurate and insightful analysis in downstream NLP tasks.\n",
                "\n",
                "#### Emoticons and Emojis Conversion\n",
                "\n",
                "Emoticons and emojis are frequently used in app reviews to express emotions, sentiments, or nuanced meanings that words alone may not fully capture. The challenge in handling these symbols lies in balancing the need to preserve their meaning with the ability of transformer models to interpret them effectively. While transformers, particularly models with advanced tokenizers such as BPE (Byte Pair Encoding) or WordPiece, are capable of recognizing emojis as individual tokens, there are trade-offs in terms of interpretability and model performance. Below, we outline two potential approaches: conversion of emojis to text and leaving them as-is, along with the rationale for each.\n",
                "\n",
                "#### 1. **Convert Emoticons and Emojis to Text**\n",
                "   **Approach**: In this strategy, emoticons and emojis are converted into their corresponding textual descriptions (e.g., \"😊\" becomes \"smiling face\" or \"happy\"). This process can be done using predefined emoji dictionaries that map each symbol to a meaningful word or phrase. \n",
                "\n",
                "   **Justification**:\n",
                "   - **Improved Interpretability**: Converting emojis to text ensures that their emotional or symbolic meaning is explicitly captured, which may enhance sentiment analysis or emotion detection tasks. Models will then treat these symbols as regular words, improving semantic understanding.\n",
                "   - **Preserving Sentiment**: Emojis often carry significant emotional weight, which can be missed if the model treats them as independent, isolated tokens. By converting them to text, we ensure that the full emotional context of the review is retained and understood by the model.\n",
                "   - **Better Alignment with Text-Based Models**: Transformer models, particularly those trained on text data (e.g., BERT, RoBERTa), may perform better when they process complete words rather than unfamiliar symbols, as text-based tokens align with the model’s pretraining. This conversion provides uniform input for the model to interpret, reducing potential ambiguity.\n",
                "\n",
                "   **Challenges**:\n",
                "   - **Loss of Brevity and Flow**: In informal text like app reviews, converting \"😊\" to \"smiling face\" might disrupt the brevity or stylistic tone of the content. This change could affect the naturalness of user-generated content, especially in sentiment-heavy reviews.\n",
                "   - **Limited Context in Text Conversion**: Some emojis have context-specific meanings (e.g., a heart emoji may indicate love, approval, or even sarcasm), and these meanings may not always be fully captured by a generic text replacement.\n",
                "\n",
                "#### 2. **Leave Emojis and Emoticons As-Is**\n",
                "   **Approach**: This strategy involves keeping emojis and emoticons in their original form and allowing the transformer model’s tokenizer to handle them natively. Tokenizers like BPE or WordPiece can break down emojis into subword units or treat them as individual tokens, based on the pretraining corpus.\n",
                "\n",
                "   **Justification**:\n",
                "   - **Capable Tokenizers**: Modern transformer models are designed to handle a wide variety of tokens, including emojis. Since these models are trained on large, diverse datasets that likely include emojis, they can recognize and process them without needing explicit conversion to text. For example, BERT can treat \"😊\" as a unique token, potentially learning its context from the surrounding text.\n",
                "   - **Retaining Natural Language Flow**: In user-generated content like app reviews, leaving emojis intact preserves the natural flow and brevity of the language. This is particularly relevant for informal or sentiment-heavy reviews, where emojis are often integral to conveying tone or nuance.\n",
                "   - **Model Pretraining**: Transformers pretrained on large-scale internet corpora (e.g., GPT models) may have already learned embeddings for commonly used emojis, allowing the model to understand the sentiment behind them without needing explicit conversion.\n",
                "\n",
                "   **Challenges**:\n",
                "   - **Ambiguity in Meaning**: While transformer models can process emojis, they may not always capture the full sentiment or emotion conveyed by them, particularly if an emoji has multiple or context-specific meanings. This can reduce the accuracy of sentiment or emotion detection tasks.\n",
                "   - **Inconsistent Handling of Emojis**: Since not all emojis carry clear or universal meanings, models might struggle with low-frequency or niche emojis that were less represented in the training data.\n",
                "\n",
                "### Recommended Approach: **As-Is for Transformer Models**\n",
                "Given the advanced capabilities of modern transformer tokenizers and the likelihood that app reviews will contain common emojis that transformers have encountered during pretraining, leaving emojis **as-is** can be a more efficient and natural approach. This preserves the integrity of user-generated content, aligns well with the model’s existing knowledge, and allows the transformer’s contextual understanding to interpret these symbols effectively.\n",
                "\n",
                "The **as-is approach** exploits the strength of transformers to process a wide variety of tokens without adding additional complexity through text conversion. This is particularly important when dealing with informal text such as app reviews, where brevity and emotional tone are often conveyed through symbols rather than words. While converting to text might slightly improve interpretability in niche cases, the cost in terms of disrupting the natural flow of language and potentially introducing noise outweighs the benefits for most applications.\n",
                "\n",
                "However, for specialized tasks such as deep sentiment analysis, where capturing fine-grained emotional nuance is critical, a hybrid approach could be considered. In such cases, selectively converting only sentimentally significant emojis might enhance performance while keeping the overall text intact.\n",
                "\n",
                "\n",
                "In this Data Quality Assessment (DQA), we will execute a series of checks designed to uncover noise, inconsistencies, or anomalies within the dataset:\n",
                "\n",
                "1. **App ID/App Name Consistency**: We ensure that `app_id` and `app_name` align. A prior analysis revealed 14 more `app_id`s than `app_name`s, which will require further investigation.\n",
                "2. **Duplicate Review IDs**: We identified 117 duplicate review `id`s. These entries must be flagged for closer examination.\n",
                "3. **Duplicate Review Content**: Approximately 14% of the reviews were found to be duplicates. These reviews need to be reviewed for potential redundancy or noise.\n",
                "4. **Review Length Anomalies**: Zero-length reviews will be removed. Extremely long reviews will be inspected for signs of repetition or low-quality content.\n",
                "5. **Non-English Text**: Reviews and app names written in non-English may not be relevant to our analysis. We will identify and decide on appropriate handling for these entries.\n",
                "6. **Inappropriate Content**: Content such as URLs, phone numbers, email addresses, or other personally identifiable information will be treated as spam and either removed or masked.\n",
                "7. **Emojis**: Emojis can add valuable context in some cases but may introduce noise in others. We will assess whether to retain, remove, or convert emojis into textual equivalents.\n",
                "8. **Formatting Anomalies**: We will flag any entries with excessive whitespace, HTML, or other markup artifacts that could interfere with analysis.\n",
                "\n",
                "**Note on Exclusions**: While this assessment focuses on structural and formatting issues, certain aspects like profanity and spelling mistakes are not included in this phase. These may be addressed during the text quality assessment, which will focus on content and linguistic features.\n",
                "\n",
                "By performing these data quality checks, we identify and mark anomalies that will be addressed in the subsequent data cleaning stage. This ensures that our dataset is flagged for inconsistencies and potential issues, laying the groundwork for clean, reliable data. Resolving these issues will enhance the accuracy of our analyses and lead to more robust conclusions in the later phases of our data processing pipeline."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "hide-cell"
                ]
            },
            "source": [
                "## Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "tags": [
                    "hide-cell"
                ]
            },
            "outputs": [],
            "source": [
                "import fasttext\n",
                "\n",
                "from discover.analysis.dqa import DataQualityAnalysis\n",
                "from discover.container import DiscoverContainer\n",
                "from discover.infra.config.flow import FlowConfigReader\n",
                "from discover.flow.data_prep.dqa.stage import DQAStage\n",
                "\n",
                "fasttext.FastText.eprint = lambda x: None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "tags": [
                    "remove-cell"
                ]
            },
            "source": [
                "## Dependency Container"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "tags": [
                    "remove-cell"
                ]
            },
            "outputs": [],
            "source": [
                "container = DiscoverContainer()\n",
                "container.init_resources()\n",
                "container.wire(\n",
                "    modules=[\n",
                "        \"discover.flow.data_prep.stage\",\n",
                "        \"discover.flow.data_prep.dqa\",\n",
                "        \"discover.analysis.base\",\n",
                "    ],\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Quality Assessment Pipeline\n",
                "The data quality assessment process conducts the data quality checks, marking the observations that require attention. We begin with the configuration, then construct and run the DQAStage pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[10/24/2024 04:39:34 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-02_dqa-review-dataset.parquet from repository.\n",
                        "[10/24/2024 04:39:34 AM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-dataprep-dqa-review from the repository.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "# ============================================================================== #\n",
                        "#                         Data Quality Assessment Stage                          #\n",
                        "# ============================================================================== #\n",
                        "\n",
                        "\n",
                        "\n",
                        "                              DetectDuplicateTask                               \n",
                        "                              -------------------                               \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_identical_rows\n",
                        "                      Anomalies Detected | 0 (0.0%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                              DetectDuplicateTask                               \n",
                        "                              -------------------                               \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_identical_review_id\n",
                        "                      Anomalies Detected | 0 (0.0%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                              DetectDuplicateTask                               \n",
                        "                              -------------------                               \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_identical_review_content\n",
                        "                      Anomalies Detected | 3923 (6.65%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                            DetectMissingReviewsTask                            \n",
                        "                            ------------------------                            \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_review_missing\n",
                        "                      Anomalies Detected | 0 (0.0%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                              DetectNonEnglishTask                              \n",
                        "                              --------------------                              \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_non_english_review\n",
                        "                      Anomalies Detected | 2276 (3.86%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                              DetectNonEnglishTask                              \n",
                        "                              --------------------                              \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_non_english_app_name\n",
                        "                      Anomalies Detected | 1402 (2.38%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                                DetectEmojiTask                                 \n",
                        "                                ---------------                                 \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_has_emoji\n",
                        "                      Anomalies Detected | 3490 (5.91%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                                DetectEmailTask                                 \n",
                        "                                ---------------                                 \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_email\n",
                        "                      Anomalies Detected | 0 (0.0%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                                 DetectURLTask                                  \n",
                        "                                 -------------                                  \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_url\n",
                        "                      Anomalies Detected | 0 (0.0%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                             DetectPhoneNumberTask                              \n",
                        "                             ---------------------                              \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_phone_number\n",
                        "                      Anomalies Detected | 26 (0.04%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                            DetectNonAsciiCharsTask                             \n",
                        "                            -----------------------                             \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_non_ascii_chars\n",
                        "                      Anomalies Detected | 27252 (46.17%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                           DetectExcessiveNumbersTask                           \n",
                        "                           --------------------------                           \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_excessive_numbers\n",
                        "                      Anomalies Detected | 41 (0.07%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                             DetectControlCharsTask                             \n",
                        "                             ----------------------                             \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_control_chars\n",
                        "                      Anomalies Detected | 2 (0.0%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                         DetectExcessiveWhitespaceTask                          \n",
                        "                         -----------------------------                          \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_excessive_whitespace\n",
                        "                      Anomalies Detected | 7540 (12.78%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                              DetectHTMLCharsTask                               \n",
                        "                              -------------------                               \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_HTML_chars\n",
                        "                      Anomalies Detected | 5 (0.01%) of 59021 records\n",
                        "\n",
                        "\n",
                        "                         DetectInconsistentIdNamesTask                          \n",
                        "                         -----------------------------                          \n",
                        "                          Start Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                       Complete Datetime | Thu, 24 Oct 2024 04:39:34\n",
                        "                                 Runtime | 0.03 seconds\n",
                        "                               DQA Check | dqa_contains_inconsistent_app_id_name\n",
                        "                      Anomalies Detected | 8 (0.1%) of 8009 records\n",
                        "\n",
                        "\n",
                        "                         Data Quality Assessment Stage                          \n",
                        "                         =============================                          \n",
                        "                           Stage Started | Thu, 24 Oct 2024 04:39:34\n",
                        "                         Stage Completed | Thu, 24 Oct 2024 04:39:35\n",
                        "                           Stage Runtime | 1.04 seconds\n",
                        "                           Cached Result | True\n",
                        "\n",
                        "\n",
                        "# ============================================================================ #\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Obtain the configuration\n",
                "reader = FlowConfigReader()\n",
                "config = reader.get_config(\"phases\", namespace=False)\n",
                "stage_config = config[\"dataprep\"][\"stages\"][\"dqa\"]\n",
                "\n",
                "# Build and run Data Ingestion Stage\n",
                "stage = DQAStage.build(stage_config=stage_config, force=True)\n",
                "asset_id = stage.run()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Quality Impressions\n",
                "Let's get a summary of the data quality issues by type."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>n</th>\n",
                            "      <th>%</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_non_ascii_chars</th>\n",
                            "      <td>27252</td>\n",
                            "      <td>46.173396</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_excessive_whitespace</th>\n",
                            "      <td>7540</td>\n",
                            "      <td>12.775114</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_identical_review_content</th>\n",
                            "      <td>3923</td>\n",
                            "      <td>6.646787</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_has_emoji</th>\n",
                            "      <td>3490</td>\n",
                            "      <td>5.91315</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_non_english_review</th>\n",
                            "      <td>2276</td>\n",
                            "      <td>3.856255</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_non_english_app_name</th>\n",
                            "      <td>1402</td>\n",
                            "      <td>2.375426</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_excessive_numbers</th>\n",
                            "      <td>41</td>\n",
                            "      <td>0.069467</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_phone_number</th>\n",
                            "      <td>26</td>\n",
                            "      <td>0.044052</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_inconsistent_app_id_name</th>\n",
                            "      <td>8</td>\n",
                            "      <td>0.013554</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_HTML_chars</th>\n",
                            "      <td>5</td>\n",
                            "      <td>0.008472</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_control_chars</th>\n",
                            "      <td>2</td>\n",
                            "      <td>0.003389</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_identical_rows</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_identical_review_id</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_review_missing</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_email</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>dqa_contains_url</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                           n          %\n",
                            "dqa_contains_non_ascii_chars           27252  46.173396\n",
                            "dqa_contains_excessive_whitespace       7540  12.775114\n",
                            "dqa_identical_review_content            3923   6.646787\n",
                            "dqa_has_emoji                           3490    5.91315\n",
                            "dqa_non_english_review                  2276   3.856255\n",
                            "dqa_non_english_app_name                1402   2.375426\n",
                            "dqa_contains_excessive_numbers            41   0.069467\n",
                            "dqa_contains_phone_number                 26   0.044052\n",
                            "dqa_contains_inconsistent_app_id_name      8   0.013554\n",
                            "dqa_contains_HTML_chars                    5   0.008472\n",
                            "dqa_contains_control_chars                 2   0.003389\n",
                            "dqa_identical_rows                         0        0.0\n",
                            "dqa_identical_review_id                    0        0.0\n",
                            "dqa_review_missing                         0        0.0\n",
                            "dqa_contains_email                         0        0.0\n",
                            "dqa_contains_url                           0        0.0"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "dqa = DataQualityAnalysis()\n",
                "dqa.summarize()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Preprocessing Approach"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data quality assessment (DQA) conducted on the AppVoCAI dataset revealed several key issues that may require some treatment during the data cleaning process. That said, our review of the DQA results, and our treatment of these anomalies must be contextualized within an overall data preprocessing ethos, or approach. \n",
                "\n",
                "Downstream tasks such as sentiment analysis, classification, text summarization and generation will leverage  **transformer-based models** (like BERT, RoBERTa, or GPT), which have shown to be quite **robust** in handling many kinds of data anomalies and variations. Unlike traditional Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM) networks, and Convolutional Neural Networks (CNNs), that rely heavily on extensive preprocessing, transformers represent an evolution in language comprehension, capable of capturing relationships across distant sequences and inferring intricate nuances in language with precision without many of the traditional natural language processing (NLP) interventions.  Here's why.\n",
                "\n",
                "1. **Contextual Understanding**:\n",
                "   - Transformer models leverage the **context** in which words appear. So, even if a word like \"goooood\" appears, the model can usually infer its meaning based on the surrounding text.\n",
                "   - Models like BERT or GPT can often recognize that \"goooood\" is just an elongated form of \"good\" because of how they understand the sequence of tokens.\n",
                "\n",
                "2. **Subword Tokenization**:\n",
                "   - Most transformer models use **subword tokenizers** like WordPiece (used by BERT) or Byte-Pair Encoding (used by GPT), which break down rare or unknown words into smaller subword units. For example:\n",
                "     - \"goooood\" might be tokenized as \"goo\" + \"##ood\".\n",
                "     - \"loooove\" might become \"lo\" + \"##ove\".\n",
                "   - This allows the model to handle rare or misspelled words by breaking them down into known subword pieces, which are still interpretable by the model.\n",
                "   \n",
                "3. **Pretraining Robustness**:\n",
                "   - Transformer models are pretrained on *massive* amounts of diverse text data, which often includes typos, misspellings, and casual language (e.g., from web data, social media). This means they've likely been exposed to, and learned from, similar patterns, making them more robust to these irregularities.\n",
                "\n",
                "In the transformer modeling paradigm, extracting rich, detailed sentiment, emotion, and intensity from customer reviews is best achieved through a conservative, light-touch approach to data preprocessing. This approach focuses on essential treatments—such as removing personally identifiable information (PII), correcting data errors, and converting emojis to text—while preserving the original text as much as possible.\n",
                "\n",
                "Certain preprocessing techniques, such as reducing repeated characters, or spelling correction, might unintentionally remove emphasis or change the tone of the review. For example, \"goooood\" with the extra \"o\"s might indicate strong positivity or excitement, whereas just \"good\" might seem more neutral. Transformer models are generally capable of understanding the difference in sentiment or tone conveyed by elongated words. Character repetitions often convey **emotion, emphasis, or informality**, and this is part of the natural variation in user-generated content. Removing or normalizing them might lose some of this nuance.\n",
                "\n",
                "\n",
                "- **Efficient Processing**: By not over-processing the text, you avoid unnecessary complexity in the preprocessing pipeline, reducing the risk of introducing errors or losing information.\n",
                "- **Transformers are Robust**: Since transformers handle these variations well, there's less pressure to \"fix\" these issues, especially if your primary goal is to capture the overall sentiment or meaning in the text.\n",
                "\n",
                "### When to Preprocess:\n",
                "There are cases where preprocessing may still be beneficial, such as:\n",
                "- **Strict Standardization**: If you're building interpretable models or need standardized outputs for downstream use cases (e.g., generating reports), you may prefer to clean or normalize text.\n",
                "- **Highly Noisy Data**: If the dataset contains extreme noise or gibberish-like text (e.g., excessive repetition of random letters), it might still be worth cleaning those cases up.\n",
                "\n",
                "### Conclusion:\n",
                "**If you’re using transformer models,** there's a strong case for leaving misspellings and repeated characters as they are, since these models are designed to handle these variations effectively. The context-awareness and tokenization strategies used by transformers can often deal with non-standard text better than more rigid traditional models.\n",
                "\n",
                "### Suggested Approach:\n",
                "- **Minimal Preprocessing**: Keep the text as close to the original form as possible, doing only necessary cleaning like removing URLs, emails, or extreme noise.\n",
                "- **Let Transformers Do the Work**: Trust that transformer-based models can handle elongated words, typos, and misspellings through contextual understanding and subword tokenization.\n",
                "\n",
                "Would you like further guidance on how transformers handle such variations in practice, or do you feel confident in this approach?\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Quality Review\n",
                "The following sections will present the anomalous observations for review prior to embarking on the cleaning stage."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Anomalies to be Removed"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Duplicate Review Content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>content</th>\n",
                            "      <th>count</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>151</th>\n",
                            "      <td>Good</td>\n",
                            "      <td>236</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>313</th>\n",
                            "      <td>Love it</td>\n",
                            "      <td>133</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>168</th>\n",
                            "      <td>Great</td>\n",
                            "      <td>130</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>172</th>\n",
                            "      <td>Great app</td>\n",
                            "      <td>114</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>230</th>\n",
                            "      <td>I love it</td>\n",
                            "      <td>76</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>279</th>\n",
                            "      <td>It’s amazing!</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>273</th>\n",
                            "      <td>It’s Ight</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>270</th>\n",
                            "      <td>Its alright</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>269</th>\n",
                            "      <td>It's so easy to use</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>320</th>\n",
                            "      <td>Love itttt</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>641 rows × 2 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                 content  count\n",
                            "151                 Good    236\n",
                            "313              Love it    133\n",
                            "168                Great    130\n",
                            "172            Great app    114\n",
                            "230            I love it     76\n",
                            "..                   ...    ...\n",
                            "279        It’s amazing!      2\n",
                            "273            It’s Ight      2\n",
                            "270          Its alright      2\n",
                            "269  It's so easy to use      2\n",
                            "320           Love itttt      2\n",
                            "\n",
                            "[641 rows x 2 columns]"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "summary, data = dqa.get_duplicate_review_content()\n",
                "summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data quality assessment (DQA) conducted on the AppVoC dataset revealed several key issues that may require some treatment during the data cleaning process. Let's take a look. \n",
                "\n",
                "### Observations to Be Removed:\n",
                "These cases represent data quality issues where the entire observation will be removed from the dataset.\n",
                "\n",
                "- **Duplicate Review Content**: 13.93% of the reviews are duplicates and will be removed to ensure the dataset contains only unique user feedback.\n",
                "- **Duplicate Review IDs**: A small fraction (0.0005%) of reviews with duplicate IDs will be removed to prevent inconsistencies.\n",
                "- **Missing Reviews**: Any reviews flagged as missing (0.000009%) will be dropped from the dataset.\n",
                "- **Inconsistent App ID-Name Pairs**: Inconsistent app ID-name pairs (0.0001%) will be removed to maintain consistency.\n",
                "- **Non-English Reviews**: 3.20% of the reviews are non-English and will be removed to focus on English content.\n",
                "- **Non-English App Names**: 2.76% of app names are non-English and will be removed.\n",
                "\n",
                "### Observations to Be Cleaned (Replacing Sequences):\n",
                "These issues involve replacing specific problematic sequences with predefined values, while keeping the rest of the observation intact.\n",
                "\n",
                "- **Non-ASCII Characters (27.88%)**: Non-ASCII characters will be replaced with an empty string to clean the text.\n",
                "- **Excessive Whitespace (12.97%)**: Whitespace sequences will be replaced with a single space to maintain proper formatting.\n",
                "- **Emojis (4.90%)**: Emojis will be converted to their text equivalents (e.g., 😊 becomes \"smiling face\").\n",
                "- **Phone Numbers (0.03%)**: Phone numbers will be replaced with \"[PHONE]\" to anonymize personal information.\n",
                "- **Control Characters (0.02%)**: Control characters will be removed by replacing them with an empty string to avoid formatting issues.\n",
                "- **HTML Characters (0.01%)**: HTML entities will be replaced with an empty string to strip unnecessary formatting.\n",
                "- **URLs (0.0007%)**: URLs will be replaced with \"[URL]\" to anonymize web addresses.\n",
                "- **Emails (0.0001%)**: Emails will be replaced with \"[EMAIL]\" to protect personal information.\n",
                "- **Excessive Numbers (0.04%)**: Excessive numbers will be replaced with \"[NUMBER]\" to normalize content where numbers dominate the text.\n",
                "\n",
                "### Risk Mitigation\n",
                "This approach delineates which observations will be removed entirely and which will undergo targeted sequence replacements to clean the data. By delineating the treatments, the data is prepared in a way that ensures both data integrity and readability, without losing more information than necessary. However, before taking the irreversible cleaning steps, we'll review a sampling of the anomalies to ensure that the flagged data is truly problematic.  "
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "appvocai",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
