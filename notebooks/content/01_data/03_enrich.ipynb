{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))\n",
    "FORCE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AppVoCAI Dataset Enrichment and Aggregation\n",
    "The Data Enrichment and Aggregation module is designed to transform raw app review data into actionable insights by enhancing and summarizing key features. This module begins by incorporating critical review metadata, such as review length and review age, to provide context on the scale and recency of user feedback. It then applies sentiment classification of each review, followed by a review quality assessment to filter for high-value content. Deviation analysis is performed to identify outliers and assess how individual reviews compare to broader patterns. The enriched data is subsequently aggregated at both the app and category levels, enabling a view of performance and sentiment trends across the mobile app ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "from discover.flow.enrich.metadata.stage import MetadataStage\n",
    "from discover.flow.enrich.sentiment.stage import SentimentClassificationStage\n",
    "from discover.flow.enrich.quality.stage import QualityStage\n",
    "from discover.flow.enrich.deviation.stage import DeviationStage\n",
    "from discover.flow.aggregation.stage import AggregationStage\n",
    "from discover.core.flow import PhaseDef, EnrichmentStageDef, AggregationStageDef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.enrich.stage\",\n",
    "        \"discover.flow.aggregation.stage\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Pipeline\n",
    "The Metadata Pipeline enriches the dataset by extracting and analyzing key features such as **review age**, **review length**, and three **temporal fields**—**month**, **day of the week**, and **hour of the day**. These features are designed to provide insights into user engagement patterns and app usage, supporting unmet needs discovery in the following ways:\n",
    "\n",
    "1. **Review Age**: Understanding how review content changes over time can help identify shifting user expectations and long-standing issues that may require attention. Analyzing review age trends can inform decisions on product updates and feature prioritization.\n",
    "\n",
    "2. **Review Length**: Longer reviews often contain richer, more detailed feedback. By evaluating review length, we can identify opportunities to address comprehensive user concerns or highlight areas where users have strong opinions or pain points.\n",
    "\n",
    "3. **Month**: Monthly trends can reveal **seasonal usage patterns**, indicating how user needs change throughout the year. This can inform strategies like seasonal feature releases, marketing campaigns, or resource allocation.\n",
    "\n",
    "4. **Day of the Week**: Analyzing reviews by the day of the week might uncover insights into **weekly routines** and how apps fit into users' schedules. For instance, productivity apps might show spikes on weekdays, while entertainment apps might peak on weekends, guiding feature development aligned with these usage patterns.\n",
    "\n",
    "5. **Hour of the Day**: Understanding when users are most active can provide clues about **contextual needs**. Apps with high engagement at night might suggest opportunities for sleep-related features, while those used during commutes may benefit from quick, on-the-go functionalities.\n",
    "\n",
    "Together, these metadata features enhance our understanding of app usage and user behavior, laying the foundation for identifying unmet needs and informing opportunity discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                             Review Metadata Stage                              #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                             Review Metadata Stage                              \n",
      "                             =====================                              \n",
      "                           Stage Started | Fri, 08 Nov 2024 22:33:19\n",
      "                         Stage Completed | Fri, 08 Nov 2024 22:33:19\n",
      "                           Stage Runtime | 0.0 seconds\n",
      "                           Cached Result | True\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.ENRICHMENT, stage=EnrichmentStageDef.METADATA\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = MetadataStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Pipeline  \n",
    "The Review-Level Sentiment Classification Pipeline uses spaCy to analyze sentiment on a scale from -1 to 1. Reviews are then classified as negative, neutral, or positive by dividing this scale into three equal spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                         Sentiment Classification Stage                         #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                         Sentiment Classification Stage                         \n",
      "                         ==============================                         \n",
      "                           Stage Started | Fri, 08 Nov 2024 22:33:26\n",
      "                         Stage Completed | Fri, 08 Nov 2024 22:33:26\n",
      "                           Stage Runtime | 0.0 seconds\n",
      "                           Cached Result | True\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.ENRICHMENT, stage=EnrichmentStageDef.SENTIMENT\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = SentimentClassificationStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Text Quality Analysis (TQA) Pipeline\n",
    "Review text quality is an indicator of the content's richness, coherence, and informativeness. In this section, we integrate two complementary quality assessment measures—a lexical/syntactic score and a perplexity-based score—into a weighted sum. This approach provides a balanced evaluation, capturing both the structural diversity and natural language fluency of the reviews.\n",
    "\n",
    "### Lexical and Syntactic Quality Assessment  \n",
    "The lexical and syntactic quality assessment (TQA) evaluates review quality using a composite score derived from multiple syntactic and lexical measures. These measures are computed with specific weights:\n",
    "\n",
    "1. **POS Count Score (40%)**: Reflects the richness of content using counts of nouns, verbs, adjectives, and adverbs.\n",
    "2. **POS Diversity Score (20%)**: Captures variety in language using an entropy-based calculation.\n",
    "3. **POS Intensity Score (10%)**: Assesses the density of key parts of speech relative to total word count.\n",
    "4. **Structural Complexity Score (20%)**: Evaluates text complexity using unique word proportion, special character usage, and word length variation.\n",
    "5. **TQA Check Score (10%)**: Incorporates quality signals such as limited digit use, minimal special characters, and proper terminal punctuation.\n",
    "\n",
    "The lexical and syntactic quality score is a weighted sum of these components.\n",
    "\n",
    "### Perplexity-Based Quality Assessment  \n",
    "This measure evaluates review quality by applying 13 linguistic and structural filters, each assigned a weight derived from relative perplexity differences between the full dataset and filtered subsets. The filters assess features like adjective presence, punctuation ratios, word repetition, and special character use. Weights are computed to emphasize filters that most reduce perplexity, thus enhancing text fluency and coherence. The final score is a weighted sum of these filter indicators. \n",
    "\n",
    "For detailed implementation and methodology, refer to the [Appendix](#appendix-link)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                              Review Quality Stage                              #\n",
      "# ============================================================================== #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/john/.ivy2/cache\n",
      "The jars for the packages stored in: /home/john/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f4d16e13-0df9-42f0-97ad-e4859827f922;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.12.500 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.12.500 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound joda-time#joda-time;2.8.1 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.12.500 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.17.0 in central\n",
      ":: resolution report :: resolve 1867ms :: artifacts dl 61ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.12.500 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.12.500 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.3.3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.17.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\tjoda-time#joda-time;2.8.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcommons-logging#commons-logging;1.2 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\tcommons-codec#commons-codec;1.11 by [commons-codec#commons-codec;1.15] in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   83  |   0   |   0   |   5   ||   78  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f4d16e13-0df9-42f0-97ad-e4859827f922\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 78 already retrieved (0kB/34ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                    NLPTask                                     \n",
      "                                    -------                                     \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:33:48\n",
      "pos_ud_ewt download started this may take some time.\n",
      "Approximate size to download 2.2 MB\n",
      "[ | ]pos_ud_ewt download started this may take some time.\n",
      "Approximate size to download 2.2 MB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:34:04\n",
      "                                 Runtime | 16.28 seconds\n",
      "\n",
      "\n",
      "                              ComputePOSStatsTask                               \n",
      "                              -------------------                               \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:34:04\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:34:05\n",
      "                                 Runtime | 0.64 seconds\n",
      "\n",
      "\n",
      "                             ComputeBasicStatsTask                              \n",
      "                             ---------------------                              \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:34:05\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:34:06\n",
      "                                 Runtime | 0.67 seconds\n",
      "\n",
      "\n",
      "                             ComputeTQAFiltersTask                              \n",
      "                             ---------------------                              \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:34:06\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:34:06\n",
      "                                 Runtime | 0.48 seconds\n",
      "\n",
      "\n",
      "                                    TQATask1                                    \n",
      "                                    --------                                    \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:34:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Fri, 08 Nov 2024 22:35:57\n",
      "                                 Runtime | 1.0 minutes and 50.57 seconds\n",
      "\n",
      "\n",
      "                                    TQATask2                                    \n",
      "                                    --------                                    \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:35:57\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:35:57\n",
      "                                 Runtime | 0.51 seconds\n",
      "\n",
      "\n",
      "                                    TQATask3                                    \n",
      "                                    --------                                    \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:35:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Complete Datetime | Fri, 08 Nov 2024 22:39:37\n",
      "                                 Runtime | 3.0 minutes and 40.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                              Review Quality Stage                              \n",
      "                              ====================                              \n",
      "                           Stage Started | Fri, 08 Nov 2024 22:33:27\n",
      "                         Stage Completed | Fri, 08 Nov 2024 22:41:36\n",
      "                           Stage Runtime | 8.0 minutes and 8.85 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.ENRICHMENT, stage=EnrichmentStageDef.QUALITY\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = QualityStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deviation Analysis Pipeline\n",
    "Deviation analysis is crucial for understanding how user feedback varies around average app performance metrics. At the app level, we analyze deviations in rating, review length, and sentiment relative to their respective averages. These insights reveal patterns in user experience, highlighting anomalies or inconsistencies that may indicate areas for improvement or unexpected user behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/08/2024 10:41:36 PM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/02_enrichment/appvocai_discover-02_enrichment-03_deviation-review-dataset.parquet from repository.\n",
      "[11/08/2024 10:41:36 PM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-enrichment-deviation-review from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                        Review Deviation Analysis Stage                         #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:41:36\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:41:36\n",
      "                                 Runtime | 0.27 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:41:36\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:41:36\n",
      "                                 Runtime | 0.21 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:41:36\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:41:37\n",
      "                                 Runtime | 0.21 seconds\n",
      "\n",
      "\n",
      "                          ComputePercentDeviationTask                           \n",
      "                          ---------------------------                           \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:41:37\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:41:37\n",
      "                                 Runtime | 0.18 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:================>                                       (4 + 10) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                        Review Deviation Analysis Stage                         \n",
      "                        ===============================                         \n",
      "                           Stage Started | Fri, 08 Nov 2024 22:41:36\n",
      "                         Stage Completed | Fri, 08 Nov 2024 22:41:39\n",
      "                           Stage Runtime | 2.77 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.ENRICHMENT, stage=EnrichmentStageDef.DEVIATION\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = DeviationStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App and Aggregation Pipelines\n",
    "Aggregating data at the app and category levels provides a high-level view of review trends and user behavior, offering insights into user engagement and feedback patterns. At the app level, we consolidate key metrics, such as average ratings, review length, review count, and total vote sum, while identifying standout reviews based on highest vote counts, top TQA scores, and longest review lengths. \n",
    "\n",
    "A similar approach is used at the category level, aggregating metrics across all apps within a category to reveal trends that may indicate common strengths or pain points across similar apps. This two-tiered aggregation—app-level and category-level—allows for both detailed and broad insights into app performance, aiding in strategic decisions and market comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### App Aggregation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/08/2024 10:41:39 PM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/03_aggregation/appvocai_discover-03_aggregation-00_app-app-dataset.parquet from repository.\n",
      "[11/08/2024 10:41:39 PM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-aggregation-app-app from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                             App Aggregation Stage                              #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                               AppAggregationTask                               \n",
      "                               ------------------                               \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:41:39\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:41:39\n",
      "                                 Runtime | 0.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                             App Aggregation Stage                              \n",
      "                             =====================                              \n",
      "                           Stage Started | Fri, 08 Nov 2024 22:41:39\n",
      "                         Stage Completed | Fri, 08 Nov 2024 22:41:45\n",
      "                           Stage Runtime | 6.25 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.AGGREGATION, stage=AggregationStageDef.APP\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = AggregationStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Aggregation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/08/2024 10:41:45 PM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [_remove_dataset_file_by_filepath] : Removed dataset file at workspace/dev/dataset/03_aggregation/appvocai_discover-03_aggregation-01_category-category-dataset.parquet from repository.\n",
      "[11/08/2024 10:41:45 PM] [INFO] [discover.infra.persistence.repo.dataset.DatasetRepo] [remove] : Removed dataset dataset-dev-aggregation-category-category from the repository.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# ============================================================================== #\n",
      "#                           Category Aggregation Stage                           #\n",
      "# ============================================================================== #\n",
      "\n",
      "\n",
      "\n",
      "                            CategoryAggregationTask                             \n",
      "                            -----------------------                             \n",
      "                          Start Datetime | Fri, 08 Nov 2024 22:41:45\n",
      "                       Complete Datetime | Fri, 08 Nov 2024 22:41:46\n",
      "                                 Runtime | 0.36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                           Category Aggregation Stage                           \n",
      "                           ==========================                           \n",
      "                           Stage Started | Fri, 08 Nov 2024 22:41:45\n",
      "                         Stage Completed | Fri, 08 Nov 2024 22:41:48\n",
      "                           Stage Runtime | 3.08 seconds\n",
      "\n",
      "\n",
      "# ============================================================================ #\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Obtain the configuration\n",
    "stage_config = reader.get_stage_config(\n",
    "    phase=PhaseDef.AGGREGATION, stage=AggregationStageDef.CATEGORY\n",
    ")\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = AggregationStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrichment Stage Wrap-Up\n",
    "The enrichment stage enhanced the dataset with features, including review metadata (such as length, age and temporal data), sentiment analysis, text quality scores, and comprehensive app- and category-level aggregations. In the upcoming EDA phase, we will leverage these enriched attributes to uncover patterns, relationships, and trends that illuminate user behavior and app performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
