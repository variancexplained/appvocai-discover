{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "if \"jbook\" in os.getcwd():\n",
    "    os.chdir(os.path.abspath(os.path.join(\"../..\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Quality Scoring Framework for App Reviews in Aspect-Based Sentiment Analysis (ABSA)\n",
    "In Aspect-Based Sentiment Analysis (ABSA), high-quality text enables models to accurately parse and infer nuanced sentiment across diverse aspects, particularly within user-generated content such as app reviews. To maximize ABSA efficacy, reviews should exhibit richness in lexical diversity, structural depth, sentiment clarity, and readability. \n",
    "\n",
    "Here, we present a text quality scoring framework that leverages multiple linguistic and structural dimensions to filter app reviews, ensuring that only those meeting high-quality standards are selected for analysis. \n",
    "\n",
    "### Quality Scoring Framework\n",
    "The framework assigns a weighted quality score to each review based on six key components:\n",
    "1. **POS Count (Content Volume)**\n",
    "2. **POS Diversity (Lexical Variety)**\n",
    "3. **Structural Complexity**\n",
    "4. **POS Intensity (Sentiment Focus)**\n",
    "5. **Readability**\n",
    "6. **TQA Check (Formal Quality Indicators)**\n",
    "\n",
    "Each component contributes to a comprehensive understanding of review quality, reflecting various linguistic and stylistic aspects that support ABSA objectives.\n",
    "\n",
    "### Overall Quality Score Formula\n",
    "\n",
    "The quality score \\( Q \\) is defined as follows:\n",
    "\n",
    "$$\n",
    "Q = w_1 \\times \\text{POS Count} + w_2 \\times \\text{POS Diversity} + w_3 \\times \\text{Structural Complexity} + w_4 \\times \\text{POS Intensity} + w_5 \\times \\text{Readability} + w_6 \\times \\text{TQA Check}\n",
    "$$\n",
    "\n",
    "where $( w_1, w_2, w_3, w_4, w_5)$, and $(w_6)$ are weights representing the relative importance of each component. The weights are calibrated to prioritize content-rich reviews conducive to multi-aspect sentiment inference.\n",
    "\n",
    "#### Weight Allocation and Justification\n",
    "\n",
    "The framework prioritizes **POS Count** due to its direct correlation with ABSA goals. POS Count holds the highest weight, as it ensures sufficient lexical volume, enabling richer and more varied sentiment and aspect extraction. POS Diversity and Structural Complexity are also assigned significant weights, as they enhance the scope and depth of analysis by ensuring reviews cover multiple aspects with well-structured expression. POS Intensity, Readability, and TQA Check receive supporting weights, contributing to focus, interpretability, and quality consistency without disproportionately influencing the quality assessment.\n",
    "\n",
    "### Components and Calculation\n",
    "\n",
    "Each component is designed to capture a specific dimension of review quality, relevant to ABSA’s emphasis on aspect coverage, sentiment clarity, and text readability.\n",
    "\n",
    "#### 1. POS Count (Content Volume) — $(w_1 = 0.4)$\n",
    "\n",
    "**Definition**: POS Count is a measure of the absolute quantity of content-bearing parts of speech, specifically nouns, verbs, adjectives, and adverbs. This component prioritizes reviews with a substantial volume of lexical material, directly supporting ABSA tasks by providing sufficient substance for identifying aspects and inferring nuanced sentiment.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{POS Count} = \\text{nouns} + \\text{verbs} + \\text{adjectives} + \\text{adverbs}\n",
    "$$\n",
    "\n",
    "**Rationale**: In the context of ABSA, reviews with high POS Count are more likely to provide in-depth feedback, encompassing multiple app features and varied sentiment. This component, weighted at 0.3, serves as the primary driver of the quality score, reflecting its fundamental role in content adequacy.\n",
    "\n",
    "#### 2. POS Diversity (Lexical Variety) — $( w_2 = 0.2 )$\n",
    "\n",
    "**Definition**: POS Diversity assesses the variety and balance of POS tags within the text. It calculates how evenly nouns, verbs, adjectives, and adverbs are distributed, using a normalized entropy score to reflect balance across content-bearing parts of speech.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{POS Diversity} = - \\sum_{i} \\left( p_{i} \\times \\log(p_{i}) \\right)\n",
    "$$\n",
    "where \\( p_i \\) represents the proportion of each POS type (nouns, verbs, adjectives, adverbs) within the text.\n",
    "\n",
    "**Rationale**: Lexical variety enhances ABSA performance by increasing the probability that multiple aspects and sentiments are represented. Reviews with balanced POS usage are more likely to contain a mixture of descriptive, evaluative, and action-oriented language, which provides a richer substrate for aspect and sentiment extraction.\n",
    "\n",
    "#### 3. Structural Complexity — $( w_3 = 0.18 )$\n",
    "\n",
    "**Definition**: Structural Complexity evaluates the variability and engagement level within each review, capturing sentence length variability, unique word usage, and punctuation proportion. This component encourages reviews with intricate sentence structures and unique tokens, both of which signal a higher depth of content and engagement.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{Structural Complexity} = 0.25 \\times \\text{sentence\\_length\\_std} + 0.25 \\times \\text{p\\_unique\\_tokens} + 0.25 \\times \\text{p\\_punctuation} + 0.25 \\times \\text{n\\_sentences}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- **sentence\\_length\\_std**: Standard deviation of sentence lengths, capturing complexity.\n",
    "- **p\\_unique\\_tokens**: Proportion of unique tokens, indicating lexical variety.\n",
    "- **p\\_punctuation**: Proportion of punctuation, reflecting sentence structuring.\n",
    "- **n\\_sentences**: Number of sentences, indicating text depth.\n",
    "\n",
    "**Rationale**: This component complements POS Count and POS Diversity by capturing sentence-level structure and engagement, both of which improve ABSA’s ability to parse and infer multi-dimensional sentiment. Weighted at 0.2, Structural Complexity balances the need for structured yet diverse content.\n",
    "\n",
    "#### 4. POS Intensity (Sentiment Focus) — $( w_4 = 0.07 )$\n",
    "\n",
    "**Definition**: POS Intensity measures the density of content-bearing words relative to total word count, emphasizing reviews where sentiment-laden and aspect-rich language predominates.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{POS Intensity} = \\frac{\\text{nouns} + \\text{verbs} + \\text{adjectives} + \\text{adverbs}}{\\text{total words}}\n",
    "$$\n",
    "\n",
    "**Rationale**: High POS Intensity suggests a focused, sentiment-rich review, where descriptive and evaluative language outweighs filler or redundant text. This complements POS Count by ensuring that content volume is matched with density, focusing on the substance of each review.\n",
    "\n",
    "#### 5. Readability — $( w_5 = 0.05 )$\n",
    "\n",
    "**Definition**: Readability assesses the ease with which a review can be read and interpreted, using the Flesch Reading Ease score to gauge accessibility. High readability ensures that reviews are well-structured and easily parsed, which benefits both ABSA models and human readability.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{Readability} = \\text{Flesch Reading Ease}\n",
    "$$\n",
    "\n",
    "**Rationale**: Readability supports ABSA by ensuring that sentiment and aspect-related language is presented in a straightforward manner. However, readability alone does not guarantee substantive content, so it is weighted lower, serving as a secondary quality indicator.\n",
    "\n",
    "#### 6. TQA Check (Formal Quality Indicators) — $( w_6 = 0.1 )$\n",
    "\n",
    "**Definition**: The TQA Check evaluates the formal quality of the text, including punctuation and digit ratio, which signal professionalism and readability. TQA Check serves as a filter for overly simplistic or noisy text.\n",
    "\n",
    "**Formula**:\n",
    "$$\n",
    "\\text{TQA Check} = 0.3 \\times (1 - \\text{high\\_digit\\_ratio}) + 0.3 \\times (1 - \\text{high\\_punctuation\\_ratio}) + 0.4 \\times \\text{has\\_terminal\\_punctuation}\n",
    "$$\n",
    "\n",
    "**Rationale**: By enforcing basic formal standards, the TQA Check helps maintain a minimum quality threshold, reducing noise without strongly influencing content richness. It’s particularly useful for filtering out low-quality reviews that might otherwise distort ABSA performance.\n",
    "\n",
    "### Final Quality Score Formula\n",
    "\n",
    "Based on the above rationale, the complete quality score formula is as follows:\n",
    "\n",
    "$$\n",
    "Q = 0.4 \\times \\text{POS Count} + 0.2 \\times \\text{POS Diversity} + 0.18 \\times \\text{Structural Complexity} + 0.07 \\times \\text{POS Intensity} + 0.05 \\times \\text{Readability} + 0.1 \\times \\text{TQA Check}\n",
    "$$\n",
    "\n",
    "This quality scoring framework provides a multi-dimensional approach to filtering app reviews for ABSA. By weighting content volume, diversity, structural complexity, intensity, readability, and formal quality checks, the score favors reviews rich in content, balanced in lexical usage, and clear in sentiment expression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Review' from 'discover.app.univariate' (/home/john/projects/appvocai-discover/discover/app/univariate.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01midgen\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssetIDGen\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PhaseDef, DataPrepStageDef\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiscover\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munivariate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Review\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Review' from 'discover.app.univariate' (/home/john/projects/appvocai-discover/discover/app/univariate.py)"
     ]
    }
   ],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.infra.config.flow import FlowConfigReader\n",
    "from discover.flow.data_prep.tqa.stage import TQAStage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORCE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "## Dependency Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.data_prep.stage\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Quality Scoring Pipeline\n",
    "The text quality scoring pipeline begins by obtaining a configuration tailored to the text quality assessment (TQA) stage. Using the `FlowConfigReader`, we retrieve and apply a configuration specific to TQA from the overall data preparation phase. This configuration includes the parameters and settings required to assess the quality of the text data.\n",
    "\n",
    "### Pipeline Steps:\n",
    "\n",
    "1. **Configuration Retrieval**: The pipeline starts by reading the configuration via `FlowConfigReader`. By specifying \"phases\" as the target configuration, we isolate the required settings, focusing on the TQA stage.\n",
    "\n",
    "2. **Stage Initialization**: The `TQAStage` is built using the retrieved `stage_config`, which defines parameters such as thresholds, quality components, and weightings for text quality scoring. Setting the `force` parameter allows us to re-run this stage if necessary.\n",
    "\n",
    "3. **Execution and Asset Creation**: Finally, running the `TQAStage` initiates the text quality assessment, where each review's quality score is computed based on the defined formula. Once completed, this produces an asset identifier, `asset_id`, which corresponds to the processed dataset with text quality scores applied.\n",
    "\n",
    "This pipeline ensures that the text quality assessment is structured and reproducible, setting the stage for further analysis and filtering based on quality thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the configuration\n",
    "reader = FlowConfigReader()\n",
    "config = reader.get_config(\"phases\", namespace=False)\n",
    "stage_config = config[\"dataprep\"][\"stages\"][\"tqa\"]\n",
    "\n",
    "# Build and run Data Ingestion Stage\n",
    "stage = TQAStage.build(stage_config=stage_config, force=FORCE)\n",
    "asset_id = stage.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon completing the text quality scoring pipeline, the dataset is now enriched with quality scores that reflect the structural and linguistic richness of each review. This dataset provides a foundation for further selection, where high-quality samples can be identified for pseudolabeling and other downstream tasks. Next, we will examine how the scores and data are distributed at different quality thresholds. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
