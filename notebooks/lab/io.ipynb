{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# IO Lab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pyarrow.parquet as pq\n",
                "import pyarrow as pa\n",
                "import pandas as pd\n",
                "from appvocai-discover.shared.frameworks.spark.factory import SparkSessionPool\n",
                "from appvocai-discover.shared.persist.file.io import IOService, TarGzHandler\n",
                "pd.options.display.max_rows = 999\n",
                "pd.options.display.max_columns = 100\n",
                "pd.options.display.max_colwidth = 20\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Convert and Compress"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset read. It has 22166591 rows with memory size of 16629646140.0 Mb.\n",
                        "Created 14 parquet files.\n",
                        "Compressed data/ext/reviews into data/ext/reviews.tar.gz\n",
                        "Conversion complete. Upload to AWS\n"
                    ]
                }
            ],
            "source": [
                "fp1 = \"data/ext/reviews.pkl\"\n",
                "fp2 = \"data/ext/reviews\"\n",
                "fp3 = \"data/ext/reviews_2024-07-03_22M.tar.gz\"\n",
                "\n",
                "df1 = IOService.read(fp1)\n",
                "df1.memory_usage(deep=True).sum().sum()/1024*1024\n",
                "print(f\"Dataset read. It has {df1.shape[0]} rows with memory size of {df1.memory_usage(deep=True).sum().sum()/1024*1024} Mb.\")\n",
                "IOService.write(filepath=fp2, data=df1, row_group_size=1073741824, partition_cols=[\"category\"])\n",
                "assert os.path.isdir(fp2)\n",
                "print(f\"Created {len(os.listdir(fp2))} parquet files.\")\n",
                "TarGzHandler().compress_directory(directory_path=fp2, tar_gz_path=fp3)\n",
                "assert os.path.exists(fp3)\n",
                "print(\"Conversion complete. Upload to AWS\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Validate Compression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracted data/ext/reviews_2024-07-03_22M.tar.gz to data/ext/reviews2\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 22166591 entries, 0 to 22166590\n",
                        "Data columns (total 11 columns):\n",
                        " #   Column       Non-Null Count     Dtype         \n",
                        "---  ------       --------------     -----         \n",
                        " 0   id           22166591 non-null  string        \n",
                        " 1   app_id       22166591 non-null  string        \n",
                        " 2   app_name     22166591 non-null  string        \n",
                        " 3   category_id  22166591 non-null  object        \n",
                        " 4   author       22166591 non-null  object        \n",
                        " 5   rating       22166591 non-null  float64       \n",
                        " 6   content      22166591 non-null  string        \n",
                        " 7   vote_sum     22166591 non-null  Int64         \n",
                        " 8   vote_count   22166591 non-null  Int64         \n",
                        " 9   date         22166591 non-null  datetime64[ns]\n",
                        " 10  category     22166591 non-null  category      \n",
                        "dtypes: Int64(2), category(1), datetime64[ns](1), float64(1), object(2), string(4)\n",
                        "memory usage: 1.7+ GB\n"
                    ]
                }
            ],
            "source": [
                "fp3 = \"data/ext/reviews_2024-07-03_22M.tar.gz\"\n",
                "fp4 = \"data/ext/reviews2\"\n",
                "TarGzHandler().extract(tar_gz_path=fp3, extract_dir=fp4)\n",
                "df2 = IOService.read(filepath=fp4)\n",
                "df2.info(verbose=True, max_cols=20, memory_usage=True, show_counts=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "appvocai-discover",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}