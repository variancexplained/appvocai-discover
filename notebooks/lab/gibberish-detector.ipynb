{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibberish Detection \n",
    "\n",
    "This notebook leverages a **AutoNLP Gibberish Detector**, specifically the `madhurjindal/autonlp-Gibberish-Detector-492513457` model, to perform gibberish detection. The goal is to efficiently  classify user input as either gibberish or non-gibberish for the purposes of **Data Quality Assessment (DQA)** and **Exploratory Data Analysis (EDA)**. \n",
    "\n",
    "## Model Overview\n",
    "\n",
    "- **Model Name**: `madhurjindal/autonlp-Gibberish-Detector-492513457`\n",
    "- **Task**: Multi-class Classification\n",
    "- **Language**: English\n",
    "- **Number of Classes**: 4 categories:\n",
    "    1. **Noise**: Gibberish at the zero level where even the different constituents of the input phrase (words) do not hold any meaning independently.\n",
    "    \n",
    "For example: dfdfer fgerfow2e0d qsqskdsd djksdnfkff swq.    \n",
    "    2. **\n",
    "\n",
    "Word Sa**lad: Gibberish at level 1 where words make sense independently, but when looked at the bigger picture (the phrase) any meaning is not depicte    d.\n",
    "For example: 22 madhur old punjab pickle chen    n    3. **ai\n",
    "\n",
    "GMild gib**berish: Gibberish at level 2 where there is a part of the sentence that has grammatical errors, word sense errors, or any syntactical abnormalities, which leads the sentence to miss out on a coherent mea    ning.\n",
    "For example: Madhur study in a t    e    4. **acher**\n",
    "\n",
    "Clean: This category represents a set of words that form a complete and meaningful sentence on     its own.\n",
    "For example: I love thir ABSA.\n",
    "\n",
    "\n",
    "\n",
    "## Workflow Outline\n",
    "\n",
    "1. **Loading and Preprocessig Data**:\n",
    "\n",
    "   - Import the necessary libraries and load th dataset.\n",
    "\n",
    "   - Perform any required preprocessing, such as cleaning text data and handling missingalues.\n",
    "\n",
    "\n",
    "\n",
    "2. **Mode Setup**:\n",
    "\n",
    "   - madhurjindal/autonlp-Gibberish-Detector-492513457t-analysis` model from Huging Face.\n",
    "\n",
    "   - Configure the model for gibberish detectionsicationGibberish Detectionnt Aalysis**:\n",
    "\n",
    "   - Use the model tgibberish sentiment for each text entry in th dataset.\n",
    "\n",
    "   -textsentiments into ofourf the five caNoisey Word Salad, Mild Gibberishe,Cleany\n",
    "   - Set a binary indicator to True if the predicted category (category with highest probability) is not Clean. Positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:05.769072Z",
     "iopub.status.busy": "2024-11-14T23:50:05.768706Z",
     "iopub.status.idle": "2024-11-14T23:50:18.531109Z",
     "shell.execute_reply": "2024-11-14T23:50:18.529822Z",
     "shell.execute_reply.started": "2024-11-14T23:50:05.769035Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tqdm -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:18.533555Z",
     "iopub.status.busy": "2024-11-14T23:50:18.533194Z",
     "iopub.status.idle": "2024-11-14T23:50:23.575192Z",
     "shell.execute_reply": "2024-11-14T23:50:23.574271Z",
     "shell.execute_reply.started": "2024-11-14T23:50:18.533521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Register `tqdm` with pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:23.577170Z",
     "iopub.status.busy": "2024-11-14T23:50:23.576532Z",
     "iopub.status.idle": "2024-11-14T23:50:23.581660Z",
     "shell.execute_reply": "2024-11-14T23:50:23.580780Z",
     "shell.execute_reply.started": "2024-11-14T23:50:23.577124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:23.584674Z",
     "iopub.status.busy": "2024-11-14T23:50:23.584103Z",
     "iopub.status.idle": "2024-11-14T23:50:24.751063Z",
     "shell.execute_reply": "2024-11-14T23:50:24.750006Z",
     "shell.execute_reply.started": "2024-11-14T23:50:23.584631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU count: 1\n",
      "Thu Nov 14 19:20:36 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.01             Driver Version: 537.70       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro P400                    On  | 00000000:03:00.0  On |                  N/A |\n",
      "| 44%   58C    P0              N/A /  N/A |   1227MiB /  2048MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:25.581530Z",
     "iopub.status.busy": "2024-11-14T23:50:25.581061Z",
     "iopub.status.idle": "2024-11-14T23:50:29.211253Z",
     "shell.execute_reply": "2024-11-14T23:50:29.210436Z",
     "shell.execute_reply.started": "2024-11-14T23:50:25.581478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tqd_clean', 'tqd_mild_gibberish', 'tqd_noise', 'tqd_word_salad']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_name = \"madhurjindal/autonlp-Gibberish-Detector-492513457\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, truncate=True, padding=True)\n",
    "labels = model.config.id2label\n",
    "formatted_labels = [\n",
    "    \"tqd_\" + label.lower().replace(\" \", \"_\") for label in labels.values()\n",
    "]\n",
    "formatted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:29.213004Z",
     "iopub.status.busy": "2024-11-14T23:50:29.212541Z",
     "iopub.status.idle": "2024-11-14T23:50:29.218987Z",
     "shell.execute_reply": "2024-11-14T23:50:29.217985Z",
     "shell.execute_reply.started": "2024-11-14T23:50:29.212968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to predict gibberish\n",
    "def predict_gibberish(text):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            text.lower(),\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=512,\n",
    "        )\n",
    "        inputs = {\n",
    "            key: value.to(device) for key, value in inputs.items()\n",
    "        }  # Move inputs to the GPU\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "    return probabilities[0].cpu().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T23:50:29.220359Z",
     "iopub.status.busy": "2024-11-14T23:50:29.220084Z",
     "iopub.status.idle": "2024-11-15T00:01:18.403070Z",
     "shell.execute_reply": "2024-11-15T00:01:18.396786Z",
     "shell.execute_reply.started": "2024-11-14T23:50:29.220328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08404846489429474,\n",
       " 0.09230869263410568,\n",
       " 0.011694173328578472,\n",
       " 0.8119486570358276]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_gibberish(\n",
    "    text=\"i don't know what i i don't know what i i don't know what i i don't know what i \"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6072773,
     "sourceId": 9888498,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6074293,
     "sourceId": 9890703,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 206902002,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
