{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sentiment Classification Lab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/john/anaconda3/envs/appvocai-discover/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "/home/john/anaconda3/envs/appvocai-discover/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
                        "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
                    ]
                }
            ],
            "source": [
                "from appvocai-discover.analysis.sentiment import SentimentClassifierSemiSupervised, SentimentClassifierConfig\n",
                "from appvocai-discover.config.training import TrainingConfig, FineTuningConfig\n",
                "from appvocai-discover.shared.io import IOService"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "fp = \"data/01_exp/review.csv\"\n",
                "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data and Configurations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "reviews = IOService.read(fp)\n",
                "classifier_config = SentimentClassifierConfig(target_dataset_size=2**5, sample_size=2**4)\n",
                "training_config = TrainingConfig()\n",
                "finetune_config = FineTuningConfig()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Full Run"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/john/anaconda3/envs/appvocai-discover/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
                        "  warnings.warn(\n",
                        "2024-05-06 20:04:25,845:sample_reviews:INFO:Sample reviews method returning dataset of 16 observations.\n",
                        "The model 'PeftModelForSequenceClassification' is not supported for sentiment-analysis. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
                        "2024-05-06 20:04:27,991:predict:INFO:Predict method returning 16 predictions.\n",
                        "2024-05-06 20:04:27,995:augment_labeled_data:INFO:Augment Labeled Data added 12 examples to labeled dataset.\n",
                        "Total labeled observations = 12\n",
                        "2024-05-06 20:04:52,840:preprocess_data:INFO:Tokenized datasets:\n",
                        "DatasetDict({\n",
                        "    train: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 9\n",
                        "    })\n",
                        "    test: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 3\n",
                        "    })\n",
                        "})\n",
                        "2024-05-06 20:04:57,808:train:INFO:Training started on 9 observations.\n",
                        "2024-05-06 20:04:58,476:notebook_metadata:ERROR:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                        "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maistudio\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "wandb version 0.16.6 is available!  To upgrade, please run:\n",
                            " $ pip install wandb --upgrade"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.16.5"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/home/john/projects/appvocai-discover/wandb/run-20240506_200500-7kzc244m</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/aistudio/huggingface/runs/7kzc244m/workspace' target=\"_blank\">NoneType</a></strong> to <a href='https://wandb.ai/aistudio/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/aistudio/huggingface' target=\"_blank\">https://wandb.ai/aistudio/huggingface</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/aistudio/huggingface/runs/7kzc244m/workspace' target=\"_blank\">https://wandb.ai/aistudio/huggingface/runs/7kzc244m/workspace</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [3/3 00:30, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.006976</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.002411</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.001534</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 20:05:46,118:train:INFO:Training complete\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [1/1 00:00]\n",
                            "    </div>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 20:05:47,553:sample_reviews:INFO:Sample reviews method returning dataset of 16 observations.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'train': {'train_loss': 0.0015338632510975003, 'train_accuracy': 1.0, 'train_runtime': 0.9657, 'train_samples_per_second': 9.32, 'train_steps_per_second': 1.036, 'epoch': 3.0}, 'validation': {'eval_loss': 0.0009233011514879763, 'eval_accuracy': 1.0, 'eval_runtime': 0.3545, 'eval_samples_per_second': 8.463, 'eval_steps_per_second': 2.821, 'epoch': 3.0}}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "The model 'PeftModelForSequenceClassification' is not supported for sentiment-analysis. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
                        "2024-05-06 20:05:50,665:predict:INFO:Predict method returning 16 predictions.\n",
                        "2024-05-06 20:05:50,670:augment_labeled_data:INFO:Augment Labeled Data added 15 examples to labeled dataset.\n",
                        "Total labeled observations = 27\n",
                        "2024-05-06 20:06:00,671:update_fingerprint:WARNING:Parameter 'function'=<function SentimentClassifierSemiSupervised.preprocess_data.<locals>.preprocess_function at 0x7fcfe35bff40> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
                        "2024-05-06 20:06:11,038:preprocess_data:INFO:Tokenized datasets:\n",
                        "DatasetDict({\n",
                        "    train: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 21\n",
                        "    })\n",
                        "    test: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 6\n",
                        "    })\n",
                        "})\n",
                        "2024-05-06 20:06:11,500:train:INFO:Training started on 21 observations.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [3/3 01:54, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.001336</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.000507</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.000325</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 20:08:28,612:train:INFO:Training complete\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [1/1 00:00]\n",
                            "    </div>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 20:08:44,530:sample_reviews:INFO:Sample reviews method returning dataset of 16 observations.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'train': {'train_loss': 0.0003246016276534647, 'train_accuracy': 1.0, 'train_runtime': 15.2853, 'train_samples_per_second': 1.374, 'train_steps_per_second': 0.065, 'epoch': 3.0}, 'validation': {'eval_loss': 0.0004151940520387143, 'eval_accuracy': 1.0, 'eval_runtime': 0.4547, 'eval_samples_per_second': 13.196, 'eval_steps_per_second': 2.199, 'epoch': 3.0}}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "The model 'PeftModelForSequenceClassification' is not supported for sentiment-analysis. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GemmaForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'JambaForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MixtralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PhiForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'Qwen2ForSequenceClassification', 'Qwen2MoeForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'StableLmForSequenceClassification', 'Starcoder2ForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n",
                        "2024-05-06 20:08:46,903:predict:INFO:Predict method returning 16 predictions.\n",
                        "2024-05-06 20:08:46,908:augment_labeled_data:INFO:Augment Labeled Data added 16 examples to labeled dataset.\n",
                        "Total labeled observations = 43\n",
                        "2024-05-06 20:09:06,994:preprocess_data:INFO:Tokenized datasets:\n",
                        "DatasetDict({\n",
                        "    train: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 34\n",
                        "    })\n",
                        "    test: Dataset({\n",
                        "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
                        "        num_rows: 9\n",
                        "    })\n",
                        "})\n",
                        "2024-05-06 20:09:07,430:train:INFO:Training started on 34 observations.\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [6/6 02:06, Epoch 3/3]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Epoch</th>\n",
                            "      <th>Training Loss</th>\n",
                            "      <th>Validation Loss</th>\n",
                            "      <th>Accuracy</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.000103</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.000045</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>No log</td>\n",
                            "      <td>0.000036</td>\n",
                            "      <td>1.000000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 20:11:42,046:train:INFO:Training complete\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='3' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [2/2 00:00]\n",
                            "    </div>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-05-06 20:12:10,872:save_model:INFO:Saved model to models//sentiment-analysis/sentiment-analysis-lora-32-samples-0.85-confidence/.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'train': {'train_loss': 3.5803153878077865e-05, 'train_accuracy': 1.0, 'train_runtime': 28.0385, 'train_samples_per_second': 1.213, 'train_steps_per_second': 0.071, 'epoch': 3.0}, 'validation': {'eval_loss': 2.8450662284740247e-05, 'eval_accuracy': 1.0, 'eval_runtime': 0.7718, 'eval_samples_per_second': 11.66, 'eval_steps_per_second': 1.296, 'epoch': 3.0}}\n"
                    ]
                }
            ],
            "source": [
                "clf = SentimentClassifierSemiSupervised(reviews=reviews, model_name=model_name, \n",
                "                                        classifier_config=classifier_config, \n",
                "                                        training_config=training_config, \n",
                "                                        finetune_config=finetune_config)\n",
                "stats = clf.run()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "                                      SentimentClassifierStats                                      \n",
                        "                               Target Dataset Size | 32\n",
                        "                                        Start Time | 2024-05-06 20:04:25.799175\n",
                        "                                          End Time | 2024-05-06 20:12:10.862763\n",
                        "                                        Iterations | 3\n",
                        "                              Current Dataset Size | 82\n",
                        "                              Iteration Start Time | 2024-05-06 20:08:44.357733\n",
                        "                                Iteration End Time | 2024-05-06 20:12:10.862734\n",
                        "           Average Samples Augmented Per Iteration | 27.3\n",
                        "                         Average Iteration Runtime | 155.02116133333334\n",
                        "                                     Total Runtime | 465 days, 1:31:34.003200\n",
                        "                               Total Training Time | 465.063484\n",
                        "                                            Metric | validation_accuracy\n",
                        "                                     Average Score | 1.0\n",
                        "                                           Verbose | True\n",
                        "\n",
                        "\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "SentimentClassifierSemiSupervised.evaluate() missing 1 required positional argument: 'tokenized_dataset'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(stats)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[0;31mTypeError\u001b[0m: SentimentClassifierSemiSupervised.evaluate() missing 1 required positional argument: 'tokenized_dataset'"
                    ]
                }
            ],
            "source": [
                "print(stats)\n",
                "clf.evaluate()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "appvocai-discover",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}