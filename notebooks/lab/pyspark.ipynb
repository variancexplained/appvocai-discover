{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PySpark Lab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['/home/john/miniconda3/envs/genai-lab/lib/python311.zip', '/home/john/miniconda3/envs/genai-lab/lib/python3.11', '/home/john/miniconda3/envs/genai-lab/lib/python3.11/lib-dynload', '', '/home/john/miniconda3/envs/genai-lab/lib/python3.11/site-packages', '/home/john/miniconda3/envs/genai-lab/lib/python3.11/site-packages/setuptools/_vendor']\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "\n",
                "print(sys.path)\n",
                "import sparknlp  # The line that's causing the error"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "3.5.4\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "'5.1.2'"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "\n",
                "from sparknlp.base import Pipeline\n",
                "from sparknlp.annotator import DocumentAssembler, LanguageDetectorDL\n",
                "import pyspark\n",
                "from pyspark.sql.functions import  col, from_unixtime\n",
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DoubleType, LongType\n",
                "from genailab.infra.utils.file.io import IOService\n",
                "\n",
                "print(pyspark.__version__)\n",
                "sparknlp.version()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Spark Session"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "spark = (\n",
                "    SparkSession.builder.appName(\"genailab\")\n",
                "    .master(\"local[*]\")\n",
                "    .config(\"spark.driver.memory\", \"32g\")\n",
                "    .config(\"spark.executor.memory\", \"32g\")\n",
                "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
                "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\n",
                "    .config(\"spark.driver.maxResultSize\", \"0\")\n",
                "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.3.3\")\n",
                "    .config(\"spark.sql.legacy.parquet.nanosAsLong\", \"true\")\n",
                "    .getOrCreate()\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "schema = StructType([ \\\n",
                "    StructField(\"id\", StringType(), True), \\\n",
                "    StructField(\"app_id\", StringType(), True), \\\n",
                "    StructField(\"app_name\", StringType(), True), \\\n",
                "    StructField(\"category_id\", StringType(), True), \\\n",
                "    StructField(\"category\", StringType(), True), \\\n",
                "    StructField(\"author\", StringType(), True), \\\n",
                "    StructField(\"rating\", DoubleType(), True), \\\n",
                "    StructField(\"title\", StringType(), True), \\\n",
                "    StructField(\"content\", StringType(), True), \\\n",
                "    StructField(\"eda_review_length\", LongType(), True), \\\n",
                "    StructField(\"vote_count\", LongType(), True), \\\n",
                "    StructField(\"vote_sum\", LongType(), True), \\\n",
                "    StructField(\"date\", LongType(), True), \\\n",
                "\n",
                "    ])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "fp1 = \"data/dev/00_raw/reviews.pkl\"\n",
                "fp2 = \"data/dev/00_raw/reviews.parquet\"\n",
                "df1 = IOService.read(filepath=fp1)\n",
                "df1.to_parquet(fp2)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Spark DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df2 = spark.read.option(\"header\", \"true\").schema(schema).parquet(fp2)\n",
                "df2 = df2.withColumn(\"date\", from_unixtime(col(\"date\")/1000000000).cast('timestamp'))\n",
                "df2.printSchema()\n",
                "df2.take(5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "documentAssembler = DocumentAssembler().setInputCol(\"content\").setOutputCol('document')\n",
                "\n",
                "#language detection\n",
                "languageDetector = LanguageDetectorDL.pretrained() \\\n",
                "  .setInputCols([\"document\"]) \\\n",
                "  .setOutputCol(\"language\")\n",
                "\n",
                "pipe = Pipeline(stages=[documentAssembler, languageDetector])\n",
                "results = pipe.fit(df2).transform(df2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Resullts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results.select(\"language.result\").show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "genai-lab",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
