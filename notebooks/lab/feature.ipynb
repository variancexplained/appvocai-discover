{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discover.container import DiscoverContainer\n",
    "from discover.assets.idgen import DatasetIDGen\n",
    "from discover.core.flow import DataPrepStageEnum, PhaseEnum\n",
    "from discover.flow.data_prep.feature.task import NLPTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = DiscoverContainer()\n",
    "container.init_resources()\n",
    "container.wire(\n",
    "    modules=[\n",
    "        \"discover.flow.stage.base\",\n",
    "        \"discover.app.base\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = AssetIDGen()\n",
    "asset_id = idg.get_asset_id(\n",
    "    asset_type=\"dataset\",\n",
    "    phase=PhaseEnum.DATAPREP,\n",
    "    stage=DataPrepStageEnum.INGEST,\n",
    "    name=\"review\",\n",
    ")\n",
    "repo = container.persist.dataset_repo()\n",
    "dataset = repo.get(asset_id, distributed=False, nlp=False)\n",
    "df = dataset.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000017994</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000709020</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000856979</th>\n",
       "      <td>3.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000915473</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001208229</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999025824</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999390082</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999425761</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999707163</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999898828</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8009 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_rating\n",
       "app_id                \n",
       "1000017994    1.000000\n",
       "1000709020    4.500000\n",
       "1000856979    3.555556\n",
       "1000915473    5.000000\n",
       "1001208229    5.000000\n",
       "...                ...\n",
       "999025824     5.000000\n",
       "999390082     5.000000\n",
       "999425761     2.000000\n",
       "999707163     2.000000\n",
       "999898828     5.000000\n",
       "\n",
       "[8009 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"app_id\")[\"rating\"].mean().to_frame().rename(\n",
    "    columns={\"rating\": \"avg_rating\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/04/2024 10:43:32 PM] [ERROR] [NLPTask.run] [wrapper] : Exception occurred in NLPTask called with data=               id      app_id                        app_name category_id  \\\n",
      "0      7889871751   580643740                  hoopla Digital        6018   \n",
      "1      6995102689  1076402606             Libby, by OverDrive        6018   \n",
      "2      8308068603  1076402606             Libby, by OverDrive        6018   \n",
      "3      7316684624   852497554    Golden Quran | المصحف الذهبي        6018   \n",
      "4      8287426523   903001147                        Axis 360        6018   \n",
      "...           ...         ...                             ...         ...   \n",
      "59016  7210496363  1560911608                      Pi Browser        6002   \n",
      "59017  9877369972   472937654            Puffin Cloud Browser        6002   \n",
      "59018  7294609981  1124666597    NETGEAR Nighthawk - WiFi App        6002   \n",
      "59019  7315433429  1016562846             Rokie - Roku Remote        6002   \n",
      "59020  9557034803  1103138272  Facemoji Keyboard: Fonts&Emoji        6002   \n",
      "\n",
      "                     author  rating  \\\n",
      "0      0a433aa553dfe6554826       5   \n",
      "1      dce2976b6ee0e0fa44a0       5   \n",
      "2      50091da0238254dbef31       5   \n",
      "3      8d51996c99eee37e1f9b       5   \n",
      "4      ccbc729a023bde903a1a       3   \n",
      "...                     ...     ...   \n",
      "59016  a087ba048fde00d3970e       5   \n",
      "59017  b485771589d54eac8fce       5   \n",
      "59018  f1524e9cba85bb2b3434       5   \n",
      "59019  8feb08ed59aae6183e8f       3   \n",
      "59020  461f43c84d6f2ea0466a       2   \n",
      "\n",
      "                                                 content  vote_sum  \\\n",
      "0      Titles I didn’t think they would have and a ap...         0   \n",
      "1      I have been getting ebooks from the library fo...         0   \n",
      "2      With my busy life the e- library brought back ...         0   \n",
      "3      شكرا جزيلا لمصمم البرنامج والذين ساهمو  فيه وا...         0   \n",
      "4      This app has a lot of content to offer but I h...         0   \n",
      "...                                                  ...       ...   \n",
      "59016  The SocialChain developer listed for Pi Mobile...         1   \n",
      "59017  I love this app, I’m able to be non restricted...         0   \n",
      "59018      Great Product, easy install with a great app.         0   \n",
      "59019  The app is really good quality but it usually ...         0   \n",
      "59020  Hi. I loved this fonts but I got a iPad so I w...         0   \n",
      "\n",
      "       vote_count                date  review_length   category  \n",
      "0               0 2021-10-08 01:25:00             25       Book  \n",
      "1               0 2021-02-15 00:01:00             47       Book  \n",
      "2               0 2022-02-01 19:29:00             47       Book  \n",
      "3               0 2021-05-09 09:14:00             21       Book  \n",
      "4               0 2022-01-27 06:53:00            134       Book  \n",
      "...           ...                 ...            ...        ...  \n",
      "59016           1 2021-04-11 14:43:39            198  Utilities  \n",
      "59017           0 2023-04-30 12:49:35             32  Utilities  \n",
      "59018           0 2021-05-03 21:46:52              8  Utilities  \n",
      "59019           0 2021-05-09 01:55:59             37  Utilities  \n",
      "59020           0 2023-01-28 17:20:56             38  Utilities  \n",
      "\n",
      "[59021 rows x 12 columns]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/john/projects/appvocai-discover/discover/infra/service/logging/task.py\", line 60, in wrapper\n",
      "    result = func(self, *args, **kwargs)\n",
      "  File \"/home/john/projects/appvocai-discover/discover/flow/data_prep/feature/task.py\", line 87, in run\n",
      "    pipeline = self._build_pipeline()\n",
      "  File \"/home/john/projects/appvocai-discover/discover/flow/data_prep/feature/task.py\", line 103, in _build_pipeline\n",
      "    DocumentAssembler().setInputCol(self._column).setOutputCol(\"document\")\n",
      "  File \"/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/__init__.py\", line 139, in wrapper\n",
      "    return func(self, **kwargs)\n",
      "  File \"/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/sparknlp/base/document_assembler.py\", line 96, in __init__\n",
      "    super(DocumentAssembler, self).__init__(classname=\"com.johnsnowlabs.nlp.DocumentAssembler\")\n",
      "  File \"/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/__init__.py\", line 139, in wrapper\n",
      "    return func(self, **kwargs)\n",
      "  File \"/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/sparknlp/internal/annotator_transformer.py\", line 36, in __init__\n",
      "    self._java_obj = self._new_java_obj(classname, self.uid)\n",
      "  File \"/home/john/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/ml/wrapper.py\", line 80, in _new_java_obj\n",
      "    assert sc is not None\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                    NLPTask                                     \n",
      "                                    -------                                     \n",
      "                          Start Datetime | Mon, 04 Nov 2024 22:43:32\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m task \u001b[38;5;241m=\u001b[39m NLPTask(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/appvocai-discover/discover/infra/service/logging/task.py:60\u001b[0m, in \u001b[0;36mtask_logger.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m printer\u001b[38;5;241m.\u001b[39mprint_kv(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart Datetime\u001b[39m\u001b[38;5;124m\"\u001b[39m, v\u001b[38;5;241m=\u001b[39mstart_fmt)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Execute the original function being decorated, passing all args and kwargs.\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# After the function completes, compute stop time and duration\u001b[39;00m\n\u001b[1;32m     63\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[0;32m~/projects/appvocai-discover/discover/flow/data_prep/feature/task.py:87\u001b[0m, in \u001b[0;36mNLPTask.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;129m@task_logger\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    Executes the NLP pipeline on the input DataFrame, applying tokenization and POS tagging,\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    and returns the transformed DataFrame with additional columns for tokens and POS tags.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m        of tokens and POS tags, respectively.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\u001b[38;5;241m.\u001b[39mfit(data)\u001b[38;5;241m.\u001b[39mtransform(data)\n",
      "File \u001b[0;32m~/projects/appvocai-discover/discover/flow/data_prep/feature/task.py:103\u001b[0m, in \u001b[0;36mNLPTask._build_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03mBuilds and returns a Spark ML Pipeline with stages for document assembly, tokenization,\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03mPOS tagging, and a Finisher for output formatting.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    and result formatting for easy integration into a DataFrame.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Assembles raw content data into a Spark NLP document\u001b[39;00m\n\u001b[1;32m    102\u001b[0m document_assembler \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 103\u001b[0m     \u001b[43mDocumentAssembler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msetInputCol(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column)\u001b[38;5;241m.\u001b[39msetOutputCol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Tokenizer splits words for NLP processing\u001b[39;00m\n\u001b[1;32m    107\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer()\u001b[38;5;241m.\u001b[39msetInputCols([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msetOutputCol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m forces keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/appvocai/lib/python3.10/site-packages/sparknlp/base/document_assembler.py:96\u001b[0m, in \u001b[0;36mDocumentAssembler.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@keyword_only\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDocumentAssembler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclassname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcom.johnsnowlabs.nlp.DocumentAssembler\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setDefault(outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\"\u001b[39m, cleanupMode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisabled\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/__init__.py:139\u001b[0m, in \u001b[0;36mkeyword_only.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m forces keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/appvocai/lib/python3.10/site-packages/sparknlp/internal/annotator_transformer.py:36\u001b[0m, in \u001b[0;36mAnnotatorTransformer.__init__\u001b[0;34m(self, classname)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetParams(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m_java_class_name \u001b[38;5;241m=\u001b[39m classname\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_java_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muid\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/appvocai/lib/python3.10/site-packages/pyspark/ml/wrapper.py:80\u001b[0m, in \u001b[0;36mJavaWrapper._new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mReturns a new Java object.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m sc \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     82\u001b[0m java_obj \u001b[38;5;241m=\u001b[39m _jvm()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m java_class\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "task = NLPTask(column=\"content\")\n",
    "df1 = task.run(data=dataset.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
