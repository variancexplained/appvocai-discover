{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from genailabslm.infra.utils.file.io import IOService\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from genailabslm.infra.service.data.generator import DataBatchGenerator\n",
    "\n",
    "pandarallel.initialize(nb_workers=18, progress_bar=False, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"SamLowe/roberta-base-go_emotions-onnx\"\n",
    "file_name = \"onnx/model_quantized.onnx\"\n",
    "fp = \"workspace/dev/dataset/01_dataprep/appvocai_discover-01_dataprep-03_tqa-review-dataset.parquet\"\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ORTModelForSequenceClassification.from_pretrained(model_id, file_name=file_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = IOService.read(fp)\n",
    "gen = DataBatchGenerator(data=df, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapped Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruncatingTokenizer:\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, text, *args, **kwargs):\n",
    "        # Force truncation, padding, and max_length\n",
    "        return self.tokenizer(\n",
    "            text,\n",
    "            padding=\"longest\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "wrapped_tokenizer = TruncatingTokenizer(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the pipeline outside the loop\n",
    "tokenizer_kwargs = {\"padding\": True, \"truncation\": True, \"max_length\": 512}\n",
    "\n",
    "onnx_classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=model,\n",
    "    device=\"cpu\",\n",
    "    tokenizer=wrapped_tokenizer,\n",
    "    top_k=3,\n",
    "    function_to_apply=\"sigmoid\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotion(text):\n",
    "    return onnx_classifier([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list to store all batch results\n",
    "all_results = []\n",
    "\n",
    "for batch in tqdm(gen, total=gen.n_batches):\n",
    "    # Parallel apply to detect emotion in the batch\n",
    "    batch = batch[\"content\"].parallel_apply(detect_emotion)\n",
    "\n",
    "    # Collect processed batch\n",
    "    all_results.append(batch)\n",
    "\n",
    "# Concatenate all results and assign to the original DataFrame\n",
    "df[\"emotion\"] = pd.concat(all_results, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appvocai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
