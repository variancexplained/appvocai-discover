{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "This notebook obtains the AppVoC dataset from AWS S3, extracts the contents, then creates production, development and testing versions of the dataset in their raw directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from hashlib import blake2b\n",
    "from pandarallel import pandarallel\n",
    "from tqdm import tqdm\n",
    "from appvocai-genailabslm.utils.aws import S3Handler\n",
    "from appvocai-genailabslm.utils.file import IOService, TarGzHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=False, nb_workers=12, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_BUCKET = \"appstore-raw\"\n",
    "FINAL_BUCKET = \"appvoc\"\n",
    "S3_KEY_RAW = \"appstore_2023-09-17_T113629.tar.gz\"\n",
    "S3_FOLDER = \"appvoc_reviews_clean_2024_06_20\"\n",
    "LOCAL_PATH = \"data/ext/appstore_2023-09-17_T113629.tar.gz\"\n",
    "EXTRACT_DIR = \"data/ext/\"\n",
    "STAGE_DIR = \"data/stage/\"\n",
    "REVIEW_FILEPATH = \"data/ext/reviews.pkl\"\n",
    "DTYPES = {\n",
    "            \"id\": \"string\",\n",
    "            \"app_id\": \"string\",\n",
    "            \"app_name\": \"string\",\n",
    "            \"category_id\": \"category\",\n",
    "            \"category\": \"category\",\n",
    "            \"author\": \"string\",\n",
    "            \"rating\": \"float64\",\n",
    "            \"title\": \"string\",\n",
    "            \"content\": \"string\",\n",
    "            \"vote_count\": \"Int64\",\n",
    "            \"vote_sum\": \"Int64\",\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data from AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(LOCAL_PATH):\n",
    "    s3 = S3Handler()\n",
    "    s3.download_file(bucket_name=RAW_BUCKET, s3_key=S3_KEY_RAW, local_path=LOCAL_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(os.listdir(EXTRACT_DIR)) == 1:\n",
    "    tgz = TarGzHandler()\n",
    "    tgz.extract(tar_gz_path=LOCAL_PATH, extract_dir=EXTRACT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_column(value):\n",
    "    \"\"\"Function used to anonymize author information.\"\"\"    \n",
    "    try:\n",
    "        h = blake2b(digest_size=10)\n",
    "        h.update(value.encode(\"utf-8\"))\n",
    "        return h.hexdigest()\n",
    "    except AttributeError as e:\n",
    "        print(f\"Atribute error occured in hash_column. \\n{e}\")        \n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred in hash_column. \\n{e}\")        \n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_review_dataset(directory, dtypes: dict):\n",
    "    \"\"\"\n",
    "    Reads all .tsv files from a directory and concatenates the data into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory containing the .tsv files.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The concatenated DataFrame.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the directory does not exist.\n",
    "        ValueError: If no .tsv files are found in the directory.\n",
    "    \"\"\"    \n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(f\"The directory {directory} does not exist.\")\n",
    "    \n",
    "    # Get a list of all .tsv files in the directory\n",
    "    tsv_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.tsv')]\n",
    "\n",
    "    if not tsv_files:\n",
    "        raise ValueError(f\"No .tsv files found in {directory}\")\n",
    "\n",
    "    # Read each .tsv file and concatenate into a single DataFrame\n",
    "    dataframes = []\n",
    "    for filepath in tqdm(tsv_files):\n",
    "        if \"Shopping\" not in filepath:  # Only 9 reviews in shopping category.\n",
    "            df = pd.read_csv(filepath, sep=\"\\t\", dtype=dtypes, parse_dates=[\"date\"], lineterminator='\\n')\n",
    "            df = df.drop(columns=[\"title\"])        \n",
    "            df = df.drop_duplicates()\n",
    "            df = df.dropna()\n",
    "            # Anonymize author\n",
    "            df[\"author\"] = df[\"author\"].parallel_apply(hash_column)\n",
    "            dataframes.append(df)\n",
    "\n",
    "    concatenated_df = pd.concat(dataframes, ignore_index=True, axis=0)\n",
    "    return concatenated_df\n",
    "\n",
    "if not os.path.exists(REVIEW_FILEPATH):\n",
    "    reviews = build_review_dataset(directory=EXTRACT_DIR, dtypes=DTYPES)\n",
    "else:\n",
    "    reviews = IOService.read(REVIEW_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22166591 entries, 0 to 22166590\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Dtype         \n",
      "---  ------       -----         \n",
      " 0   id           string        \n",
      " 1   app_id       string        \n",
      " 2   app_name     string        \n",
      " 3   category_id  object        \n",
      " 4   category     object        \n",
      " 5   author       object        \n",
      " 6   rating       float64       \n",
      " 7   content      string        \n",
      " 8   vote_sum     Int64         \n",
      " 9   vote_count   Int64         \n",
      " 10  date         datetime64[ns]\n",
      "dtypes: Int64(2), datetime64[ns](1), float64(1), object(3), string(4)\n",
      "memory usage: 1.9+ GB\n"
     ]
    }
   ],
   "source": [
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>content</th>\n",
       "      <th>vote_sum</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9996920641</td>\n",
       "      <td>6446212408</td>\n",
       "      <td>Cookie Blocker</td>\n",
       "      <td>6002</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>bddd71849aa3fa6ede22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I used to use other extensions until they star...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-06-04 03:13:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8612588402</td>\n",
       "      <td>1577062674</td>\n",
       "      <td>NotifiNote: Notification Notes</td>\n",
       "      <td>6002</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>03b87d640a42153c3292</td>\n",
       "      <td>5.0</td>\n",
       "      <td>When displayed in notifications it includes in...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-04-27 20:00:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9731516851</td>\n",
       "      <td>1577062674</td>\n",
       "      <td>NotifiNote: Notification Notes</td>\n",
       "      <td>6002</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>6c8dc65632e59026ce2d</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DL'd &amp; installed today. I can see where this w...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-19 23:04:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9468795531</td>\n",
       "      <td>1577062674</td>\n",
       "      <td>NotifiNote: Notification Notes</td>\n",
       "      <td>6002</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>84b42d8051adc33c1de0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very convenient for reminding yourself for var...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-04 04:20:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9865359594</td>\n",
       "      <td>1577062674</td>\n",
       "      <td>NotifiNote: Notification Notes</td>\n",
       "      <td>6002</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>87f088639e0f11916816</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I am very forgetful and have post it notes all...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-04-27 04:01:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      app_id                        app_name category_id  \\\n",
       "0  9996920641  6446212408                  Cookie Blocker        6002   \n",
       "1  8612588402  1577062674  NotifiNote: Notification Notes        6002   \n",
       "2  9731516851  1577062674  NotifiNote: Notification Notes        6002   \n",
       "3  9468795531  1577062674  NotifiNote: Notification Notes        6002   \n",
       "4  9865359594  1577062674  NotifiNote: Notification Notes        6002   \n",
       "\n",
       "    category                author  rating  \\\n",
       "0  Utilities  bddd71849aa3fa6ede22     5.0   \n",
       "1  Utilities  03b87d640a42153c3292     5.0   \n",
       "2  Utilities  6c8dc65632e59026ce2d     3.0   \n",
       "3  Utilities  84b42d8051adc33c1de0     5.0   \n",
       "4  Utilities  87f088639e0f11916816     3.0   \n",
       "\n",
       "                                             content  vote_sum  vote_count  \\\n",
       "0  I used to use other extensions until they star...         0           0   \n",
       "1  When displayed in notifications it includes in...         3           4   \n",
       "2  DL'd & installed today. I can see where this w...         2           2   \n",
       "3  Very convenient for reminding yourself for var...         0           0   \n",
       "4  I am very forgetful and have post it notes all...         0           0   \n",
       "\n",
       "                 date  \n",
       "0 2023-06-04 03:13:04  \n",
       "1 2022-04-27 20:00:48  \n",
       "2 2023-03-19 23:04:51  \n",
       "3 2023-01-04 04:20:12  \n",
       "4 2023-04-27 04:01:53  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(REVIEW_FILEPATH):\n",
    "    IOService.write(filepath=REVIEW_FILEPATH, data=reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage Files by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_files(df: pd.DataFrame, stage_dir: str, force: bool = False):\n",
    "    dfg = df.groupby(by='category')\n",
    "    for name, data in tqdm(dfg):\n",
    "        filename = f\"{name.replace(' ', '-')}.tsv\"\n",
    "        filepath = os.path.join(stage_dir, filename)        \n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        if not os.path.exists(filepath) or force:\n",
    "            data.to_csv(filepath, sep=\"\\t\", index=False, header=True, lineterminator='\\n')        \n",
    "#stage_files(df=reviews, stage_dir=STAGE_DIR, force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Staged Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_staged_files(stage_dir: str, dtypes: dict):\n",
    "    categories = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "    crs = []\n",
    "    pcrs = []\n",
    "    tsv_files = [os.path.join(stage_dir, f) for f in os.listdir(stage_dir) if f.endswith('.tsv')]\n",
    "    for filepath in tqdm(tsv_files):\n",
    "        df = pd.read_csv(filepath, sep=\"\\t\", dtype=dtypes, parse_dates=[\"date\"], lineterminator='\\n')\n",
    "        category = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        r = df.shape[0]\n",
    "        c = df.shape[1]\n",
    "        nc = df[df.isna().any(axis=1)].shape[0]\n",
    "        cr = r - nc\n",
    "        pcr = round(cr / r * 100,2) \n",
    "\n",
    "        categories.append(category)\n",
    "        rows.append(r)\n",
    "        cols.append(c)\n",
    "        crs.append(cr)\n",
    "        pcrs.append(pcr)\n",
    "    d = {\"Category\": categories, \"Rows\": rows, \"Columns\": cols, \"Complete Rows\": crs, \"Percent Complete Rows\": pcrs}\n",
    "    df = pd.DataFrame(d)\n",
    "    df.loc[\"Total\"] = df.sum()\n",
    "    df.loc[df.index[-1], 'Category'] = ''\n",
    "    df.loc[df.index[-1], 'Columns'] = cols[0]\n",
    "    df.loc[df.index[-1], 'Percent Complete Rows'] = round(df.loc[df.index[-1], 'Complete Rows'] / df.loc[df.index[-1], 'Rows'] * 100,2)\n",
    "    return df\n",
    "#summary = summarize_staged_files(stage_dir=STAGE_DIR, dtypes=DTYPES)\n",
    "# summary\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:00<00:00, 23.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File appvoc_reviews_clean_2024_06_20/Social-Networking.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Entertainment.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Education.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Lifestyle.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Business.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Utilities.tsv already exists in appvoc bucket.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [00:00<00:00, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File appvoc_reviews_clean_2024_06_20/Medical.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Finance.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Health-&-Fitness.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Productivity.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Book.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Photo-&-Video.tsv already exists in appvoc bucket.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 24.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File appvoc_reviews_clean_2024_06_20/Reference.tsv already exists in appvoc bucket.\n",
      "File appvoc_reviews_clean_2024_06_20/Food-&-Drink.tsv already exists in appvoc bucket.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"read_timeout\": 120, \"retries\": {'max_attempts': 10}}\n",
    "s3 = S3Handler(config=config)\n",
    "if not s3.bucket_exists(bucket_name=FINAL_BUCKET):\n",
    "    s3.create_bucket(bucket_name=FINAL_BUCKET)\n",
    "s3.upload_folder(local_folder=STAGE_DIR, bucket_name=FINAL_BUCKET, s3_folder=S3_FOLDER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Project Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset: pd.DataFrame, env: str, frac: float = 1.0):\n",
    "    filepath = os.path.join(\"data\", env, \"00_raw/reviews.pkl\")\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    if not os.path.exists(filepath):\n",
    "        if frac < 1:\n",
    "            dataset = dataset.sample(frac=frac)\n",
    "        IOService.write(filepath=filepath, data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(dataset=reviews, env='prod')\n",
    "create_dataset(dataset=reviews, env='dev', frac=0.001)\n",
    "create_dataset(dataset=reviews, env='test', frac=0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-lab-slm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
