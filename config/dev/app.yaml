#!/usr/bin/env python3
# -*- coding:utf-8 -*-
# ================================================================================================ #
# Project    : GenAI-Lab-SLM                                                                       #
# Version    : 0.1.0                                                                               #
# Python     : 3.10.12                                                                             #
# Filename   : /config/dev/app.yaml                                                                #
# ------------------------------------------------------------------------------------------------ #
# Author     : John James                                                                          #
# Email      : john.james.ai.studio@gmail.com                                                      #
# URL        : https://github.com/variancexplained/genai-lab-slm                                   #
# ------------------------------------------------------------------------------------------------ #
# Created    : Thursday April 20th 2023 01:19:19 pm                                                #
# Modified   : Friday January 31st 2025 04:59:40 am                                                #
# ------------------------------------------------------------------------------------------------ #
# License    : MIT License                                                                         #
# Copyright  : (c) 2023 John James                                                                 #
# ================================================================================================ #
env: dev
# ------------------------------------------------------------------------------------------------ #
#                                           SETUP                                                  #
# ------------------------------------------------------------------------------------------------ #
setup:
  data:
    source_filepath: data/stage/dev/reviews
    dataset_config:
      phase: dataprep
      stage: raw
      name: review
      file_format: parquet
      dftype: pandas
# ------------------------------------------------------------------------------------------------ #
#                                      LOGGING                                                     #
# ------------------------------------------------------------------------------------------------ #
logging:
  handlers:
    console:
      class: logging.StreamHandler
      formatter: console
      level: INFO # Default, possibly overridden in environment config
      stream: ext://sys.stderr
    file:
      backupCount: 0
      class: logging.handlers.TimedRotatingFileHandler
      filename: logs/dev/log # Override in environment specific configurations
      formatter: file
      interval: 1
      level: INFO # Default, possibly overridden in environment config
      when: midnight
  loggers:
    py4j:  # Add this block to suppress py4j logging
      level: ERROR
      handlers:
        - console
        - file
      propagate: false  # Prevent py4j logs from being propagated to the root logger
  root:
    handlers:
    - console
    - file
    level: INFO # Default, possibly overridden in environment config
  version: 1
# ------------------------------------------------------------------------------------------------ #
#                                          IO                                                      #
# ------------------------------------------------------------------------------------------------ #
io:
  pandas:
    parquet:
      write_kwargs:
        row_group_size: 536870912 # 512 MB
# ------------------------------------------------------------------------------------------------ #
#                                    REPOSITORY                                                    #
# ------------------------------------------------------------------------------------------------ #
repository:
  dataset:
    fal: workspace/dev/datasets/fal/
    dal: workspace/dev/datasets/dal/
    ral: workspace/dev/datasets/ral/


# ------------------------------------------------------------------------------------------------ #
#                                 DATA PROCESSING                                                  #
# ------------------------------------------------------------------------------------------------ #
spark:
  parquet_block_size: 536870912 # 512 MB
# To compute memory limit, allocate 60%-70% of available memory and divide by nworkers to get
# memory_limit for each worker
dask:
  npartitions: 64
  nworkers: 16
  memory_limit:   "6GiB"
  threads_per_worker: 1
  processes: False

